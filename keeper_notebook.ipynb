{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/htleffew/hiring_analytics_simulator/blob/main/keeper_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kDt_ljf54Xx",
        "outputId": "b8ec0a4c-8aba-46d9-ed53-ae5501b458fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Netflix Org Dashboard Generation ---\n",
            "Report date: 2025-04-23\n",
            "Loading data from employee_snapshot.csv and employee_history.csv...\n",
            "Calculating organizational scope for managers...\n",
            "Identifying data quality issues...\n",
            "Found 61 potential date formatting issues.\n",
            "Found 18 promotion timing issues (promo date before hire date).\n",
            "Proceeding with 617 records having valid hire dates.\n",
            "Generating dashboard components...\n",
            "Generated 22 chart specifications.\n",
            "Generated data for 6 tables.\n",
            "\n",
            "--- Validating Generated JSON ---\n",
            "--- JSON Validation Complete ---\n",
            "\n",
            "Rendering HTML template: gem_ip_template.html\n",
            "Successfully rendered template to gem_ip_dashboard.html\n",
            "--- Dashboard successfully generated: gem_ip_dashboard.html ---\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This script processes employee snapshot and history data to generate\n",
        "organizational insights, statistical summaries, data visualizations,\n",
        "and narrative reports, culminating in an HTML dashboard.\n",
        "\n",
        "This first part covers:\n",
        "- Importing necessary libraries.\n",
        "- Configuring file paths and settings.\n",
        "- Defining helper functions for validation and formatting.\n",
        "- Loading and processing the raw employee data.\n",
        "- Defining the initial narrative generation function including statistical analysis.\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# # 1. Imports\n",
        "# =============================================================================\n",
        "# Description: This section imports all the necessary Python libraries\n",
        "# required for data manipulation, visualization, statistical analysis,\n",
        "# JSON handling, date/time operations, and template rendering.\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "import datetime as dt\n",
        "import json\n",
        "import traceback\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import jinja2\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import ttest_ind, chi2_contingency, pearsonr\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# # 2. Configuration\n",
        "# =============================================================================\n",
        "# Description: This section defines global configuration variables, including\n",
        "# input file names, output file name, template file name, the report date,\n",
        "# and color palettes for visualizations. It also sets the default Plotly\n",
        "# theme to ensure visual consistency with the dashboard's intended style.\n",
        "\n",
        "# --- File Paths ---\n",
        "snapshot_file = \"employee_snapshot.csv\"\n",
        "history_file = \"employee_history.csv\"\n",
        "output_html = \"gem_ip_dashboard.html\"\n",
        "template_file = \"gem_ip_template.html\"\n",
        "\n",
        "# --- Report Settings ---\n",
        "report_date = dt.datetime.now() # Use current date/time for the report\n",
        "\n",
        "# --- Visualization Settings ---\n",
        "# Define color palette matching the target dashboard theme (e.g., Netflix-inspired)\n",
        "color_palette = {\n",
        "    'primary': '#e50914',      # Example: Netflix red\n",
        "    'secondary': '#f5f5f1',    # Example: Netflix white/light gray\n",
        "    'tertiary': '#b3b3b3',    # Example: Netflix medium gray\n",
        "    'dark_gray': '#1f1f1f',    # Example: Netflix dark gray\n",
        "    'black': '#141414'         # Example: Netflix black\n",
        "}\n",
        "\n",
        "# Set default Plotly theme for consistency\n",
        "# This theme is applied globally but can be overridden by specific chart configurations\n",
        "# or JavaScript within the HTML template.\n",
        "pio.templates.default = \"plotly_dark\"\n",
        "pio.templates[\"plotly_dark\"].layout.update(\n",
        "    paper_bgcolor='rgba(0,0,0,0)',      # Transparent background for embedding\n",
        "    plot_bgcolor='rgba(31,31,31,0.5)', # Semi-transparent dark plot area\n",
        "    font_color=color_palette['secondary'],\n",
        "    font_family=\"Segoe UI, sans-serif\" # Specify a clean, professional font\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# # 3. Helper Functions\n",
        "# =============================================================================\n",
        "# Description: This section contains utility functions used throughout the\n",
        "# script for tasks like JSON validation, date formatting, safe numerical\n",
        "# rounding, and calculating organizational scope (total reports).\n",
        "\n",
        "def validate_json(json_string, variable_name):\n",
        "    \"\"\"\n",
        "    Validates if a given string is parsable as JSON.\n",
        "\n",
        "    Prints a warning if the input is not a string or an error if parsing fails.\n",
        "    This helps ensure that data passed to the HTML template is correctly formatted.\n",
        "\n",
        "    Args:\n",
        "        json_string (any): The input to validate. Expected to be a string.\n",
        "        variable_name (str): The name of the variable being validated (for logging).\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the input is a valid JSON string or not a string, False otherwise.\n",
        "    \"\"\"\n",
        "    if not isinstance(json_string, str):\n",
        "        # If the input isn't a string, bypass JSON validation but log a warning.\n",
        "        print(f\"--- VALIDATION WARNING for {variable_name}: Input is not a string (type: {type(json_string)}). Skipping json.loads validation. ---\")\n",
        "        return True # Assuming non-strings are acceptable if not intended to be JSON\n",
        "    try:\n",
        "        # Attempt to parse the string as JSON\n",
        "        json.loads(json_string)\n",
        "        # print(f\"Validation successful for: {variable_name}\") # Optional: Success message for debugging\n",
        "        return True\n",
        "    except json.JSONDecodeError as e:\n",
        "        # Handle specific JSON parsing errors\n",
        "        print(f\"--- INVALID JSON DETECTED in {variable_name} ---\")\n",
        "        print(f\"Error message: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        # Catch any other unexpected errors during validation\n",
        "        print(f\"--- UNEXPECTED ERROR during validation of {variable_name} ---\")\n",
        "        print(f\"Error: {e}\")\n",
        "        return False\n",
        "\n",
        "def format_timestamp(value):\n",
        "    \"\"\"\n",
        "    Formats various date/time representations into a 'YYYY-MM-DD' string.\n",
        "\n",
        "    Handles pandas Timestamps, NaT (Not a Time), and string inputs. Attempts\n",
        "    to parse strings using common formats before falling back. Returns None\n",
        "    for null or empty values.\n",
        "\n",
        "    Args:\n",
        "        value (any): The date/time value to format (Timestamp, NaT, str, etc.).\n",
        "\n",
        "    Returns:\n",
        "        str or None: The formatted date string ('YYYY-MM-DD'), the original\n",
        "                     string if unparseable (and not empty), or None for null/empty inputs.\n",
        "    \"\"\"\n",
        "    if pd.isnull(value):\n",
        "        return None\n",
        "    if isinstance(value, str):\n",
        "        if not value or value.lower() == 'nan': # Check for empty or 'nan' strings\n",
        "             return None\n",
        "        try:\n",
        "            # Attempt parsing with a specific format first (e.g., YYYYMMDD)\n",
        "            return pd.to_datetime(value, format='%Y%m%d').strftime('%Y-%m-%d')\n",
        "        except ValueError:\n",
        "            try:\n",
        "                 # Attempt generic parsing if the specific format fails\n",
        "                 return pd.to_datetime(value).strftime('%Y-%m-%d')\n",
        "            except ValueError:\n",
        "                 # If all parsing fails, return the original non-empty string\n",
        "                 return value\n",
        "    elif isinstance(value, pd.Timestamp):\n",
        "        # Format pandas Timestamp objects\n",
        "        return value.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        # Fallback for other types (e.g., integers representing dates)\n",
        "        return str(value)\n",
        "\n",
        "def safe_round(value, decimals=1, na_value='N/A'):\n",
        "    \"\"\"\n",
        "    Safely rounds a numerical value to a specified number of decimal places.\n",
        "\n",
        "    Handles non-numeric inputs (like NaN, None, or strings) by returning a\n",
        "    specified placeholder value ('N/A' by default).\n",
        "\n",
        "    Args:\n",
        "        value (any): The value to round.\n",
        "        decimals (int): The number of decimal places to round to. Defaults to 1.\n",
        "        na_value (str): The value to return if the input is not a valid number.\n",
        "                        Defaults to 'N/A'.\n",
        "\n",
        "    Returns:\n",
        "        float or str: The rounded number, or the na_value placeholder.\n",
        "    \"\"\"\n",
        "    if pd.isna(value) or not isinstance(value, (int, float, np.number)):\n",
        "        return na_value\n",
        "    try:\n",
        "        # Use np.round for compatibility with numpy types\n",
        "        return np.round(value, decimals)\n",
        "    except (TypeError, ValueError):\n",
        "         # Catch potential errors during rounding itself\n",
        "         return na_value\n",
        "\n",
        "def calculate_total_scope(employee_id, manager_map, visited):\n",
        "    \"\"\"\n",
        "    Recursively calculates the total organizational scope for a manager.\n",
        "\n",
        "    Scope includes both direct and indirect reports down the hierarchy.\n",
        "    Uses a set to avoid double-counting and a visited set to prevent infinite\n",
        "    loops in case of circular reporting structures.\n",
        "\n",
        "    Args:\n",
        "        employee_id (int): The Employee ID of the manager whose scope is being calculated.\n",
        "        manager_map (dict): A dictionary where keys are manager IDs and values are lists\n",
        "                            of their direct report employee IDs.\n",
        "        visited (set): A set containing employee IDs already visited in the current\n",
        "                       recursion path to detect cycles.\n",
        "\n",
        "    Returns:\n",
        "        set: A set containing the Employee IDs of all direct and indirect reports.\n",
        "    \"\"\"\n",
        "    # Base case: If we've already processed this employee in this path, stop.\n",
        "    if employee_id in visited:\n",
        "        return set()\n",
        "    visited.add(employee_id)\n",
        "\n",
        "    # Get direct reports for the current employee\n",
        "    direct_reports = manager_map.get(employee_id, [])\n",
        "    total_reports_set = set(direct_reports) # Start with direct reports\n",
        "\n",
        "    # Recursively find reports of reports\n",
        "    for report_id in direct_reports:\n",
        "        # Pass a copy of visited to avoid interference between sibling branches\n",
        "        indirect_reports = calculate_total_scope(report_id, manager_map, visited.copy())\n",
        "        total_reports_set.update(indirect_reports) # Add indirect reports to the set\n",
        "\n",
        "    return total_reports_set\n",
        "\n",
        "# =============================================================================\n",
        "# # 4. Data Loading and Processing\n",
        "# =============================================================================\n",
        "# Description: This section defines the `load_data` function, which handles\n",
        "# reading the employee snapshot and history CSV files, merging them, cleaning\n",
        "# data types, standardizing values (like job functions and levels), deriving\n",
        "# new features (like tenure, role, span of control, total scope), and\n",
        "# identifying data quality issues (like invalid dates or illogical promotion timing).\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Loads, merges, cleans, and processes employee data from CSV files.\n",
        "\n",
        "    Reads 'employee_snapshot.csv' and 'employee_history.csv', merges them on\n",
        "    'employee_id', standardizes column names, cleans job functions and levels,\n",
        "    determines employee roles (Manager/IC), processes dates, calculates derived\n",
        "    metrics like tenure, time-to-promotion, span of control, and total scope.\n",
        "    It also identifies and separates records with data quality issues.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Contains:\n",
        "            - df_clean (pd.DataFrame): The main processed DataFrame with valid data.\n",
        "            - bad_dates_json (str): JSON string listing records with date format issues.\n",
        "            - promo_issue_json (str): JSON string listing records where promotion date\n",
        "                                      is illogical (e.g., before hire date).\n",
        "            Returns (None, \"[]\", \"[]\") if file loading or critical processing fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"Loading data from {snapshot_file} and {history_file}...\")\n",
        "        # Read CSVs, explicitly setting dtype to string initially to avoid type inference issues\n",
        "        snap = pd.read_csv(snapshot_file, dtype=str)\n",
        "        hist = pd.read_csv(history_file, dtype=str)\n",
        "\n",
        "        # --- Column Name Standardization ---\n",
        "        snap.columns = snap.columns.str.lower().str.replace(' ', '_')\n",
        "        hist.columns = hist.columns.str.lower().str.replace(' ', '_')\n",
        "\n",
        "        # --- Data Validation: Check for Required Columns ---\n",
        "        required_snap_cols = ['employee_id', 'mgr_employee_id', 'job_level', 'job_function']\n",
        "        required_hist_cols = ['employee_id', 'hire_date', 'promotion_date']\n",
        "\n",
        "        missing_snap = [col for col in required_snap_cols if col not in snap.columns]\n",
        "        missing_hist = [col for col in required_hist_cols if col not in hist.columns]\n",
        "\n",
        "        if missing_snap:\n",
        "             raise ValueError(f\"Snapshot CSV missing required columns: {missing_snap}. Found: {snap.columns.tolist()}\")\n",
        "        if missing_hist:\n",
        "             raise ValueError(f\"History CSV missing required columns: {missing_hist}. Found: {hist.columns.tolist()}\")\n",
        "\n",
        "        # --- Data Type Conversion and Cleaning: IDs ---\n",
        "        # Convert IDs to numeric, coercing errors to NaN for later removal\n",
        "        snap['employee_id'] = pd.to_numeric(snap['employee_id'], errors='coerce')\n",
        "        hist['employee_id'] = pd.to_numeric(hist['employee_id'], errors='coerce')\n",
        "        snap['mgr_employee_id'] = pd.to_numeric(snap['mgr_employee_id'], errors='coerce')\n",
        "\n",
        "        # Drop rows where essential IDs couldn't be converted to numeric\n",
        "        snap.dropna(subset=['employee_id'], inplace=True)\n",
        "        hist.dropna(subset=['employee_id'], inplace=True)\n",
        "\n",
        "        # Convert valid employee IDs to integers\n",
        "        snap['employee_id'] = snap['employee_id'].astype(int)\n",
        "        hist['employee_id'] = hist['employee_id'].astype(int)\n",
        "\n",
        "        # --- Merge DataFrames ---\n",
        "        # Perform a left merge to keep all snapshot records and add history info where available\n",
        "        df = pd.merge(snap, hist, on='employee_id', how='left')\n",
        "\n",
        "        # --- Clean Job Function ---\n",
        "        # Consolidate variations and fill missing values\n",
        "        df['job_function'] = df['job_function'].replace({\n",
        "            'Product': 'Product Development',\n",
        "            'Content': 'Content and Studio',\n",
        "            'Studio': 'Content and Studio'\n",
        "        }).fillna('Other') # Fill NaNs with 'Other'\n",
        "        # Standardize functions outside the main focus groups into 'Other'\n",
        "        valid_functions = ['Product Development', 'Content and Studio']\n",
        "        df['job_function'] = df['job_function'].apply(lambda x: x if x in valid_functions else 'Other')\n",
        "\n",
        "        # --- Clean Job Level ---\n",
        "        # Store original level string, handle NaNs\n",
        "        df['job_level_raw'] = df['job_level'].astype(str).str.strip().fillna('Unknown')\n",
        "        # Extract numeric part (level number) if present at the beginning\n",
        "        df['specific_level_num'] = df['job_level_raw'].str.extract(r'^(\\d+)').iloc[:, 0].astype('Int64') # Use Int64 for nullable integer\n",
        "        # Extract title part, removing number and separators\n",
        "        df['job_level_title'] = df['job_level_raw'].str.replace(r'^\\d+\\s*-\\s*', '', regex=True) # Remove \"## - \"\n",
        "        df['job_level_title'] = df['job_level_title'].str.replace(r'^\\d+\\s*', '', regex=True)      # Remove \"## \"\n",
        "        df['job_level_title'] = df['job_level_title'].replace('', 'Unknown') # Handle empty strings after replacements\n",
        "        # Standardize various representations of unknown/missing levels\n",
        "        df.loc[df['job_level_title'].isin(['nan', 'None', 'unknown']), 'job_level_title'] = 'Unknown'\n",
        "\n",
        "        # --- Determine Role (Manager/IC) ---\n",
        "        # Define keywords indicating a management role\n",
        "        manager_titles = ['Manager', 'Director', 'Vice President', 'VP']\n",
        "        # Initial role assignment based on job title keywords (case-insensitive)\n",
        "        df['role'] = df['job_level_title'].apply(\n",
        "            lambda x: 'People Manager' if any(title.lower() in str(x).lower() for title in manager_titles) else 'Individual Contributor'\n",
        "        )\n",
        "        # Refine role based on reporting structure: if someone is listed as a manager for others, mark them as manager\n",
        "        # Ensure mgr_employee_id is treated as numeric before creating the set\n",
        "        valid_mgr_ids = pd.to_numeric(df['mgr_employee_id'], errors='coerce').dropna()\n",
        "        mgr_ids_with_reports = set(valid_mgr_ids.astype(int))\n",
        "        df.loc[df['employee_id'].isin(mgr_ids_with_reports), 'role'] = 'People Manager'\n",
        "        df['is_manager'] = (df['role'] == 'People Manager') # Create a boolean flag for convenience\n",
        "\n",
        "        # --- Process Dates ---\n",
        "        # Store original date strings for diagnostics\n",
        "        df['hire_date_str'] = df['hire_date'].astype(str).str.strip()\n",
        "        df['promotion_date_str'] = df['promotion_date'].astype(str).str.strip()\n",
        "\n",
        "        # Convert date strings to datetime objects, coercing errors to NaT (Not a Time)\n",
        "        # Assuming YYYYMMDD format based on original code\n",
        "        df['hire_date_dt'] = pd.to_datetime(df['hire_date_str'], format='%Y%m%d', errors='coerce')\n",
        "        df['promotion_date_dt'] = pd.to_datetime(df['promotion_date_str'], format='%Y%m%d', errors='coerce')\n",
        "\n",
        "        # --- Calculate Derived Fields ---\n",
        "        # Extract year and quarter from hire date\n",
        "        df['hire_year'] = df['hire_date_dt'].dt.year.astype('Int64')\n",
        "        df['hire_quarter_num'] = df['hire_date_dt'].dt.quarter.astype('Int64')\n",
        "        # Create a string representation of the hire quarter (e.g., '2023Q1')\n",
        "        df['hire_quarter'] = df['hire_date_dt'].dt.to_period('Q').astype(str).replace('NaT', pd.NA)\n",
        "\n",
        "        # Extract promotion year\n",
        "        df['promotion_year'] = df['promotion_date_dt'].dt.year.astype('Int64')\n",
        "\n",
        "        # Calculate tenure in years (as a float)\n",
        "        df['tenure_years'] = ((report_date - df['hire_date_dt']).dt.days / 365.25)\n",
        "\n",
        "        # Calculate time to promotion in years (as a float)\n",
        "        df['time_to_promotion'] = ((df['promotion_date_dt'] - df['hire_date_dt']).dt.days / 365.25)\n",
        "        # Invalidate TTP if the promotion date is illogical (before hire date)\n",
        "        df.loc[df['time_to_promotion'] < 0, 'time_to_promotion'] = pd.NA\n",
        "\n",
        "        # Create a boolean flag indicating if an employee has a valid promotion record\n",
        "        df['is_promoted'] = df['promotion_date_dt'].notna() & (df['time_to_promotion'].notna()) # Requires valid date and non-negative TTP\n",
        "\n",
        "        # --- Calculate Span of Control (Direct Reports) ---\n",
        "        # Count occurrences of each manager ID in the 'mgr_employee_id' column\n",
        "        # Ensure mgr_employee_id is numeric before value_counts\n",
        "        valid_mgr_ids_span = pd.to_numeric(df['mgr_employee_id'], errors='coerce').dropna()\n",
        "        direct_span = valid_mgr_ids_span.astype(int).value_counts()\n",
        "        # Map the counts to each employee; fill with 0 for non-managers or those with no reports\n",
        "        df['span_of_control'] = df['employee_id'].map(direct_span).fillna(0).astype(int)\n",
        "\n",
        "        # --- Calculate Total Scope (Direct + Indirect Reports) ---\n",
        "        # Build a map of manager -> list of direct reports\n",
        "        manager_map = defaultdict(list)\n",
        "        map_df = df[['employee_id', 'mgr_employee_id']].dropna() # Use only rows with valid IDs\n",
        "        for _, row in map_df.iterrows():\n",
        "             try:\n",
        "                 mgr_id = int(row['mgr_employee_id'])\n",
        "                 emp_id = int(row['employee_id'])\n",
        "                 # Avoid self-references which can break recursive calculations\n",
        "                 if mgr_id != emp_id:\n",
        "                    manager_map[mgr_id].append(emp_id)\n",
        "             except (ValueError, TypeError):\n",
        "                 # Silently ignore rows where IDs are not valid integers\n",
        "                 pass\n",
        "\n",
        "        # Calculate scope for each manager using the recursive helper function\n",
        "        print(\"Calculating organizational scope for managers...\")\n",
        "        scope_map = {}\n",
        "        manager_employee_ids = df.loc[df['is_manager'], 'employee_id'].dropna().unique()\n",
        "        for mid in manager_employee_ids:\n",
        "             try:\n",
        "                 mid_int = int(mid) # Ensure ID is integer\n",
        "                 # The calculate_total_scope function returns a set of all reports\n",
        "                 scope_map[mid_int] = len(calculate_total_scope(mid_int, manager_map, set()))\n",
        "             except (ValueError, TypeError):\n",
        "                 # Silently ignore invalid manager IDs\n",
        "                 pass\n",
        "        # Map the calculated scope to each employee; fill with 0 for non-managers\n",
        "        df['total_scope'] = df['employee_id'].map(scope_map).fillna(0).astype(int)\n",
        "\n",
        "        # --- Identify Data Quality Issues ---\n",
        "        print(\"Identifying data quality issues...\")\n",
        "        # Find records where original date strings exist but failed parsing\n",
        "        bad_hire = df.loc[df['hire_date_dt'].isna() & df['hire_date_str'].notna() & (df['hire_date_str'] != 'nan') & (df['hire_date_str'] != ''),\n",
        "                          ['employee_id', 'hire_date_str']]\n",
        "        bad_promo = df.loc[df['promotion_date_dt'].isna() & df['promotion_date_str'].notna() & (df['promotion_date_str'] != 'nan') & (df['promotion_date_str'] != ''),\n",
        "                           ['employee_id', 'promotion_date_str']]\n",
        "\n",
        "        # Find records where promotion date was before hire date (using original parsed dates)\n",
        "        promo_before_hire = df[(df['promotion_date_dt'] < df['hire_date_dt']) & df['promotion_date_dt'].notna() & df['hire_date_dt'].notna()].copy()\n",
        "\n",
        "        # --- Format Records for Diagnostics Output ---\n",
        "        # Combine bad hire/promo date records\n",
        "        bad_dates_records = pd.concat([\n",
        "            bad_hire.assign(type='Hire Date', original_value=bad_hire['hire_date_str']),\n",
        "            bad_promo.assign(type='Promotion Date', original_value=bad_promo['promotion_date_str'])\n",
        "        ])[['employee_id', 'type', 'original_value']].to_dict(orient='records')\n",
        "\n",
        "        # Format promo-before-hire records\n",
        "        promo_before_hire['hire_date_fmt'] = promo_before_hire['hire_date_dt'].apply(format_timestamp)\n",
        "        promo_before_hire['promotion_date_fmt'] = promo_before_hire['promotion_date_dt'].apply(format_timestamp)\n",
        "        # Calculate the original negative TTP for display purposes\n",
        "        promo_before_hire['orig_ttp'] = ((promo_before_hire['promotion_date_dt'] - promo_before_hire['hire_date_dt']).dt.days / 365.25)\n",
        "\n",
        "        promo_issue_records = promo_before_hire[['employee_id', 'hire_date_fmt', 'promotion_date_fmt', 'orig_ttp']].round({'orig_ttp': 2}).rename(\n",
        "            columns={'hire_date_fmt': 'hire_date', 'promotion_date_fmt': 'promotion_date', 'orig_ttp': 'time_to_promotion'}\n",
        "        ).to_dict(orient='records')\n",
        "\n",
        "        # Convert diagnostic records to JSON strings\n",
        "        bad_dates_json = json.dumps(bad_dates_records, default=str) # Use default=str for safety\n",
        "        promo_issue_json = json.dumps(promo_issue_records, default=str)\n",
        "\n",
        "        print(f\"Found {len(bad_dates_records)} potential date formatting issues.\")\n",
        "        print(f\"Found {len(promo_issue_records)} promotion timing issues (promo date before hire date).\")\n",
        "\n",
        "        # --- Create Final Clean DataFrame ---\n",
        "        # Exclude records with invalid hire dates, as tenure is fundamental\n",
        "        df_clean = df.dropna(subset=['hire_date_dt']).copy()\n",
        "        print(f\"Proceeding with {len(df_clean)} records having valid hire dates.\")\n",
        "\n",
        "        return df_clean, bad_dates_json, promo_issue_json\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File not found - {e}. Please ensure '{snapshot_file}' and '{history_file}' are in the correct directory.\")\n",
        "        # Return empty structures in case of file error\n",
        "        return None, \"[]\", \"[]\"\n",
        "    except ValueError as e:\n",
        "         # Catch specific data validation errors (e.g., missing columns)\n",
        "         print(f\"Error processing data: {e}\")\n",
        "         traceback.print_exc()\n",
        "         return None, \"[]\", \"[]\"\n",
        "    except Exception as e:\n",
        "        # Catch any other unexpected errors during loading/processing\n",
        "        print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None, \"[]\", \"[]\"\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# # 5. Narrative Generation\n",
        "# =============================================================================\n",
        "# Description: This section defines functions to generate textual summaries\n",
        "# and insights based on the processed data. It includes statistical tests\n",
        "# (like Chi-square for proportions, t-tests for means) to support the\n",
        "# observations. The narratives cover workforce composition, tenure, span of\n",
        "# control, promotions, and organizational design aspects.\n",
        "\n",
        "# --- Narrative Generation Functions ---\n",
        "\n",
        "def generate_narrative_summaries(df):\n",
        "    \"\"\"\n",
        "    Generates high-level narrative summaries and performs initial statistical tests.\n",
        "\n",
        "    Focuses on overall composition, tenure differences, manager ratios, span of\n",
        "    control, and promotion rates between 'Product Development' and 'Content and Studio'.\n",
        "    Calculates key metrics and performs Chi-square tests for categorical differences\n",
        "    and t-tests for numerical differences (tenure, span). Implements OLS regression\n",
        "    to analyze promotion velocity differences controlling for job level. Synthesizes\n",
        "    key statistically significant findings. Stores intermediate calculations for\n",
        "    potential use by more detailed narrative functions. Includes basic checks for\n",
        "    statistical significance (p < 0.05) and practical significance (e.g., tenure\n",
        "    difference > 0.5 years). Adds HTML line breaks (<br>) for readability in the\n",
        "    final dashboard output.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The processed DataFrame from `load_data`.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing narrative strings (e.g., 'composition_summary')\n",
        "              and intermediate calculation results (e.g., 'avg_tenure').\n",
        "              Returns {'error': message} if input data is invalid or empty.\n",
        "    \"\"\"\n",
        "    narratives = {}\n",
        "    intermediate_results = {} # Store calculations for potential reuse\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        return {'error': 'Input data is empty or missing.'}\n",
        "\n",
        "    # --- Data Preparation for Analysis ---\n",
        "    # Focus analysis on specific job functions, falling back to all data if none found\n",
        "    comp_df = df[df['job_function'].isin(['Product Development', 'Content and Studio'])].copy()\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: No data found for 'Product Development' or 'Content and Studio'. Analyzing all data.\")\n",
        "        comp_df = df.copy()\n",
        "\n",
        "    if comp_df.empty:\n",
        "         return {'error': 'Filtered or original data is empty.'}\n",
        "\n",
        "    # --- 1. Composition Summary ---\n",
        "    try:\n",
        "        total_employees = len(comp_df)\n",
        "        intermediate_results['total_employees'] = total_employees\n",
        "\n",
        "        # Group data by function and role to get counts\n",
        "        comp_by_func_role = comp_df.groupby(['job_function', 'role'], observed=False).size().unstack(fill_value=0)\n",
        "        intermediate_results['comp_by_func_role'] = comp_by_func_role\n",
        "\n",
        "        # Calculate overall percentages for ICs and Managers\n",
        "        ic_pct = (comp_df['role'] == 'Individual Contributor').mean() * 100 if 'role' in comp_df.columns else np.nan\n",
        "        mgr_pct = (comp_df['role'] == 'People Manager').mean() * 100 if 'role' in comp_df.columns else np.nan\n",
        "        intermediate_results['ic_pct'] = ic_pct\n",
        "        intermediate_results['mgr_pct'] = mgr_pct\n",
        "\n",
        "        # Calculate manager percentages per function, handling potential missing data\n",
        "        prod_mgr_pct = np.nan\n",
        "        cont_mgr_pct = np.nan\n",
        "        if 'Product Development' in comp_by_func_role.index and 'People Manager' in comp_by_func_role.columns:\n",
        "            prod_total = comp_by_func_role.loc['Product Development'].sum()\n",
        "            if prod_total > 0:\n",
        "                prod_mgr_pct = (comp_by_func_role.loc['Product Development', 'People Manager'] / prod_total) * 100\n",
        "        if 'Content and Studio' in comp_by_func_role.index and 'People Manager' in comp_by_func_role.columns:\n",
        "            cont_total = comp_by_func_role.loc['Content and Studio'].sum()\n",
        "            if cont_total > 0:\n",
        "                cont_mgr_pct = (comp_by_func_role.loc['Content and Studio', 'People Manager'] / cont_total) * 100\n",
        "        intermediate_results['prod_mgr_pct'] = prod_mgr_pct\n",
        "        intermediate_results['cont_mgr_pct'] = cont_mgr_pct\n",
        "\n",
        "        # Construct the narrative string\n",
        "        narratives['composition_summary'] = (\n",
        "            f\"Across {total_employees:,} employees analyzed (focusing on Product Development and Content & Studio), \"\n",
        "            f\"Individual Contributors constitute {safe_round(ic_pct, 0)}% and People Managers {safe_round(mgr_pct, 0)}%.\"\n",
        "            f\"<br><br>\" # Double line break for spacing in HTML\n",
        "            f\"Manager representation differs: {safe_round(prod_mgr_pct, 0)}% in Product Development versus {safe_round(cont_mgr_pct, 0)}% in Content & Studio. \"\n",
        "            f\"This variation might reflect differing organizational structures or team sizes within these functions.\"\n",
        "        )\n",
        "\n",
        "        # --- Statistical Test: Role Distribution (Chi-square) ---\n",
        "        roles_stat_sig_text = \"\" # Initialize empty string\n",
        "        try:\n",
        "            # Check if data exists for both functions and both roles\n",
        "            if ('Product Development' in comp_by_func_role.index and\n",
        "                'Content and Studio' in comp_by_func_role.index and\n",
        "                'Individual Contributor' in comp_by_func_role.columns and\n",
        "                'People Manager' in comp_by_func_role.columns):\n",
        "\n",
        "                # Create the contingency table for the Chi-square test\n",
        "                contingency_table = comp_by_func_role.loc[['Product Development', 'Content and Studio'], ['Individual Contributor', 'People Manager']]\n",
        "\n",
        "                # Check if all cell counts are >= 5 (requirement for Chi-square validity)\n",
        "                if contingency_table.values.min() >= 5:\n",
        "                    chi2, p_val, _, _ = chi2_contingency(contingency_table)\n",
        "                    intermediate_results['roles_p_value'] = p_val # Store p-value\n",
        "                    if p_val < 0.05:\n",
        "                        roles_stat_sig_text = f\"<br><br>A chi-square test (p = {p_val:.3f}) indicates a statistically significant difference in the IC vs. Manager distribution between these two functions.\"\n",
        "                    else:\n",
        "                        roles_stat_sig_text = f\"<br><br>A chi-square test (p = {p_val:.3f}) suggests the observed difference in IC vs. Manager distribution may not be statistically significant.\"\n",
        "                else:\n",
        "                     roles_stat_sig_text = \"<br><br>Note: Data is insufficient (some group counts < 5) for a reliable chi-square test on role distribution.\"\n",
        "                     intermediate_results['roles_p_value'] = np.nan\n",
        "            else:\n",
        "                roles_stat_sig_text = \"<br><br>Note: Required functions or roles are missing, statistical test for role distribution could not be performed.\"\n",
        "                intermediate_results['roles_p_value'] = np.nan\n",
        "        except Exception as stat_e:\n",
        "            print(f\"Chi-square test for role mix failed: {stat_e}\")\n",
        "            roles_stat_sig_text = \"<br><br>Note: An error occurred during the statistical test for role distribution.\"\n",
        "            intermediate_results['roles_p_value'] = np.nan\n",
        "\n",
        "        # Append the statistical significance note to the main summary\n",
        "        narratives['composition_summary'] += roles_stat_sig_text\n",
        "        intermediate_results['roles_stat_sig_text'] = roles_stat_sig_text # Store full text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating composition narrative: {e}\")\n",
        "        narratives['composition_summary'] = \"Error generating composition narrative.\"\n",
        "        intermediate_results['roles_stat_sig_text'] = \"\" # Ensure key exists even on error\n",
        "        intermediate_results['roles_p_value'] = np.nan\n",
        "\n",
        "    # --- 2. Tenure Summary ---\n",
        "    try:\n",
        "        # Initialize metrics to NaN\n",
        "        avg_tenure, prod_avg_tenure, cont_avg_tenure = np.nan, np.nan, np.nan\n",
        "        prod_pct_new, cont_pct_new, diff_tenure = np.nan, np.nan, np.nan\n",
        "\n",
        "        if 'tenure_years' in comp_df.columns and comp_df['tenure_years'].notna().any():\n",
        "            # Filter out NaNs and ensure tenure is numeric for calculations\n",
        "            tenure_df = comp_df[comp_df['tenure_years'].notna()].copy()\n",
        "            tenure_df['tenure_years'] = pd.to_numeric(tenure_df['tenure_years'], errors='coerce')\n",
        "            tenure_df.dropna(subset=['tenure_years'], inplace=True)\n",
        "\n",
        "            if not tenure_df.empty:\n",
        "                avg_tenure = tenure_df['tenure_years'].mean()\n",
        "                intermediate_results['avg_tenure'] = avg_tenure\n",
        "\n",
        "                # Get tenure values for each function\n",
        "                prod_vals = tenure_df[tenure_df['job_function'] == 'Product Development']['tenure_years']\n",
        "                cont_vals = tenure_df[tenure_df['job_function'] == 'Content and Studio']['tenure_years']\n",
        "\n",
        "                prod_avg_tenure = prod_vals.mean() # Returns NaN if prod_vals is empty\n",
        "                cont_avg_tenure = cont_vals.mean() # Returns NaN if cont_vals is empty\n",
        "                intermediate_results['prod_avg_tenure'] = prod_avg_tenure\n",
        "                intermediate_results['cont_avg_tenure'] = cont_avg_tenure\n",
        "\n",
        "                # Calculate percentage of employees with less than 2 years tenure\n",
        "                prod_pct_new = (prod_vals < 2).mean() * 100 if not prod_vals.empty else np.nan\n",
        "                cont_pct_new = (cont_vals < 2).mean() * 100 if not cont_vals.empty else np.nan\n",
        "                intermediate_results['prod_pct_new'] = prod_pct_new\n",
        "                intermediate_results['cont_pct_new'] = cont_pct_new\n",
        "\n",
        "                # Compare average tenures between functions\n",
        "                if not np.isnan(prod_avg_tenure) and not np.isnan(cont_avg_tenure):\n",
        "                    diff_tenure = abs(prod_avg_tenure - cont_avg_tenure)\n",
        "                    intermediate_results['diff_tenure'] = diff_tenure\n",
        "\n",
        "                    # Narrative based on the magnitude of the difference\n",
        "                    if diff_tenure < 0.5: # Threshold for similarity\n",
        "                        comparison = \"is broadly similar across functions\"\n",
        "                        narratives['tenure_summary'] = (\n",
        "                            f\"The average employee tenure is {safe_round(avg_tenure, 1)} years and {comparison} \"\n",
        "                            f\"(Product Development: {safe_round(prod_avg_tenure, 1)}, Content & Studio: {safe_round(cont_avg_tenure, 1)}).\"\n",
        "                            f\"<br><br>\"\n",
        "                            f\"Employees with less than 2 years of tenure comprise {safe_round(prod_pct_new, 0)}% in Product Development and \"\n",
        "                            f\"{safe_round(cont_pct_new, 0)}% in Content & Studio.\"\n",
        "                        )\n",
        "                    else: # Difference is more notable\n",
        "                        comparison = \"differs across functions\"\n",
        "                        narratives['tenure_summary'] = (\n",
        "                            f\"The average employee tenure is {safe_round(avg_tenure, 1)} years, and {comparison}: \"\n",
        "                            f\"{safe_round(prod_avg_tenure, 1)} years in Product Development versus {safe_round(cont_avg_tenure, 1)} years in Content & Studio.\"\n",
        "                            f\"<br><br>\"\n",
        "                            f\"The proportion of newer employees (< 2 years tenure) is {safe_round(prod_pct_new, 0)}% in Product Development and \"\n",
        "                            f\"{safe_round(cont_pct_new, 0)}% in Content & Studio.\"\n",
        "                        )\n",
        "                else: # Data missing for one or both functions\n",
        "                     intermediate_results['diff_tenure'] = np.nan\n",
        "                     narratives['tenure_summary'] = f\"The overall average employee tenure is {safe_round(avg_tenure, 1)} years. Data is insufficient for a direct comparison between Product Development and Content & Studio.\"\n",
        "\n",
        "                # --- Statistical Test: Tenure Difference (t-test) ---\n",
        "                tenure_stat_sig_text = \"\"\n",
        "                try:\n",
        "                    # Check for sufficient sample size in both groups (e.g., > 10)\n",
        "                    if len(prod_vals.dropna()) > 10 and len(cont_vals.dropna()) > 10:\n",
        "                        # Perform Welch's t-test (robust to unequal variances)\n",
        "                        t_stat, p_val = ttest_ind(prod_vals.dropna(), cont_vals.dropna(), equal_var=False, nan_policy='omit')\n",
        "                        intermediate_results['tenure_p_value'] = p_val # Store p-value\n",
        "                        if p_val < 0.05:\n",
        "                            tenure_stat_sig_text = f\"<br><br>A t-test suggests this difference in average tenure is statistically significant (p = {p_val:.3f}), indicating it is unlikely due to random chance.\"\n",
        "                        else:\n",
        "                            tenure_stat_sig_text = f\"<br><br>A t-test indicates the difference in average tenure is not statistically significant (p = {p_val:.3f}).\"\n",
        "                    else:\n",
        "                        tenure_stat_sig_text = \"<br><br>Note: Sample sizes (<=10 in one or both groups) are too small to reliably test the statistical significance of the tenure difference.\"\n",
        "                        intermediate_results['tenure_p_value'] = np.nan\n",
        "                except Exception as stat_e:\n",
        "                     print(f\"Error performing tenure significance test: {stat_e}\")\n",
        "                     tenure_stat_sig_text = \"<br><br>Note: An error occurred during the statistical test for tenure difference.\"\n",
        "                     intermediate_results['tenure_p_value'] = np.nan\n",
        "\n",
        "                # Append significance test result to tenure summary\n",
        "                if 'tenure_summary' in narratives: # Ensure base narrative exists\n",
        "                     narratives['tenure_summary'] += tenure_stat_sig_text\n",
        "                intermediate_results['tenure_stat_sig_text'] = tenure_stat_sig_text\n",
        "\n",
        "            else: # If tenure_df is empty after cleaning\n",
        "                 narratives['tenure_summary'] = \"No valid numeric tenure data available for analysis.\"\n",
        "                 intermediate_results['tenure_stat_sig_text'] = \"\"\n",
        "                 intermediate_results['tenure_p_value'] = np.nan\n",
        "        else: # If 'tenure_years' column is missing or all NaNs\n",
        "            narratives['tenure_summary'] = \"Tenure data ('tenure_years' column) not available or insufficient for analysis.\"\n",
        "            intermediate_results['tenure_stat_sig_text'] = \"\"\n",
        "            intermediate_results['tenure_p_value'] = np.nan\n",
        "\n",
        "        # Ensure intermediate keys exist even if calculations failed\n",
        "        for key in ['avg_tenure', 'prod_avg_tenure', 'cont_avg_tenure', 'diff_tenure']:\n",
        "            if key not in intermediate_results: intermediate_results[key] = np.nan\n",
        "        if 'tenure_stat_sig_text' not in intermediate_results: intermediate_results['tenure_stat_sig_text'] = \"\"\n",
        "        if 'tenure_p_value' not in intermediate_results: intermediate_results['tenure_p_value'] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating tenure narrative: {e}\")\n",
        "        narratives['tenure_summary'] = \"Error generating tenure narrative.\"\n",
        "        intermediate_results['tenure_stat_sig_text'] = \"\"\n",
        "        intermediate_results['tenure_p_value'] = np.nan\n",
        "        # Ensure intermediate keys exist on error\n",
        "        for key in ['avg_tenure', 'prod_avg_tenure', 'cont_avg_tenure', 'diff_tenure']:\n",
        "            if key not in intermediate_results: intermediate_results[key] = np.nan\n",
        "\n",
        "    # --- 3. Org Design Insight (Manager Ratio) ---\n",
        "    try:\n",
        "        # Initialize metrics\n",
        "        prod_mgr_ratio, cont_mgr_ratio = np.nan, np.nan\n",
        "\n",
        "        if 'job_function' in comp_df.columns and 'is_manager' in comp_df.columns:\n",
        "            # Calculate manager counts and total employees per function\n",
        "            prod_mgrs = comp_df[(comp_df['job_function'] == 'Product Development') & comp_df['is_manager']].shape[0]\n",
        "            cont_mgrs = comp_df[(comp_df['job_function'] == 'Content and Studio') & comp_df['is_manager']].shape[0]\n",
        "            prod_total = comp_df[comp_df['job_function'] == 'Product Development'].shape[0]\n",
        "            cont_total = comp_df[comp_df['job_function'] == 'Content and Studio'].shape[0]\n",
        "\n",
        "            # Calculate manager ratios (as percentage), handling division by zero\n",
        "            prod_mgr_ratio = (prod_mgrs / prod_total * 100) if prod_total > 0 else 0\n",
        "            cont_mgr_ratio = (cont_mgrs / cont_total * 100) if cont_total > 0 else 0\n",
        "            intermediate_results['prod_mgr_ratio'] = prod_mgr_ratio\n",
        "            intermediate_results['cont_mgr_ratio'] = cont_mgr_ratio\n",
        "\n",
        "            # Construct the narrative\n",
        "            narratives['org_design_insight'] = (\n",
        "                f\"Organizational design appears to differ based on the ratio of managers within each function.\"\n",
        "                f\"<br><br>Product Development has a manager ratio of {safe_round(prod_mgr_ratio, 1)}%, while Content & Studio has a ratio of {safe_round(cont_mgr_ratio, 1)}%.\"\n",
        "                f\"<br><br>\"\n",
        "                f\"These differences might reflect distinct operational needs or team structures. For instance, technical teams might prioritize a higher ratio of individual contributors for deep technical work, whereas studio teams might require more managers for coordination across diverse creative roles.\"\n",
        "            )\n",
        "        else:\n",
        "             narratives['org_design_insight'] = \"Org design insight requires 'job_function' and 'is_manager' columns.\"\n",
        "             intermediate_results['prod_mgr_ratio'] = np.nan\n",
        "             intermediate_results['cont_mgr_ratio'] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating org design insight: {e}\")\n",
        "        narratives['org_design_insight'] = \"Error generating org design insight.\"\n",
        "        intermediate_results['prod_mgr_ratio'] = np.nan\n",
        "        intermediate_results['cont_mgr_ratio'] = np.nan\n",
        "\n",
        "    # --- 4. Span of Control Summary ---\n",
        "    try:\n",
        "        # Initialize metrics\n",
        "        avg_span, prod_avg_span, cont_avg_span, diff_span = np.nan, np.nan, np.nan, np.nan\n",
        "\n",
        "        if 'is_manager' in comp_df.columns and 'span_of_control' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            # Filter for managers with valid, positive span of control data\n",
        "            managers_df = comp_df[comp_df['is_manager'] & comp_df['span_of_control'].notna() & (comp_df['span_of_control'] > 0)].copy()\n",
        "            managers_df['span_of_control'] = pd.to_numeric(managers_df['span_of_control'], errors='coerce')\n",
        "            managers_df.dropna(subset=['span_of_control'], inplace=True)\n",
        "\n",
        "            if not managers_df.empty:\n",
        "                avg_span = managers_df['span_of_control'].mean()\n",
        "                intermediate_results['avg_span'] = avg_span\n",
        "\n",
        "                # Get span values for each function\n",
        "                prod_span_vals = managers_df[managers_df['job_function'] == 'Product Development']['span_of_control']\n",
        "                cont_span_vals = managers_df[managers_df['job_function'] == 'Content and Studio']['span_of_control']\n",
        "\n",
        "                prod_avg_span = prod_span_vals.mean() # NaN if empty\n",
        "                cont_avg_span = cont_span_vals.mean() # NaN if empty\n",
        "                intermediate_results['prod_avg_span'] = prod_avg_span\n",
        "                intermediate_results['cont_avg_span'] = cont_avg_span\n",
        "\n",
        "                # Calculate difference if both averages are valid\n",
        "                if not np.isnan(prod_avg_span) and not np.isnan(cont_avg_span):\n",
        "                    diff_span = abs(prod_avg_span - cont_avg_span)\n",
        "                    intermediate_results['diff_span'] = diff_span\n",
        "                else:\n",
        "                    intermediate_results['diff_span'] = np.nan\n",
        "\n",
        "                # --- Statistical Test: Span Difference (t-test) ---\n",
        "                span_stat_sig_text = \"\"\n",
        "                try:\n",
        "                    if len(prod_span_vals.dropna()) > 10 and len(cont_span_vals.dropna()) > 10:\n",
        "                        t_stat, p_val = ttest_ind(prod_span_vals.dropna(), cont_span_vals.dropna(), equal_var=False, nan_policy='omit')\n",
        "                        intermediate_results['span_p_value'] = p_val # Store p-value\n",
        "                        if p_val < 0.05:\n",
        "                            span_stat_sig_text = f\"<br><br>A t-test suggests this difference in average span is statistically significant (p = {p_val:.3f}).\"\n",
        "                        else:\n",
        "                            span_stat_sig_text = f\"<br><br>A t-test indicates the difference in average span may not be statistically significant (p = {p_val:.3f}).\"\n",
        "                    else:\n",
        "                        span_stat_sig_text = \"<br><br>Note: Sample sizes (<=10) are too small for reliable span of control significance testing.\"\n",
        "                        intermediate_results['span_p_value'] = np.nan\n",
        "                except Exception as stat_e:\n",
        "                    print(f\"Span t-test failed: {stat_e}\")\n",
        "                    span_stat_sig_text = \"<br><br>Note: Statistical test for span difference unavailable due to error.\"\n",
        "                    intermediate_results['span_p_value'] = np.nan\n",
        "\n",
        "                # Construct the narrative\n",
        "                narratives['span_summary'] = (\n",
        "                    f\"Managers in Product Development have an average span of control of {safe_round(prod_avg_span, 1)} direct reports, \"\n",
        "                    f\"compared to {safe_round(cont_avg_span, 1)} in Content & Studio.\"\n",
        "                    f\"<br><br>\"\n",
        "                    f\"The overall average span for managers with direct reports is {safe_round(avg_span, 1)}.\"\n",
        "                    f\"{span_stat_sig_text}\" # Append significance text\n",
        "                )\n",
        "                intermediate_results['span_stat_sig_text'] = span_stat_sig_text\n",
        "            else:\n",
        "                narratives['span_summary'] = \"No managers with valid, positive span of control data were found for analysis.\"\n",
        "                intermediate_results['avg_span'] = np.nan\n",
        "                intermediate_results['prod_avg_span'] = np.nan\n",
        "                intermediate_results['cont_avg_span'] = np.nan\n",
        "                intermediate_results['diff_span'] = np.nan\n",
        "                intermediate_results['span_stat_sig_text'] = \"\"\n",
        "                intermediate_results['span_p_value'] = np.nan\n",
        "        else:\n",
        "             narratives['span_summary'] = \"Span summary requires 'is_manager', 'span_of_control', and 'job_function' columns.\"\n",
        "             intermediate_results['avg_span'] = np.nan\n",
        "             intermediate_results['prod_avg_span'] = np.nan\n",
        "             intermediate_results['cont_avg_span'] = np.nan\n",
        "             intermediate_results['diff_span'] = np.nan\n",
        "             intermediate_results['span_stat_sig_text'] = \"\"\n",
        "             intermediate_results['span_p_value'] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating span summary: {e}\")\n",
        "        narratives['span_summary'] = \"Error generating span summary.\"\n",
        "        intermediate_results['avg_span'] = np.nan\n",
        "        intermediate_results['prod_avg_span'] = np.nan\n",
        "        intermediate_results['cont_avg_span'] = np.nan\n",
        "        intermediate_results['diff_span'] = np.nan\n",
        "        intermediate_results['span_stat_sig_text'] = \"\"\n",
        "        intermediate_results['span_p_value'] = np.nan\n",
        "\n",
        "    # --- 5. Promotion Insight (Rate by Function) ---\n",
        "    try:\n",
        "        # Initialize metrics\n",
        "        promo_rate_prod, promo_rate_cont = np.nan, np.nan\n",
        "        promo_counts = pd.Series(dtype=int)\n",
        "        total_by_func = pd.Series(dtype=int)\n",
        "\n",
        "        if 'is_promoted' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            # Filter for employees with valid promotion records\n",
        "            promo_df = comp_df[comp_df['is_promoted']].copy()\n",
        "            if not promo_df.empty:\n",
        "                # Calculate total employees per function\n",
        "                total_by_func = comp_df.groupby('job_function', observed=False).size()\n",
        "                # Calculate promoted employees per function\n",
        "                promo_counts = promo_df.groupby('job_function', observed=False).size()\n",
        "                intermediate_results['promo_counts'] = promo_counts\n",
        "                intermediate_results['total_by_func'] = total_by_func\n",
        "\n",
        "                # Get counts, defaulting to 0 if function doesn't exist\n",
        "                prod_total = total_by_func.get('Product Development', 0)\n",
        "                cont_total = total_by_func.get('Content and Studio', 0)\n",
        "                prod_promoted = promo_counts.get('Product Development', 0)\n",
        "                cont_promoted = promo_counts.get('Content and Studio', 0)\n",
        "\n",
        "                # Calculate promotion rates (as percentage), handling division by zero\n",
        "                promo_rate_prod = (prod_promoted / prod_total * 100) if prod_total > 0 else 0\n",
        "                promo_rate_cont = (cont_promoted / cont_total * 100) if cont_total > 0 else 0\n",
        "                intermediate_results['promo_rate_prod'] = promo_rate_prod\n",
        "                intermediate_results['promo_rate_cont'] = promo_rate_cont\n",
        "\n",
        "                # --- Statistical Test: Promotion Rates (Chi-square) ---\n",
        "                promo_rate_stat_sig_text = \"\"\n",
        "                try:\n",
        "                    # Ensure totals are non-zero before creating contingency table\n",
        "                    if prod_total > 0 and cont_total > 0:\n",
        "                        # Calculate non-promoted counts\n",
        "                        prod_not_promoted = prod_total - prod_promoted\n",
        "                        cont_not_promoted = cont_total - cont_promoted\n",
        "                        contingency_table = [[prod_promoted, prod_not_promoted],\n",
        "                                             [cont_promoted, cont_not_promoted]]\n",
        "\n",
        "                        # Check for sufficient counts (>= 5 in all cells)\n",
        "                        if all(count >= 5 for row in contingency_table for count in row):\n",
        "                            chi2, p_val, _, _ = chi2_contingency(contingency_table)\n",
        "                            intermediate_results['promo_rate_p_value'] = p_val # Store p-value\n",
        "                            if p_val < 0.05:\n",
        "                                promo_rate_stat_sig_text = f\"<br><br>A chi-square test (p = {p_val:.3f}) suggests this difference in promotion rates is statistically significant.\"\n",
        "                            else:\n",
        "                                promo_rate_stat_sig_text = f\"<br><br>A chi-square test (p = {p_val:.3f}) indicates the difference in promotion rates may not be statistically significant.\"\n",
        "                        else:\n",
        "                            promo_rate_stat_sig_text = \"<br><br>Note: Data is insufficient (some group counts < 5) for a reliable chi-square test on promotion rates.\"\n",
        "                            intermediate_results['promo_rate_p_value'] = np.nan\n",
        "                    else:\n",
        "                        promo_rate_stat_sig_text = \"<br><br>Note: Cannot perform chi-square test on promotion rates as one or both functions have zero total employees.\"\n",
        "                        intermediate_results['promo_rate_p_value'] = np.nan\n",
        "\n",
        "                except Exception as stat_e:\n",
        "                    print(f\"Promotion rate Chi-square test failed: {stat_e}\")\n",
        "                    promo_rate_stat_sig_text = \"<br><br>Note: Statistical test for promotion rates unavailable due to error.\"\n",
        "                    intermediate_results['promo_rate_p_value'] = np.nan\n",
        "\n",
        "                # Construct the narrative\n",
        "                narratives['promotion_insight'] = (\n",
        "                    f\"Overall promotion rates observed in the data are: \"\n",
        "                    f\"Product Development at {safe_round(promo_rate_prod, 1)}% and Content & Studio at {safe_round(promo_rate_cont, 1)}%.\"\n",
        "                    f\"<br><br>\"\n",
        "                    f\"Differences in promotion rates could reflect variations in growth trajectories, role structures, or performance cycles between the functions.\"\n",
        "                    f\"{promo_rate_stat_sig_text}\" # Append significance text\n",
        "                )\n",
        "                intermediate_results['promo_rate_stat_sig_text'] = promo_rate_stat_sig_text\n",
        "            else:\n",
        "                narratives['promotion_insight'] = \"No employees with valid promotion records were found in the data to analyze rates.\"\n",
        "                intermediate_results['promo_rate_prod'] = np.nan\n",
        "                intermediate_results['promo_rate_cont'] = np.nan\n",
        "                intermediate_results['promo_rate_stat_sig_text'] = \"\"\n",
        "                intermediate_results['promo_rate_p_value'] = np.nan\n",
        "        else:\n",
        "            narratives['promotion_insight'] = \"Promotion insight requires 'is_promoted' and 'job_function' columns.\"\n",
        "            intermediate_results['promo_rate_prod'] = np.nan\n",
        "            intermediate_results['promo_rate_cont'] = np.nan\n",
        "            intermediate_results['promo_rate_stat_sig_text'] = \"\"\n",
        "            intermediate_results['promo_rate_p_value'] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotion insight: {e}\")\n",
        "        narratives['promotion_insight'] = \"Error generating promotion insight.\"\n",
        "        intermediate_results['promo_rate_prod'] = np.nan\n",
        "        intermediate_results['promo_rate_cont'] = np.nan\n",
        "        intermediate_results['promo_rate_stat_sig_text'] = \"\"\n",
        "        intermediate_results['promo_rate_p_value'] = np.nan\n",
        "\n",
        "    # --- 6. Promotions Trend Summary (by Year) ---\n",
        "    try:\n",
        "        if 'is_promoted' in comp_df.columns and 'promotion_year' in comp_df.columns:\n",
        "            # Filter for promoted employees with valid, numeric promotion year\n",
        "            promo_trend_df = comp_df[comp_df['is_promoted'] & comp_df['promotion_year'].notna()].copy()\n",
        "            promo_trend_df['promotion_year'] = pd.to_numeric(promo_trend_df['promotion_year'], errors='coerce')\n",
        "            promo_trend_df.dropna(subset=['promotion_year'], inplace=True)\n",
        "\n",
        "            if not promo_trend_df.empty:\n",
        "                # Group by year and count promotions\n",
        "                trend = promo_trend_df.groupby('promotion_year').size()\n",
        "                if not trend.empty:\n",
        "                    peak_year = trend.idxmax() # Year with the highest number of promotions\n",
        "                    narratives['promotions_trend_summary'] = (\n",
        "                        f\"Analysis of promotion data shows activity peaked in {int(peak_year)} with {trend[peak_year]:,} recorded promotions.\"\n",
        "                        f\"<br><br>Year-over-year trends in promotion volume can be influenced by factors such as large hiring cohorts reaching promotion eligibility, changes in promotion policies, or shifts in business growth and investment.\"\n",
        "                    )\n",
        "                else:\n",
        "                     narratives['promotions_trend_summary'] = \"No promotion data found after grouping by year.\"\n",
        "            else:\n",
        "                narratives['promotions_trend_summary'] = \"No valid promotion data (is_promoted=True and numeric non-null promotion_year) available for trend analysis.\"\n",
        "        else:\n",
        "            narratives['promotions_trend_summary'] = \"Promotion trend summary requires 'is_promoted' and 'promotion_year' columns.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotions trend summary: {e}\")\n",
        "        narratives['promotions_trend_summary'] = \"Error generating promotions trend summary.\"\n",
        "\n",
        "    # --- 7. Regression-based Insight: Time to Promotion ---\n",
        "    # Reimplemented OLS regression logic\n",
        "    try:\n",
        "        # Check for necessary columns\n",
        "        required_cols = ['time_to_promotion', 'job_function', 'job_level_title']\n",
        "        if all(col in comp_df.columns for col in required_cols):\n",
        "            # Prepare data: drop NaNs in relevant columns first\n",
        "            reg_df = comp_df[required_cols].dropna().copy()\n",
        "\n",
        "            # Convert time_to_promotion to numeric *after* initial dropna\n",
        "            reg_df['time_to_promotion'] = pd.to_numeric(reg_df['time_to_promotion'], errors='coerce')\n",
        "            reg_df.dropna(subset=['time_to_promotion'], inplace=True) # Drop if conversion failed\n",
        "\n",
        "            # Check if sufficient data remains (e.g., > 50 for reliability)\n",
        "            if len(reg_df) > 50:\n",
        "                try:\n",
        "                    # Create dummy variables for categorical features\n",
        "                    # drop_first=True avoids multicollinearity\n",
        "                    reg_df_dummies = pd.get_dummies(reg_df, columns=['job_function', 'job_level_title'], drop_first=True, dummy_na=False, dtype=float)\n",
        "\n",
        "                    # Define independent variables (X) and dependent variable (y)\n",
        "                    y = reg_df_dummies['time_to_promotion']\n",
        "                    X = reg_df_dummies.drop(columns=['time_to_promotion'])\n",
        "                    X = sm.add_constant(X, has_constant='add') # Add intercept\n",
        "\n",
        "                    # Ensure X and y are purely numeric and aligned (handle potential NaNs introduced by dummies/constant)\n",
        "                    X = X.astype(float) # Ensure all X columns are float\n",
        "                    y = y.astype(float)\n",
        "                    combined = pd.concat([y, X], axis=1).dropna() # Drop rows with any NaNs\n",
        "\n",
        "                    if len(combined) > 10: # Check if enough data remains after cleaning\n",
        "                        y_clean = combined['time_to_promotion']\n",
        "                        X_clean = combined.drop(columns=['time_to_promotion'])\n",
        "\n",
        "                        # Fit the Ordinary Least Squares (OLS) model\n",
        "                        model = sm.OLS(y_clean, X_clean).fit()\n",
        "                        intermediate_results['ttp_regression_model'] = model # Store model results\n",
        "\n",
        "                        # Check if the specific predictor exists (depends on base category)\n",
        "                        # Assumes 'Content and Studio' is the base category for job_function\n",
        "                        predictor_name = 'job_function_Product Development'\n",
        "                        if predictor_name in model.params:\n",
        "                            beta = model.params[predictor_name] # Coefficient\n",
        "                            pval = model.pvalues[predictor_name] # P-value\n",
        "                            intermediate_results['ttp_regression_beta'] = beta\n",
        "                            intermediate_results['ttp_regression_pval'] = pval\n",
        "\n",
        "                            if pval < 0.05: # Check for statistical significance\n",
        "                                direction = 'faster' if beta < 0 else 'slower'\n",
        "                                narratives['promotion_regression_insight'] = (\n",
        "                                    f\"Controlling for job level, being in Product Development is associated with statistically significantly {direction} promotions (average difference of {abs(beta):.2f} years, p = {pval:.3f}).\"\n",
        "                                    f\"<br><br>This suggests that function-specific factors, beyond just the assigned job level, may influence the typical time it takes for an employee to be promoted in these areas.\"\n",
        "                                )\n",
        "                            else:\n",
        "                                narratives['promotion_regression_insight'] = (\n",
        "                                    f\"After controlling for job level, the analysis did not find a statistically significant difference (p = {pval:.3f}) in the average time to promotion between Product Development and Content & Studio.\"\n",
        "                                )\n",
        "                        else:\n",
        "                            narratives['promotion_regression_insight'] = f\"Regression analysis completed, but the specific predictor '{predictor_name}' was not included in the final model, possibly due to data characteristics (e.g., collinearity or lack of variation).\"\n",
        "                            intermediate_results['ttp_regression_beta'] = np.nan\n",
        "                            intermediate_results['ttp_regression_pval'] = np.nan\n",
        "                    else:\n",
        "                         narratives['promotion_regression_insight'] = \"Insufficient data remaining after cleaning numeric types required for regression analysis.\"\n",
        "                         intermediate_results['ttp_regression_beta'] = np.nan\n",
        "                         intermediate_results['ttp_regression_pval'] = np.nan\n",
        "                except Exception as model_e:\n",
        "                     print(f\"Error during regression model fitting or analysis: {model_e}\")\n",
        "                     traceback.print_exc()\n",
        "                     narratives['promotion_regression_insight'] = f\"An error occurred during the regression analysis: {model_e}\"\n",
        "                     intermediate_results['ttp_regression_beta'] = np.nan\n",
        "                     intermediate_results['ttp_regression_pval'] = np.nan\n",
        "            else:\n",
        "                narratives['promotion_regression_insight'] = f\"Insufficient data ({len(reg_df)} valid rows) to run regression reliably after handling missing values.\"\n",
        "                intermediate_results['ttp_regression_beta'] = np.nan\n",
        "                intermediate_results['ttp_regression_pval'] = np.nan\n",
        "        else:\n",
        "            narratives['promotion_regression_insight'] = f\"Regression insight requires columns: {', '.join(required_cols)}.\"\n",
        "            intermediate_results['ttp_regression_beta'] = np.nan\n",
        "            intermediate_results['ttp_regression_pval'] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotion regression insight setup: {e}\")\n",
        "        traceback.print_exc()\n",
        "        narratives['promotion_regression_insight'] = \"Error setting up promotion regression insight.\"\n",
        "        intermediate_results['ttp_regression_beta'] = np.nan\n",
        "        intermediate_results['ttp_regression_pval'] = np.nan\n",
        "\n",
        "    # --- 8. Executive Summary Findings Synthesis ---\n",
        "    # Reimplemented dynamic synthesis based on intermediate results\n",
        "    try:\n",
        "        exec_points = []\n",
        "        # Retrieve results from intermediate storage\n",
        "        diff_tenure_local = intermediate_results.get('diff_tenure', np.nan)\n",
        "        tenure_pval_local = intermediate_results.get('tenure_p_value', np.nan)\n",
        "        prod_avg_tenure_local = intermediate_results.get('prod_avg_tenure', np.nan)\n",
        "        cont_avg_tenure_local = intermediate_results.get('cont_avg_tenure', np.nan)\n",
        "\n",
        "        diff_span_local = intermediate_results.get('diff_span', np.nan)\n",
        "        span_pval_local = intermediate_results.get('span_p_value', np.nan)\n",
        "        prod_avg_span_local = intermediate_results.get('prod_avg_span', np.nan)\n",
        "        cont_avg_span_local = intermediate_results.get('cont_avg_span', np.nan)\n",
        "\n",
        "        promo_rate_pval_local = intermediate_results.get('promo_rate_p_value', np.nan)\n",
        "        promo_rate_prod_local = intermediate_results.get('promo_rate_prod', np.nan)\n",
        "        promo_rate_cont_local = intermediate_results.get('promo_rate_cont', np.nan)\n",
        "\n",
        "        ttp_regr_beta_local = intermediate_results.get('ttp_regression_beta', np.nan)\n",
        "        ttp_regr_pval_local = intermediate_results.get('ttp_regression_pval', np.nan)\n",
        "\n",
        "        # Check Tenure Significance (p < 0.05 and difference >= 0.5 years)\n",
        "        if not np.isnan(tenure_pval_local) and tenure_pval_local < 0.05 and not np.isnan(diff_tenure_local) and diff_tenure_local >= 0.5:\n",
        "             exec_points.append(f\"Average tenure differs significantly (p={tenure_pval_local:.3f}) between Product Development ({safe_round(prod_avg_tenure_local, 1)} yrs) and Content & Studio ({safe_round(cont_avg_tenure_local, 1)} yrs).\")\n",
        "\n",
        "        # Check Span Significance (p < 0.05 and difference >= 1.0 report)\n",
        "        if not np.isnan(span_pval_local) and span_pval_local < 0.05 and not np.isnan(diff_span_local) and diff_span_local >= 1.0:\n",
        "            exec_points.append(f\"Average manager span of control differs significantly (p={span_pval_local:.3f}) between Product Development ({safe_round(prod_avg_span_local, 1)}) and Content & Studio ({safe_round(cont_avg_span_local, 1)}).\")\n",
        "\n",
        "        # Check Promotion Rate Significance (p < 0.05)\n",
        "        if not np.isnan(promo_rate_pval_local) and promo_rate_pval_local < 0.05:\n",
        "             exec_points.append(f\"Promotion rates differ significantly (p={promo_rate_pval_local:.3f}): Product Development ({safe_round(promo_rate_prod_local, 1)}%) vs Content & Studio ({safe_round(promo_rate_cont_local, 1)}%).\")\n",
        "\n",
        "        # Check Promotion Regression Significance (p < 0.05)\n",
        "        if not np.isnan(ttp_regr_pval_local) and ttp_regr_pval_local < 0.05:\n",
        "             direction = 'faster' if ttp_regr_beta_local < 0 else 'slower'\n",
        "             years_diff = abs(ttp_regr_beta_local)\n",
        "             exec_points.append(f\"After controlling for level, Product Development promotes significantly {direction} (by {years_diff:.2f} yrs, p={ttp_regr_pval_local:.3f}) compared to Content & Studio.\")\n",
        "\n",
        "        # Construct the final summary message\n",
        "        if exec_points:\n",
        "            # Use HTML list for better formatting\n",
        "            findings_list = \"\".join([f\"<li>{point}</li>\" for point in exec_points])\n",
        "            narratives['exec_summary_findings'] = (\n",
        "                \"Key statistically significant differences (p < 0.05) meeting analysis thresholds were observed between functions:\"\n",
        "                f\"<ul>{findings_list}</ul>\"\n",
        "            )\n",
        "        else:\n",
        "            narratives['exec_summary_findings'] = \"No statistically significant differences meeting the defined thresholds were found in the comparisons of tenure, span of control, promotion rates, or promotion timing (controlling for level) between Product Development and Content & Studio.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error synthesizing exec findings: {e}\")\n",
        "        narratives['exec_summary_findings'] = \"Error synthesizing executive summary findings.\"\n",
        "\n",
        "    # Add intermediate results to the main narratives dictionary\n",
        "    narratives.update(intermediate_results)\n",
        "\n",
        "    return narratives\n",
        "\n",
        "# --- Detailed Narrative Generation Function ---\n",
        "\n",
        "def generate_detailed_narratives(df, bad_dates_json_str=\"[]\", promo_issue_json_str=\"[]\"):\n",
        "    \"\"\"\n",
        "    Generates detailed narrative insights matching the dashboard template keys.\n",
        "\n",
        "    Builds upon the output of `generate_narrative_summaries` by adding more\n",
        "    granular insights, formatting text with HTML breaks (<br>), and structuring\n",
        "    content for specific dashboard sections (Composition, Tenure, Span, Promotions,\n",
        "    Hiring, Time to Promotion, Diagnostics, Strategic). Includes data quality\n",
        "    summaries based on provided JSON strings and generates conditional strategic\n",
        "    recommendations.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The primary processed DataFrame from `load_data`.\n",
        "        bad_dates_json_str (str, optional): JSON string listing records with\n",
        "                                             date formatting issues. Defaults to \"[]\".\n",
        "        promo_issue_json_str (str, optional): JSON string listing records with\n",
        "                                              promotion timing issues. Defaults to \"[]\".\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing narrative strings keyed to match the\n",
        "              HTML template's expected variables. Returns the initial error\n",
        "              dictionary if `generate_narrative_summaries` failed.\n",
        "    \"\"\"\n",
        "    # Start with the basic summaries and intermediate results from Part 1 function\n",
        "    # This dictionary already contains initial narratives and calculation results.\n",
        "    narratives = generate_narrative_summaries(df)\n",
        "\n",
        "    # Exit early if the initial summary generation failed\n",
        "    if 'error' in narratives:\n",
        "        print(\"Error detected in initial summary generation. Skipping detailed narratives.\")\n",
        "        # Clean up intermediate keys potentially added before the error\n",
        "        keys_to_remove = {k for k in narratives if k != 'error'}\n",
        "        for key in keys_to_remove:\n",
        "            narratives.pop(key, None)\n",
        "        return narratives\n",
        "\n",
        "    # Re-filter data consistently (focus on Product Dev and Content/Studio)\n",
        "    comp_df = df[df['job_function'].isin(['Product Development', 'Content and Studio'])].copy()\n",
        "    if comp_df.empty:\n",
        "        # Fallback to original df if filtering removes all data\n",
        "        comp_df = df.copy()\n",
        "\n",
        "    if comp_df.empty:\n",
        "         print(\"Warning: No data available for detailed narrative generation after filtering.\")\n",
        "         # Return the narratives dict which might contain summaries based on full data if fallback occurred\n",
        "         return narratives # Return summaries generated so far\n",
        "\n",
        "    # --- Generate Detailed Narratives for Template Keys ---\n",
        "\n",
        "    # == Composition Section ==\n",
        "    # 'composition_summary': Already generated by generate_narrative_summaries.\n",
        "    # 'org_design_insight': Already generated by generate_narrative_summaries.\n",
        "\n",
        "    # --- Roles Insight (Detailed IC/Manager Mix) ---\n",
        "    try:\n",
        "        if 'job_function' in comp_df.columns and 'role' in comp_df.columns:\n",
        "            # Calculate role percentages per function\n",
        "            roles_by_func = comp_df.groupby(['job_function', 'role'], observed=False).size().unstack(fill_value=0)\n",
        "            roles_pct = roles_by_func.apply(lambda x: x / x.sum() * 100 if x.sum() > 0 else x, axis=1)\n",
        "\n",
        "            # Extract percentages, handling missing data\n",
        "            prod_ic_pct = roles_pct.loc['Product Development', 'Individual Contributor'] if ('Product Development' in roles_pct.index and 'Individual Contributor' in roles_pct.columns) else np.nan\n",
        "            cont_ic_pct = roles_pct.loc['Content and Studio', 'Individual Contributor'] if ('Content and Studio' in roles_pct.index and 'Individual Contributor' in roles_pct.columns) else np.nan\n",
        "\n",
        "            # Retrieve the statistical significance text generated earlier\n",
        "            roles_sig_text = narratives.get('roles_stat_sig_text', ' Statistical test result unavailable.')\n",
        "\n",
        "            # Construct the narrative\n",
        "            narratives['roles_insight'] = (\n",
        "                f\"Product Development and Content & Studio exhibit distinct ratios of Individual Contributors (ICs) to People Managers.\"\n",
        "                f\"<br><br>\"\n",
        "                f\"Product Development comprises {safe_round(prod_ic_pct, 0)}% ICs, compared to {safe_round(cont_ic_pct, 0)}% in Content & Studio.\"\n",
        "                f\"<br>\" # Single break before the interpretation\n",
        "                f\"This difference may reflect fundamental variations in how technical work (potentially favoring deeper IC roles) and creative/studio work (potentially requiring more coordination layers) are structured.\"\n",
        "                f\"{roles_sig_text}\" # Append the pre-formatted statistical test result\n",
        "            )\n",
        "        else:\n",
        "             narratives['roles_insight'] = \"Roles insight requires 'job_function' and 'role' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating roles_insight: {e}\")\n",
        "        narratives['roles_insight'] = \"Error generating roles insight.\"\n",
        "\n",
        "    # --- Leadership Insight (Director/VP Distribution) ---\n",
        "    try:\n",
        "        if 'job_level_title' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            leadership_levels = ['Director', 'Vice President']\n",
        "            leaders_df = comp_df[comp_df['job_level_title'].isin(leadership_levels)]\n",
        "\n",
        "            if not leaders_df.empty:\n",
        "                # Count leaders in each target function\n",
        "                prod_leaders = leaders_df[leaders_df['job_function'] == 'Product Development'].shape[0]\n",
        "                cont_leaders = leaders_df[leaders_df['job_function'] == 'Content and Studio'].shape[0]\n",
        "                total_leaders_in_scope = prod_leaders + cont_leaders\n",
        "\n",
        "                # Calculate percentage distribution *among these leaders*\n",
        "                prod_pct_of_leaders = (prod_leaders / total_leaders_in_scope * 100) if total_leaders_in_scope > 0 else 0\n",
        "                cont_pct_of_leaders = (cont_leaders / total_leaders_in_scope * 100) if total_leaders_in_scope > 0 else 0\n",
        "\n",
        "                # --- Statistical Test: Proportion of Leaders (Chi-square) ---\n",
        "                leader_prop_stat_text = \"\"\n",
        "                try:\n",
        "                    # Get total employees in each function for the test\n",
        "                    prod_total_func = comp_df[comp_df['job_function'] == 'Product Development'].shape[0]\n",
        "                    cont_total_func = comp_df[comp_df['job_function'] == 'Content and Studio'].shape[0]\n",
        "\n",
        "                    if prod_total_func > 0 and cont_total_func > 0:\n",
        "                        # Calculate non-leaders in each function\n",
        "                        prod_non_leaders = prod_total_func - prod_leaders\n",
        "                        cont_non_leaders = cont_total_func - cont_leaders\n",
        "                        # Contingency table: [Leaders, Non-Leaders] x [Prod, Content]\n",
        "                        contingency = [[prod_leaders, prod_non_leaders], [cont_leaders, cont_non_leaders]]\n",
        "\n",
        "                        # Check counts for validity\n",
        "                        if all(count >= 5 for row in contingency for count in row):\n",
        "                            chi2, p_val, _, _ = chi2_contingency(contingency)\n",
        "                            significance = \"differs significantly\" if p_val < 0.05 else \"does not differ significantly\"\n",
        "                            leader_prop_stat_text = f\"<br><br>A chi-square test (p = {p_val:.3f}) suggests the proportion of senior leaders ({', '.join(leadership_levels)}) {significance} between these functions.\"\n",
        "                        else:\n",
        "                            leader_prop_stat_text = f\"<br><br>Note: Data is insufficient (some group counts < 5) to reliably test the significance of the leadership proportion difference.\"\n",
        "                    else:\n",
        "                        leader_prop_stat_text = \"<br><br>Note: Cannot perform statistical test on leadership proportion as one or both functions have zero employees.\"\n",
        "                except Exception as stat_e:\n",
        "                    print(f\"Chi-square test for leadership proportion failed: {stat_e}\")\n",
        "                    leader_prop_stat_text = \"<br><br>Note: An error occurred during the statistical test for leadership proportion.\"\n",
        "\n",
        "                # Construct the narrative\n",
        "                narratives['leadership_insight'] = (\n",
        "                    f\"Among the senior leaders ({', '.join(leadership_levels)}) specifically within Product Development and Content & Studio, \"\n",
        "                    f\"{safe_round(prod_pct_of_leaders, 0)}% are affiliated with Product Development, while {safe_round(cont_pct_of_leaders, 0)}% are with Content & Studio.\"\n",
        "                    f\"<br><br>\"\n",
        "                    f\"This distribution may indicate differences in the relative scale or hierarchical structure of leadership within these two core functions.\"\n",
        "                    f\"{leader_prop_stat_text}\" # Append significance text\n",
        "                )\n",
        "            else:\n",
        "                 narratives['leadership_insight'] = f\"No employees were found at the specified leadership levels ({', '.join(leadership_levels)}) within the analyzed functions.\"\n",
        "        else:\n",
        "            narratives['leadership_insight'] = \"Leadership insight requires 'job_level_title' and 'job_function' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating leadership_insight: {e}\")\n",
        "        narratives['leadership_insight'] = \"Error generating leadership insight.\"\n",
        "\n",
        "\n",
        "    # == Tenure Section ==\n",
        "    # 'tenure_summary': Already generated (Average Tenure / Density).\n",
        "\n",
        "    # --- Detailed Tenure Insight (Median and Long Tenure) ---\n",
        "    try:\n",
        "        if 'tenure_years' in comp_df.columns and comp_df['tenure_years'].notna().any():\n",
        "            # Use NaN-filtered, numeric tenure data\n",
        "            tenure_df = comp_df[comp_df['tenure_years'].notna()].copy()\n",
        "            tenure_df['tenure_years'] = pd.to_numeric(tenure_df['tenure_years'], errors='coerce')\n",
        "            tenure_df.dropna(subset=['tenure_years'], inplace=True)\n",
        "\n",
        "            if not tenure_df.empty:\n",
        "                # Calculate median tenure per function\n",
        "                prod_median = tenure_df[tenure_df['job_function'] == 'Product Development']['tenure_years'].median()\n",
        "                cont_median = tenure_df[tenure_df['job_function'] == 'Content and Studio']['tenure_years'].median()\n",
        "\n",
        "                # Calculate percentage with 4+ years tenure per function\n",
        "                prod_4yr_pct = (tenure_df[tenure_df['job_function'] == 'Product Development']['tenure_years'] >= 4).mean() * 100\n",
        "                cont_4yr_pct = (tenure_df[tenure_df['job_function'] == 'Content and Studio']['tenure_years'] >= 4).mean() * 100\n",
        "\n",
        "                # Compare medians if both are valid numbers\n",
        "                if not np.isnan(prod_median) and not np.isnan(cont_median):\n",
        "                    median_diff = abs(prod_median - cont_median)\n",
        "                    if median_diff < 0.5: # Threshold for similarity\n",
        "                        narratives['tenure_insight'] = (\n",
        "                            f\"Median tenure shows similarity across functions (Product Development: {safe_round(prod_median, 1)} years, Content & Studio: {safe_round(cont_median, 1)} years).\"\n",
        "                            f\"<br><br>\"\n",
        "                            f\"The proportion of employees with four or more years of tenure is {safe_round(prod_4yr_pct, 0)}% in Product Development and {safe_round(cont_4yr_pct, 0)}% in Content & Studio.\"\n",
        "                        )\n",
        "                    else: # Notable difference\n",
        "                        narratives['tenure_insight'] = (\n",
        "                            f\"Median tenure differs between functions: Product Development is at {safe_round(prod_median, 1)} years, while Content & Studio is at {safe_round(cont_median, 1)} years.\"\n",
        "                            f\"<br><br>\"\n",
        "                            f\"Regarding longer-serving employees (4+ years tenure), they constitute {safe_round(prod_4yr_pct, 0)}% of Product Development and {safe_round(cont_4yr_pct, 0)}% of Content & Studio.\"\n",
        "                        )\n",
        "                else: # Handle cases where median calculation failed for one/both\n",
        "                     narratives['tenure_insight'] = \"Median tenure comparison is not possible due to missing or insufficient data in one or both functions.\"\n",
        "            else:\n",
        "                narratives['tenure_insight'] = \"No valid numeric tenure data available for detailed insight calculation.\"\n",
        "        else:\n",
        "            narratives['tenure_insight'] = \"Detailed tenure insight requires the 'tenure_years' column with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating detailed tenure insight: {e}\")\n",
        "        narratives['tenure_insight'] = \"Error generating detailed tenure insight.\"\n",
        "\n",
        "    # --- Tenure by Level Insight ---\n",
        "    try:\n",
        "        if 'tenure_years' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Use NaN-filtered, numeric tenure data\n",
        "            tenure_level_df = comp_df[comp_df['tenure_years'].notna()].copy()\n",
        "            tenure_level_df['tenure_years'] = pd.to_numeric(tenure_level_df['tenure_years'], errors='coerce')\n",
        "            tenure_level_df.dropna(subset=['tenure_years'], inplace=True)\n",
        "\n",
        "            if not tenure_level_df.empty:\n",
        "                # Group by cleaned job level title and calculate mean tenure\n",
        "                avg_tenure_by_level = tenure_level_df.groupby('job_level_title')['tenure_years'].mean().round(1)\n",
        "                # Exclude 'Unknown' level and sort by tenure (descending)\n",
        "                avg_tenure_by_level = avg_tenure_by_level[avg_tenure_by_level.index != 'Unknown'].sort_values(ascending=False)\n",
        "\n",
        "                if not avg_tenure_by_level.empty:\n",
        "                    # Format as an HTML list for the narrative\n",
        "                    level_tenure_items = [f\"<li>{lvl}: {val} years</li>\" for lvl, val in avg_tenure_by_level.items()]\n",
        "                    level_tenure_formatted_list = f\"<ul>{''.join(level_tenure_items)}</ul>\"\n",
        "                    narratives['tenure_level_insight'] = (\n",
        "                        f\"Average tenure generally increases with job level, reflecting experience accumulation. Representative average tenures include:\"\n",
        "                        f\"{level_tenure_formatted_list}\"\n",
        "                    )\n",
        "                else:\n",
        "                    narratives['tenure_level_insight'] = \"Could not calculate average tenure by level after filtering for known levels.\"\n",
        "            else:\n",
        "                narratives['tenure_level_insight'] = \"No valid numeric tenure data found to analyze tenure by job level.\"\n",
        "        else:\n",
        "            narratives['tenure_level_insight'] = \"Tenure by level insight requires 'tenure_years' and 'job_level_title' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating tenure_level_insight: {e}\")\n",
        "        narratives['tenure_level_insight'] = \"Error generating tenure by level insight.\"\n",
        "\n",
        "\n",
        "    # == Span Section ==\n",
        "    # 'span_summary': Already generated (Average Span Comparison).\n",
        "\n",
        "    # --- Span by Level Insight ---\n",
        "    try:\n",
        "        if 'span_of_control' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Filter for managers with valid, positive span\n",
        "            level_span_df = comp_df[comp_df['is_manager'] & comp_df['span_of_control'].notna() & (comp_df['span_of_control'] > 0)].copy()\n",
        "            level_span_df['span_of_control'] = pd.to_numeric(level_span_df['span_of_control'], errors='coerce')\n",
        "            level_span_df.dropna(subset=['span_of_control'], inplace=True)\n",
        "\n",
        "            if not level_span_df.empty:\n",
        "                # Group by level and calculate average span\n",
        "                avg_span_by_level = level_span_df.groupby('job_level_title')['span_of_control'].mean().round(1)\n",
        "                # Filter for typical manager levels and sort\n",
        "                manager_levels_ordered = ['Manager', 'Director', 'Vice President']\n",
        "                avg_span_by_level = avg_span_by_level.reindex(manager_levels_ordered).dropna()\n",
        "\n",
        "                if not avg_span_by_level.empty:\n",
        "                    # Format as HTML list\n",
        "                    level_span_items = [f\"<li>{level}: {val} reports</li>\" for level, val in avg_span_by_level.items()]\n",
        "                    level_span_formatted_list = f\"<ul>{''.join(level_span_items)}</ul>\"\n",
        "                    narratives['span_level_insight'] = (\n",
        "                        f\"Average span of control tends to increase with managerial level. Sample averages for managers with direct reports:\"\n",
        "                        f\"{level_span_formatted_list}\"\n",
        "                    )\n",
        "                else:\n",
        "                    narratives['span_level_insight'] = \"Could not calculate average span by manager level after filtering.\"\n",
        "            else:\n",
        "                narratives['span_level_insight'] = \"No managers with valid, positive span of control data were found.\"\n",
        "        else:\n",
        "            narratives['span_level_insight'] = \"Span by level insight requires 'span_of_control', 'job_level_title', and 'is_manager' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating span_level_insight: {e}\")\n",
        "        narratives['span_level_insight'] = \"Error generating span by level insight.\"\n",
        "\n",
        "    # --- Combined Span Control Insight ---\n",
        "    # This combines the average span comparison and the span-by-level insight.\n",
        "    try:\n",
        "        span_summary_text = narratives.get('span_summary', \"\")\n",
        "        span_level_text = narratives.get('span_level_insight', \"\")\n",
        "        combined_span_text = \"\"\n",
        "\n",
        "        # Add summary text if valid\n",
        "        if span_summary_text and not span_summary_text.startswith(\"Error\") and not span_summary_text.startswith(\"No managers\"):\n",
        "            combined_span_text += span_summary_text\n",
        "\n",
        "        # Add level text if valid, adding spacing\n",
        "        if span_level_text and not span_level_text.startswith(\"Error\") and not span_level_text.startswith(\"Could not\") and not span_level_text.startswith(\"No managers\"):\n",
        "             if combined_span_text: # Add breaks if combining with previous text\n",
        "                 combined_span_text += f\"<br><br>Furthermore, {span_level_text}\"\n",
        "             else:\n",
        "                 combined_span_text = span_level_text # Use directly if it's the only text\n",
        "\n",
        "        if combined_span_text:\n",
        "             narratives['span_control_insight'] = combined_span_text\n",
        "        else:\n",
        "             # Provide a fallback if both underlying insights failed\n",
        "             narratives['span_control_insight'] = \"Detailed span of control insights could not be generated due to missing or insufficient data.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating span_control_insight: {e}\")\n",
        "        narratives['span_control_insight'] = \"Error combining span insights.\"\n",
        "\n",
        "\n",
        "    # == Promotions Section ==\n",
        "    # 'promotion_insight': Already generated (Rate Comparison).\n",
        "    # 'promotions_trend_summary': Already generated (Peak Year).\n",
        "\n",
        "    # --- Promotion Seasonality Insight ---\n",
        "    try:\n",
        "        if 'promotion_date_dt' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            # Ensure the date column is actually datetime type\n",
        "            if pd.api.types.is_datetime64_any_dtype(comp_df['promotion_date_dt']):\n",
        "                # Filter for records with valid promotion dates\n",
        "                promo_quarters_df = comp_df[comp_df['promotion_date_dt'].notna()].copy()\n",
        "                if not promo_quarters_df.empty:\n",
        "                    # Extract quarter and group by function/quarter\n",
        "                    promo_quarters_df['promo_q'] = 'Q' + promo_quarters_df['promotion_date_dt'].dt.quarter.astype(str)\n",
        "                    promo_q_counts = promo_quarters_df.groupby(['job_function', 'promo_q'], observed=False).size().unstack(fill_value=0)\n",
        "\n",
        "                    # Determine peak quarter for each function\n",
        "                    prod_peak_q_str = \"\"\n",
        "                    cont_peak_q_str = \"\"\n",
        "                    if 'Product Development' in promo_q_counts.index and promo_q_counts.loc['Product Development'].sum() > 0:\n",
        "                        prod_peak_q = promo_q_counts.loc['Product Development'].idxmax()\n",
        "                        prod_peak_q_str = f\"{prod_peak_q} for Product Development\"\n",
        "                    if 'Content and Studio' in promo_q_counts.index and promo_q_counts.loc['Content and Studio'].sum() > 0:\n",
        "                        cont_peak_q = promo_q_counts.loc['Content and Studio'].idxmax()\n",
        "                        cont_peak_q_str = f\"{cont_peak_q} for Content & Studio\"\n",
        "\n",
        "                    # Construct narrative based on available peak data\n",
        "                    if prod_peak_q_str and cont_peak_q_str:\n",
        "                         narratives['promotion_seasonality_insight'] = f\"Promotion activity exhibits seasonality, tending to peak in {prod_peak_q_str} and {cont_peak_q_str}.\" \\\n",
        "                                                                        f\"<br><br>This pattern may align with annual performance review cycles, planning periods, or other business cadences.\"\n",
        "                    elif prod_peak_q_str:\n",
        "                         narratives['promotion_seasonality_insight'] = f\"Promotion activity tends to peak in {prod_peak_q_str}. Data for Content & Studio peak was unavailable or insufficient.\"\n",
        "                    elif cont_peak_q_str:\n",
        "                         narratives['promotion_seasonality_insight'] = f\"Promotion activity tends to peak in {cont_peak_q_str}. Data for Product Development peak was unavailable or insufficient.\"\n",
        "                    else:\n",
        "                         narratives['promotion_seasonality_insight'] = \"Insufficient promotion data available to determine peak quarters for either function.\"\n",
        "                else:\n",
        "                    narratives['promotion_seasonality_insight'] = \"No valid promotion dates found for seasonality analysis.\"\n",
        "            else:\n",
        "                 narratives['promotion_seasonality_insight'] = \"Promotion seasonality analysis requires the 'promotion_date_dt' column to be of datetime type.\"\n",
        "        else:\n",
        "            narratives['promotion_seasonality_insight'] = \"Promotion seasonality insight requires 'promotion_date_dt' and 'job_function' columns.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotion_seasonality_insight: {e}\")\n",
        "        narratives['promotion_seasonality_insight'] = \"Error generating promotion seasonality insight.\"\n",
        "\n",
        "\n",
        "    # == Hiring Section ==\n",
        "\n",
        "    # --- Hiring Year Insight (Year-over-Year Change) ---\n",
        "    try:\n",
        "        if 'hire_year' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            # Ensure hire_year is numeric and drop NaNs\n",
        "            hire_years_df = comp_df[comp_df['hire_year'].notna()].copy()\n",
        "            hire_years_df['hire_year'] = pd.to_numeric(hire_years_df['hire_year'], errors='coerce')\n",
        "            hire_years_df.dropna(subset=['hire_year'], inplace=True)\n",
        "            hire_years_df['hire_year'] = hire_years_df['hire_year'].astype(int) # Convert to int after dropna\n",
        "\n",
        "            if not hire_years_df.empty:\n",
        "                # Group hires by year and function\n",
        "                hires_by_year_func = hire_years_df.groupby(['hire_year', 'job_function'], observed=False).size().unstack(fill_value=0)\n",
        "\n",
        "                if len(hires_by_year_func) >= 2:\n",
        "                    # Compare the two most recent years with data\n",
        "                    hires_by_year_func = hires_by_year_func.sort_index()\n",
        "                    year2 = hires_by_year_func.index[-1]\n",
        "                    year1 = hires_by_year_func.index[-2]\n",
        "\n",
        "                    # Get counts for each function in the two years\n",
        "                    prod_y1 = hires_by_year_func.loc[year1, 'Product Development'] if 'Product Development' in hires_by_year_func.columns else 0\n",
        "                    prod_y2 = hires_by_year_func.loc[year2, 'Product Development'] if 'Product Development' in hires_by_year_func.columns else 0\n",
        "                    cont_y1 = hires_by_year_func.loc[year1, 'Content and Studio'] if 'Content and Studio' in hires_by_year_func.columns else 0\n",
        "                    cont_y2 = hires_by_year_func.loc[year2, 'Content and Studio'] if 'Content and Studio' in hires_by_year_func.columns else 0\n",
        "\n",
        "                    # Calculate percentage change, handling division by zero\n",
        "                    prod_change = ((prod_y2 - prod_y1) / prod_y1 * 100) if prod_y1 > 0 else (np.inf if prod_y2 > 0 else 0)\n",
        "                    cont_change = ((cont_y2 - cont_y1) / cont_y1 * 100) if cont_y1 > 0 else (np.inf if cont_y2 > 0 else 0)\n",
        "\n",
        "                    # Format change strings\n",
        "                    prod_change_str = f\"{'+' if prod_change >= 0 else ''}{safe_round(prod_change, 0)}%\" if np.isfinite(prod_change) else (\"Increase from zero\" if prod_y2 > 0 else \"No change from zero\")\n",
        "                    cont_change_str = f\"{'+' if cont_change >= 0 else ''}{safe_round(cont_change, 0)}%\" if np.isfinite(cont_change) else (\"Increase from zero\" if cont_y2 > 0 else \"No change from zero\")\n",
        "\n",
        "                    narratives['hiring_year_insight'] = (\n",
        "                        f\"Comparing hiring volume between {int(year1)} and {int(year2)}:\"\n",
        "                        f\"<br><br>\"\n",
        "                        f\"Product Development hiring changed by {prod_change_str}, while Content & Studio hiring changed by {cont_change_str}.\"\n",
        "                    )\n",
        "                else:\n",
        "                    narratives['hiring_year_insight'] = \"Insufficient historical data (less than 2 years with hiring activity) to compare year-over-year hiring trends.\"\n",
        "            else:\n",
        "                narratives['hiring_year_insight'] = \"No valid numeric hire year data found for trend analysis.\"\n",
        "        else:\n",
        "             narratives['hiring_year_insight'] = \"Hiring year insight requires 'hire_year' and 'job_function' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hiring_year_insight: {e}\")\n",
        "        narratives['hiring_year_insight'] = \"Error generating hiring year insight.\"\n",
        "\n",
        "    # --- Hiring Level Insight (Top Levels by Function) ---\n",
        "    try:\n",
        "        if 'job_function' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Group hires by function and level\n",
        "            hires_by_level_func = comp_df.groupby(['job_function', 'job_level_title'], observed=False).size().unstack(fill_value=0)\n",
        "            prod_top_str = \"\"\n",
        "            cont_top_str = \"\"\n",
        "\n",
        "            # Get top 3 hiring levels for Product Development\n",
        "            if 'Product Development' in hires_by_level_func.index:\n",
        "                prod_levels = hires_by_level_func.loc['Product Development'].sort_values(ascending=False)\n",
        "                prod_level_items = [f\"<li>{lvl} ({val:,})</li>\" for lvl, val in prod_levels.head(3).items() if val > 0 and lvl != 'Unknown']\n",
        "                prod_top_str = f\"<ul>{''.join(prod_level_items)}</ul>\" if prod_level_items else \"<li>No significant hiring volume found at specific levels.</li>\"\n",
        "\n",
        "            # Get top 3 hiring levels for Content & Studio\n",
        "            if 'Content and Studio' in hires_by_level_func.index:\n",
        "                cont_levels = hires_by_level_func.loc['Content and Studio'].sort_values(ascending=False)\n",
        "                cont_level_items = [f\"<li>{lvl} ({val:,})</li>\" for lvl, val in cont_levels.head(3).items() if val > 0 and lvl != 'Unknown']\n",
        "                cont_top_str = f\"<ul>{''.join(cont_level_items)}</ul>\" if cont_level_items else \"<li>No significant hiring volume found at specific levels.</li>\"\n",
        "\n",
        "            narratives['hiring_level_insight'] = (\n",
        "                f\"The most common job levels for new hires appear to differ by function:\"\n",
        "                f\"<br><b>Product Development Top Levels:</b>{prod_top_str}\"\n",
        "                f\"<br><b>Content & Studio Top Levels:</b>{cont_top_str}\"\n",
        "            )\n",
        "        else:\n",
        "            narratives['hiring_level_insight'] = \"Hiring level insight requires 'job_function' and 'job_level_title' columns with valid data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hiring_level_insight: {e}\")\n",
        "        narratives['hiring_level_insight'] = \"Error generating hiring level insight.\"\n",
        "\n",
        "    # --- Combined Hiring Insight ---\n",
        "    # Consolidates the year-over-year and level-based hiring insights.\n",
        "    try:\n",
        "        hiring_year_text = narratives.get('hiring_year_insight', \"\")\n",
        "        hiring_level_text = narratives.get('hiring_level_insight', \"\")\n",
        "        combined_hiring_text = \"\"\n",
        "\n",
        "        # Add year text if valid\n",
        "        if hiring_year_text and not hiring_year_text.startswith(\"Error\") and not hiring_year_text.startswith(\"Insufficient\") and not hiring_year_text.startswith(\"No valid\"):\n",
        "            combined_hiring_text += hiring_year_text\n",
        "\n",
        "        # Add level text if valid, adding spacing\n",
        "        if hiring_level_text and not hiring_level_text.startswith(\"Error\"):\n",
        "             if combined_hiring_text: # Add breaks if combining\n",
        "                 combined_hiring_text += f\"<br><br>Regarding the levels hired into, {hiring_level_text}\"\n",
        "             else:\n",
        "                 combined_hiring_text = hiring_level_text # Use directly if it's the only text\n",
        "\n",
        "        if combined_hiring_text:\n",
        "            narratives['hiring_insight'] = combined_hiring_text\n",
        "        else:\n",
        "            narratives['hiring_insight'] = \"Detailed hiring insights could not be generated due to missing or insufficient underlying data.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hiring_insight: {e}\")\n",
        "        narratives['hiring_insight'] = \"Error combining hiring insights.\"\n",
        "\n",
        "\n",
        "    # == Time to Promotion Section ==\n",
        "\n",
        "    # --- Promotion Timeline Insight (Average Time by Level) ---\n",
        "    ttp_by_level_data = pd.Series(dtype=float) # Initialize for storing data used later\n",
        "    try:\n",
        "        if 'time_to_promotion' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Filter for valid, numeric TTP data\n",
        "            promo_timing_df = comp_df[comp_df['time_to_promotion'].notna()].copy()\n",
        "            promo_timing_df['time_to_promotion'] = pd.to_numeric(promo_timing_df['time_to_promotion'], errors='coerce')\n",
        "            promo_timing_df.dropna(subset=['time_to_promotion'], inplace=True)\n",
        "\n",
        "            if not promo_timing_df.empty:\n",
        "                # Group by level promoted *into* and calculate average TTP\n",
        "                ttp_by_level_data = promo_timing_df.groupby('job_level_title')['time_to_promotion'].mean().round(1)\n",
        "                # Exclude 'Unknown', sort by typical progression (can customize order)\n",
        "                level_order_promo = ['Manager', 'Director', 'Vice President'] # Example order\n",
        "                ttp_by_level_data = ttp_by_level_data.reindex(level_order_promo).dropna()\n",
        "                narratives['ttp_by_level_data'] = ttp_by_level_data # Store data for strategic steps\n",
        "\n",
        "                if not ttp_by_level_data.empty:\n",
        "                    # Format as HTML list\n",
        "                    ttp_items = [f\"<li>{lvl}: {val} years</li>\" for lvl, val in ttp_by_level_data.items()]\n",
        "                    ttp_formatted_list = f\"<ul>{''.join(ttp_items)}</ul>\"\n",
        "                    narratives['promotion_timeline_insight'] = (\n",
        "                        f\"The average time elapsed until promotion (Time to Promotion) varies by the level achieved:\"\n",
        "                        f\"{ttp_formatted_list}\"\n",
        "                        f\"This provides insight into typical progression timelines for these levels.\"\n",
        "                    )\n",
        "                else:\n",
        "                    narratives['promotion_timeline_insight'] = \"Could not calculate average time to promotion by relevant job levels after filtering.\"\n",
        "                    narratives['ttp_by_level_data'] = pd.Series(dtype=float) # Ensure empty series if no data\n",
        "            else:\n",
        "                narratives['promotion_timeline_insight'] = \"Insufficient valid numeric 'time_to_promotion' data to calculate by level.\"\n",
        "                narratives['ttp_by_level_data'] = pd.Series(dtype=float)\n",
        "        else:\n",
        "            narratives['promotion_timeline_insight'] = \"Promotion timeline insight requires 'time_to_promotion' and 'job_level_title' columns with valid data.\"\n",
        "            narratives['ttp_by_level_data'] = pd.Series(dtype=float)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotion_timeline_insight: {e}\")\n",
        "        narratives['promotion_timeline_insight'] = \"Error generating promotion timeline insight.\"\n",
        "        narratives['ttp_by_level_data'] = pd.Series(dtype=float) # Ensure empty series on error\n",
        "\n",
        "    # --- Promotion Timing Summary (Copy for Template) ---\n",
        "    # Some templates might use a different key for the same info, so copy if available.\n",
        "    if 'promotion_timeline_insight' in narratives and not narratives['promotion_timeline_insight'].startswith(\"Error\") and not narratives['promotion_timeline_insight'].startswith(\"Could not\") and not narratives['promotion_timeline_insight'].startswith(\"Insufficient\"):\n",
        "        narratives['promotion_timing_summary'] = narratives['promotion_timeline_insight']\n",
        "    else:\n",
        "        # Ensure the key exists even if the original failed\n",
        "        narratives['promotion_timing_summary'] = \"Promotion timing summary (average TTP by level) could not be generated.\"\n",
        "\n",
        "    # --- Promotion Velocity Insight (Rename from Regression) ---\n",
        "    # Rename the key from the regression analysis for template compatibility.\n",
        "    if 'promotion_regression_insight' in narratives:\n",
        "        insight_text = narratives.pop('promotion_regression_insight') # Remove old key\n",
        "        # Ensure appropriate line breaks if not already present\n",
        "        if '<br>' not in insight_text and '.' in insight_text:\n",
        "             insight_text = insight_text.replace('. ', '.<br><br>', 1)\n",
        "        narratives['promo_velocity_insight'] = insight_text\n",
        "    else:\n",
        "        # Ensure key exists if regression failed\n",
        "        narratives['promo_velocity_insight'] = \"Promotion velocity insight (regression analysis) not available or encountered an error.\"\n",
        "\n",
        "    # --- Tenure vs. Time to Promotion Correlation Insight ---\n",
        "    try:\n",
        "        if 'tenure_years' in comp_df.columns and 'time_to_promotion' in comp_df.columns:\n",
        "            # Prepare data: numeric, non-null tenure and TTP\n",
        "            ttp_tenure_df = comp_df[['tenure_years', 'time_to_promotion']].copy()\n",
        "            ttp_tenure_df['tenure_years'] = pd.to_numeric(ttp_tenure_df['tenure_years'], errors='coerce')\n",
        "            ttp_tenure_df['time_to_promotion'] = pd.to_numeric(ttp_tenure_df['time_to_promotion'], errors='coerce')\n",
        "            ttp_tenure_df.dropna(inplace=True)\n",
        "\n",
        "            if len(ttp_tenure_df) > 30: # Require sufficient data for meaningful correlation\n",
        "                corr, p_val = pearsonr(ttp_tenure_df['tenure_years'], ttp_tenure_df['time_to_promotion'])\n",
        "\n",
        "                # Describe correlation strength\n",
        "                corr_desc = \"weak\"\n",
        "                if abs(corr) > 0.7: corr_desc = \"strong\"\n",
        "                elif abs(corr) > 0.4: corr_desc = \"moderate\"\n",
        "\n",
        "                # Describe significance\n",
        "                sig_text = f\"(p = {p_val:.3f}, statistically significant)\" if p_val < 0.05 else f\"(p = {p_val:.3f}, not statistically significant)\"\n",
        "                direction = \"positive\" if corr > 0 else \"negative\" if corr < 0 else \"negligible\"\n",
        "\n",
        "                # Interpretation based on direction\n",
        "                interpretation = \"\"\n",
        "                if corr > 0.1: # Threshold for positive interpretation\n",
        "                     interpretation = \"This suggests that employees with longer tenure at the time of their promotion also tended to have taken longer to reach that promotion (i.e., longer time between promotions or longer time since hire).\"\n",
        "                elif corr < -0.1: # Threshold for negative interpretation\n",
        "                     interpretation = \"This suggests that employees with longer tenure at the time of their promotion tended to have shorter times to promotion (i.e., faster progression).\"\n",
        "                else: # Weak or negligible correlation\n",
        "                     interpretation = \"This indicates little to no linear relationship between an employee's tenure and their time to promotion within this dataset.\"\n",
        "\n",
        "\n",
        "                narratives['tenure_ttp_insight'] = (\n",
        "                    f\"Analysis reveals a {corr_desc}, {direction} correlation ({corr:.2f}) between employee tenure (at time of promotion) and their time-to-promotion {sig_text}.\"\n",
        "                    f\"<br><br>{interpretation}\"\n",
        "                )\n",
        "            else:\n",
        "                narratives['tenure_ttp_insight'] = \"Insufficient data (<= 30 records with valid tenure and time-to-promotion) to reliably analyze the correlation between these two metrics.\"\n",
        "        else:\n",
        "            narratives['tenure_ttp_insight'] = \"Correlation analysis requires 'tenure_years' and 'time_to_promotion' columns with valid numeric data.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating tenure_ttp_insight: {e}\")\n",
        "        narratives['tenure_ttp_insight'] = \"Error analyzing tenure vs. time-to-promotion correlation.\"\n",
        "\n",
        "\n",
        "    # == Diagnostics Section ==\n",
        "\n",
        "    # --- Data Quality Summary ---\n",
        "    try:\n",
        "        num_bad_dates = 0\n",
        "        num_promo_issues = 0\n",
        "        # Parse the JSON strings passed from load_data to get counts\n",
        "        if bad_dates_json_str:\n",
        "            try:\n",
        "                bad_dates_list = json.loads(bad_dates_json_str)\n",
        "                num_bad_dates = len(bad_dates_list)\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"Warning: Could not parse bad_dates_json_str for quality summary.\")\n",
        "        if promo_issue_json_str:\n",
        "            try:\n",
        "                promo_issues_list = json.loads(promo_issue_json_str)\n",
        "                num_promo_issues = len(promo_issues_list)\n",
        "            except json.JSONDecodeError:\n",
        "                print(\"Warning: Could not parse promo_issue_json_str for quality summary.\")\n",
        "\n",
        "        # Describe data processing steps\n",
        "        processing_summary = (\n",
        "            \"<b>Data Processing Overview:</b><br>\"\n",
        "            \"<ul>\"\n",
        "            \"<li>Loaded employee snapshot and history data from CSV files.</li>\"\n",
        "            \"<li>Standardized column names and converted key identifiers (employee, manager IDs) to appropriate types.</li>\"\n",
        "            \"<li>Merged the snapshot and history datasets based on employee ID.</li>\"\n",
        "            \"<li>Cleaned and standardized job function names (e.g., mapping 'Product' to 'Product Development').</li>\"\n",
        "            \"<li>Parsed job level strings to extract numerical level and title components.</li>\"\n",
        "            \"<li>Determined employee role (People Manager or Individual Contributor) based on job title keywords and reporting structure verification.</li>\"\n",
        "            \"<li>Converted hire and promotion date strings to datetime objects, handling potential format errors.</li>\"\n",
        "            \"<li>Calculated derived metrics: tenure, time-to-promotion (invalidating illogical dates), direct span of control, and total organizational scope (direct + indirect reports).</li>\"\n",
        "            \"<li>Identified records with date format errors or promotion dates preceding hire dates for exclusion from relevant calculations and reporting in the diagnostics tab.</li>\"\n",
        "            \"<li>Filtered the final dataset to include only records with valid, parseable hire dates for time-based analyses.</li>\"\n",
        "            \"</ul>\"\n",
        "        )\n",
        "\n",
        "        # Describe data quality findings based on counts\n",
        "        quality_findings = \"<br><b>Data Quality Findings:</b><br>\"\n",
        "        if num_bad_dates == 0 and num_promo_issues == 0:\n",
        "            quality_findings += \"No major date formatting errors or illogical promotion timing issues (promotion before hire) were detected in the source data based on the applied parsing rules.\"\n",
        "        else:\n",
        "            quality_findings += \"Data quality checks identified the following potential issues:\"\n",
        "            findings_list_items = []\n",
        "            if num_bad_dates > 0:\n",
        "                findings_list_items.append(f\"<li>{num_bad_dates} records contained date strings (hire or promotion) that could not be parsed into valid dates using the expected format. These records were excluded from time-based calculations where necessary.</li>\")\n",
        "            if num_promo_issues > 0:\n",
        "                findings_list_items.append(f\"<li>{num_promo_issues} records had a promotion date recorded earlier than the hire date. The time-to-promotion calculation for these records was invalidated.</li>\")\n",
        "            quality_findings += f\"<ul>{''.join(findings_list_items)}</ul>\"\n",
        "            quality_findings += \"Specific details for affected records are available in the Diagnostics tab.\"\n",
        "\n",
        "        narratives['data_quality_summary'] = processing_summary + quality_findings\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating data_quality_summary: {e}\")\n",
        "        narratives['data_quality_summary'] = \"Error generating data quality summary narrative.\"\n",
        "\n",
        "\n",
        "    # == Strategic Section ==\n",
        "\n",
        "    # --- Strategic Next Steps (Conditional Recommendations) ---\n",
        "    try:\n",
        "        strategic_next_steps_list = []\n",
        "        # Retrieve necessary intermediate results\n",
        "        diff_span_local = narratives.get('diff_span', np.nan)\n",
        "        span_pval_local = narratives.get('span_p_value', np.nan)\n",
        "        prod_span_local = narratives.get('prod_avg_span', np.nan)\n",
        "        cont_span_local = narratives.get('cont_avg_span', np.nan)\n",
        "\n",
        "        diff_tenure_local = narratives.get('diff_tenure', np.nan)\n",
        "        tenure_pval_local = narratives.get('tenure_p_value', np.nan)\n",
        "        prod_tenure_local = narratives.get('prod_avg_tenure', np.nan)\n",
        "        cont_tenure_local = narratives.get('cont_avg_tenure', np.nan)\n",
        "\n",
        "        ttp_by_level_local = narratives.get('ttp_by_level_data', pd.Series(dtype=float)) # Retrieve stored series\n",
        "\n",
        "        # Condition 1: Significant and large span difference\n",
        "        if not np.isnan(span_pval_local) and span_pval_local < 0.05 and not np.isnan(diff_span_local) and diff_span_local >= 1.0:\n",
        "             strategic_next_steps_list.append(f\"Investigate the impact of the significant difference in average manager span of control (Product: {safe_round(prod_span_local,1)} vs. Content: {safe_round(cont_span_local,1)}) on manager workload, team dynamics, and employee development opportunities.\")\n",
        "\n",
        "        # Condition 2: Significant and large tenure difference\n",
        "        if not np.isnan(tenure_pval_local) and tenure_pval_local < 0.05 and not np.isnan(diff_tenure_local) and diff_tenure_local >= 0.5:\n",
        "             strategic_next_steps_list.append(f\"Explore the drivers behind the significant variation in average employee tenure (Product: {safe_round(prod_tenure_local, 1)} yrs vs. Content: {safe_round(cont_tenure_local, 1)} yrs), considering factors like retention patterns, role expectations, or career pathing within each function.\")\n",
        "\n",
        "        # Condition 3: Check TTP for specific levels (e.g., Director)\n",
        "        if ttp_by_level_local is not None and not ttp_by_level_local.empty:\n",
        "             if 'Director' in ttp_by_level_local.index:\n",
        "                 dir_ttp = ttp_by_level_local.get('Director')\n",
        "                 if dir_ttp is not None and not np.isnan(dir_ttp) and dir_ttp > 3.0: # Example threshold\n",
        "                     strategic_next_steps_list.append(f\"Review the promotion pathway to Director level, as the current average time-to-promotion ({dir_ttp:.1f} years) warrants examination regarding alignment with career progression expectations and potential barriers.\")\n",
        "\n",
        "        # Add standard exploratory steps\n",
        "        strategic_next_steps_list.extend([\n",
        "            \"Analyze voluntary attrition rates, segmenting by function, level, and tenure, to identify potential retention challenges.\",\n",
        "            \"If available, correlate manager span of control and total scope with team performance metrics or employee engagement survey results.\",\n",
        "            \"Evaluate the effectiveness of different hiring sources (e.g., internal mobility vs. external hires) for key roles and leadership positions.\",\n",
        "            \"Compare internal promotion rates against external hiring rates, particularly for senior and leadership levels, to assess internal talent pipeline health.\"\n",
        "        ])\n",
        "\n",
        "        # Format as a simple text list with newlines for the template\n",
        "        # Jinja2 templates often handle markdown or simple text formatting better than raw HTML lists here.\n",
        "        if strategic_next_steps_list:\n",
        "             narratives['strategic_next_steps'] = \"**Further Exploration Recommended:**\\n\" + \"\\n\".join([f\"- {step}\" for step in strategic_next_steps_list])\n",
        "        else:\n",
        "             narratives['strategic_next_steps'] = \"**Further Exploration Recommended:**\\nNo specific areas were flagged based on the current analysis thresholds, but standard checks (e.g., attrition analysis, engagement correlation, hiring source review) remain valuable for ongoing organizational health monitoring.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating strategic_next_steps: {e}\")\n",
        "        narratives['strategic_next_steps'] = \"Error generating strategic recommendations.\"\n",
        "\n",
        "    # --- Strategic Overall Context ---\n",
        "    # Provides a high-level summary framing the detailed insights.\n",
        "    try:\n",
        "        # Use a standard framing narrative\n",
        "        narratives['strategic_overall'] = (\n",
        "             \"Analysis of the Product Development and Content & Studio functions reveals distinct organizational patterns and talent dynamics. Variations exist in team structures (indicated by manager ratios and span of control), employee tenure profiles, and the velocity of talent movement (reflected in promotion rates and timelines).\"\n",
        "             \"<br><br>\"\n",
        "             \"These differences may stem from the unique operational requirements, strategic priorities, and historical evolution of each function. Understanding these variations is crucial for ensuring equitable employee experiences, optimizing organizational design, and supporting effective scaling and talent management strategies across diverse parts of the business.\"\n",
        "             \"<br><br>\"\n",
        "             \"The detailed insights and recommended next steps aim to facilitate deeper investigation into areas where observed differences may warrant further attention or strategic intervention.\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating strategic_overall: {e}\")\n",
        "        narratives['strategic_overall'] = \"Error generating overall strategic summary.\"\n",
        "\n",
        "    # --- Strategic Insight 1: Structure Reflects Strategy ---\n",
        "    # Summarizes findings related to org structure (manager ratio, span).\n",
        "    try:\n",
        "        org_design_text = narratives.get('org_design_insight', '')\n",
        "        span_text = narratives.get('span_control_insight', '')\n",
        "        insight_parts = []\n",
        "        if org_design_text and not org_design_text.startswith(\"Error\"): insight_parts.append(org_design_text)\n",
        "        if span_text and not span_text.startswith(\"Error\") and not span_text.startswith(\"Detailed span\"): insight_parts.append(span_text)\n",
        "\n",
        "        if insight_parts:\n",
        "             narratives['strategic_insight_1'] = \"<b>Organizational structures appear tailored, potentially reflecting differing strategic needs and operational models:</b><br><br>\" + \"<br><br>\".join(insight_parts)\n",
        "        else:\n",
        "             narratives['strategic_insight_1'] = \"<b>Organizational Structure Insight:</b><br>Analysis of manager ratios and span of control could not be completed due to data limitations.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating strategic_insight_1: {e}\")\n",
        "        narratives['strategic_insight_1'] = \"Error generating strategic insight on structure.\"\n",
        "\n",
        "    # --- Strategic Insight 2: Differing Talent Velocities ---\n",
        "    # Repurposes the executive summary findings about significant differences.\n",
        "    if 'exec_summary_findings' in narratives:\n",
        "        findings_text = narratives.pop('exec_summary_findings') # Remove old key\n",
        "        if findings_text and not findings_text.startswith(\"Error\") and not findings_text.startswith(\"No statistically significant\"):\n",
        "            narratives['strategic_insight_2'] = f\"<b>Key differences in talent velocity and structure observed:</b><br>{findings_text}\"\n",
        "        else:\n",
        "            # Provide specific fallback if findings were non-significant or errored\n",
        "            narratives['strategic_insight_2'] = \"<b>Talent Velocity Comparison:</b><br>Analysis did not identify statistically significant differences meeting thresholds in tenure, span, promotion rates, or controlled promotion timing between the functions.\"\n",
        "    else:\n",
        "        # Ensure key exists if base findings failed earlier\n",
        "         narratives['strategic_insight_2'] = \"<b>Talent Velocity Comparison:</b><br>Comparative analysis of talent velocity metrics encountered an error or data was insufficient.\"\n",
        "\n",
        "\n",
        "    # --- Strategic Insight 3: Operational Cycles Drive Talent Flow ---\n",
        "    # Summarizes findings related to seasonality (promotions, hiring trends).\n",
        "    try:\n",
        "        promo_season_text = narratives.get('promotion_seasonality_insight', '')\n",
        "        hiring_year_text = narratives.get('hiring_year_insight', '')\n",
        "        insight_parts = []\n",
        "        if promo_season_text and not promo_season_text.startswith(\"Error\") and not promo_season_text.startswith(\"Insufficient\"): insight_parts.append(promo_season_text)\n",
        "        if hiring_year_text and not hiring_year_text.startswith(\"Error\") and not hiring_year_text.startswith(\"Insufficient\"): insight_parts.append(hiring_year_text)\n",
        "\n",
        "        if insight_parts:\n",
        "            narratives['strategic_insight_3'] = \"<b>Talent movement shows seasonality, potentially linked to operational cycles:</b><br><br>\" + \"<br><br>\".join(insight_parts)\n",
        "        else:\n",
        "            narratives['strategic_insight_3'] = \"<b>Operational Cycles Insight:</b><br>Analysis of seasonality in promotions and hiring trends could not be completed due to data limitations.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating strategic_insight_3: {e}\")\n",
        "        narratives['strategic_insight_3'] = \"Error generating strategic insight on operational cycles.\"\n",
        "\n",
        "    # --- Strategic ML Insight (Informational Placeholder) ---\n",
        "    # Adds context about potential future analyses.\n",
        "    narratives['strategic_ml_insight'] = \"Advanced analytical techniques, such as predictive modeling for attrition risk or promotion likelihood using machine learning, could offer deeper strategic insights. These methods can help identify subtle patterns and leading indicators not apparent through descriptive statistics alone but are beyond the scope of this current dashboard version.\"\n",
        "\n",
        "    # --- Add Executive Summary Components (for top cards) ---\n",
        "    # These provide quick numerical summaries.\n",
        "    try:\n",
        "        total_employees = narratives.get('total_employees', len(comp_df)) # Use intermediate if available\n",
        "        role_counts = comp_df['role'].value_counts() if 'role' in comp_df.columns else pd.Series(dtype=int)\n",
        "        level_counts = comp_df['job_level_title'].value_counts() if 'job_level_title' in comp_df.columns else pd.Series(dtype=int)\n",
        "        func_total = comp_df['job_function'].value_counts() if 'job_function' in comp_df.columns else pd.Series(dtype=int)\n",
        "        prod_total_exec = func_total.get('Product Development', 0)\n",
        "        cont_total_exec = func_total.get('Content and Studio', 0)\n",
        "\n",
        "        # Retrieve calculated averages/medians from intermediate results\n",
        "        avg_span_exec = narratives.get('avg_span', np.nan)\n",
        "        prod_span_exec = narratives.get('prod_avg_span', np.nan)\n",
        "        cont_span_exec = narratives.get('cont_avg_span', np.nan)\n",
        "        avg_tenure_exec = narratives.get('avg_tenure', np.nan)\n",
        "        prod_tenure_exec = narratives.get('prod_avg_tenure', np.nan)\n",
        "        cont_tenure_exec = narratives.get('cont_avg_tenure', np.nan)\n",
        "\n",
        "        # Format executive summary strings\n",
        "        narratives['exec_summary_employees'] = (\n",
        "            f\"Total Analyzed: {total_employees:,} (Prod: {prod_total_exec:,}, Content: {cont_total_exec:,})\"\n",
        "            f\"<br>Role Split: ICs={role_counts.get('Individual Contributor', 0):,}, Managers={role_counts.get('People Manager', 0):,}\"\n",
        "            f\"<br>Top Levels: {', '.join([f'{lvl} ({cnt:,})' for lvl, cnt in level_counts.head(3).items()])}\"\n",
        "        )\n",
        "        narratives['exec_summary_span'] = (\n",
        "             f\"Avg Span (Overall): {safe_round(avg_span_exec, 1)}\"\n",
        "             f\"<br>Avg Span (Prod): {safe_round(prod_span_exec, 1)}\"\n",
        "             f\"<br>Avg Span (Content): {safe_round(cont_span_exec, 1)}\"\n",
        "        )\n",
        "        narratives['exec_summary_tenure'] = (\n",
        "            f\"Avg Tenure (Overall): {safe_round(avg_tenure_exec, 1)} yrs\"\n",
        "            f\"<br>Avg Tenure (Prod): {safe_round(prod_tenure_exec, 1)} yrs\"\n",
        "            f\"<br>Avg Tenure (Content): {safe_round(cont_tenure_exec, 1)} yrs\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating exec_summary card narratives: {e}\")\n",
        "        narratives['exec_summary_employees'] = \"Error generating employee breakdown.\"\n",
        "        narratives['exec_summary_tenure'] = \"Error generating tenure summary.\"\n",
        "        narratives['exec_summary_span'] = \"Error generating span summary.\"\n",
        "\n",
        "\n",
        "    # --- Final Cleanup ---\n",
        "    # Remove intermediate calculation results and temporary keys before returning\n",
        "    intermediate_keys_to_remove = {\n",
        "        'total_employees', 'comp_by_func_role', 'ic_pct', 'mgr_pct', 'prod_mgr_pct',\n",
        "        'cont_mgr_pct', 'roles_p_value', 'roles_stat_sig_text',\n",
        "        'avg_tenure', 'prod_avg_tenure', 'cont_avg_tenure', 'prod_pct_new',\n",
        "        'cont_pct_new', 'diff_tenure', 'tenure_p_value', 'tenure_stat_sig_text',\n",
        "        'prod_mgr_ratio', 'cont_mgr_ratio',\n",
        "        'avg_span', 'prod_avg_span', 'cont_avg_span', 'diff_span', 'span_p_value', 'span_stat_sig_text',\n",
        "        'promo_counts', 'total_by_func', 'promo_rate_prod', 'promo_rate_cont',\n",
        "        'promo_rate_p_value', 'promo_rate_stat_sig_text',\n",
        "        'ttp_regression_model', 'ttp_regression_beta', 'ttp_regression_pval',\n",
        "        'ttp_by_level_data' # Remove the stored series data\n",
        "    }\n",
        "\n",
        "    # Remove the identified keys\n",
        "    for key in intermediate_keys_to_remove:\n",
        "        narratives.pop(key, None) # Use pop with default to avoid errors if key missing\n",
        "\n",
        "    # Final check for any remaining error messages and replace with standard fallback\n",
        "    final_keys = list(narratives.keys())\n",
        "    for key in final_keys:\n",
        "        value = narratives.get(key)\n",
        "        if isinstance(value, str) and (value.startswith(\"Error generating\") or value.startswith(\"Could not calculate\") or value.endswith(\"unavailable.\") or value.startswith(\"Insufficient data\") or value.startswith(\"Note:\")):\n",
        "            # Replace specific error/note messages with a generic indicator for the dashboard\n",
        "            narratives[key] = f\"Insight generation for '{key}' encountered an issue or data was unavailable/insufficient for analysis.\"\n",
        "\n",
        "    return narratives\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# # 6. Chart Creation\n",
        "# =============================================================================\n",
        "# Description: This section defines the `create_charts` function, which\n",
        "# generates a variety of visualizations using Plotly Express and Plotly\n",
        "# Graph Objects. It takes the processed DataFrame as input and returns a\n",
        "# dictionary of chart specifications suitable for JSON serialization and\n",
        "# embedding into the HTML template. An inner helper function `encode_chart`\n",
        "# standardizes styling and encoding.\n",
        "\n",
        "# Define safe_round here if it wasn't defined globally or imported properly\n",
        "# For context, assuming it's available from Part 1.\n",
        "def safe_round(value, decimals=1, na_value='N/A'):\n",
        "    \"\"\"\n",
        "    Safely rounds a numerical value to a specified number of decimal places.\n",
        "\n",
        "    Handles non-numeric inputs (like NaN, None, or strings) by returning a\n",
        "    specified placeholder value ('N/A' by default).\n",
        "\n",
        "    Args:\n",
        "        value (any): The value to round.\n",
        "        decimals (int): The number of decimal places to round to. Defaults to 1.\n",
        "        na_value (str): The value to return if the input is not a valid number.\n",
        "                        Defaults to 'N/A'.\n",
        "\n",
        "    Returns:\n",
        "        float or str: The rounded number, or the na_value placeholder.\n",
        "    \"\"\"\n",
        "    if pd.isna(value) or not isinstance(value, (int, float, np.number)):\n",
        "        return na_value\n",
        "    try:\n",
        "        # Use np.round for compatibility with numpy types\n",
        "        return np.round(value, decimals)\n",
        "    except (TypeError, ValueError):\n",
        "         # Catch potential errors during rounding itself\n",
        "         return na_value\n",
        "\n",
        "\n",
        "# --- Chart Creation Function ---\n",
        "def create_charts(df):\n",
        "    \"\"\"\n",
        "    Generates various Plotly charts from the input DataFrame.\n",
        "\n",
        "    Creates visualizations covering workforce composition, tenure distribution,\n",
        "    span of control, promotion trends, hiring patterns, and time-to-promotion\n",
        "    metrics. Applies consistent styling and formatting using an inner helper.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The processed DataFrame from `load_data`.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are chart identifiers (matching template\n",
        "              expectations) and values are Plotly figure specifications encoded\n",
        "              as Python dictionaries. Returns an empty dict if input is invalid.\n",
        "    \"\"\"\n",
        "    charts = {}\n",
        "    if df is None or df.empty:\n",
        "        print(\"Input DataFrame is empty or None. No charts will be generated.\")\n",
        "        return charts\n",
        "\n",
        "    # --- Configuration & Setup ---\n",
        "    # Access global color palette (defined in Part 1)\n",
        "    global color_palette\n",
        "    if 'color_palette' not in globals():\n",
        "        print(\"Warning: color_palette not defined globally. Using default colors.\")\n",
        "        # Define fallback colors if global palette is missing\n",
        "        color_palette = {'primary': '#E50914', 'secondary': '#B3B3B3', 'tertiary': '#808080'}\n",
        "\n",
        "    # Define primary colors for direct use\n",
        "    netflix_red = color_palette.get('primary', '#E50914')\n",
        "    netflix_grey = color_palette.get('secondary', '#B3B3B3')\n",
        "    netflix_other = color_palette.get('tertiary', '#808080')\n",
        "\n",
        "    # Map job functions to specific colors for consistency across charts\n",
        "    color_map = {\n",
        "        'Product Development': netflix_red,\n",
        "        'Content and Studio': netflix_grey,\n",
        "        'Other': netflix_other\n",
        "    }\n",
        "\n",
        "    # Check for required columns needed for various charts\n",
        "    required_cols = ['job_function', 'job_level_title', 'role', 'tenure_years',\n",
        "                     'is_manager', 'span_of_control', 'is_promoted', 'promotion_year',\n",
        "                     'hire_quarter', 'time_to_promotion', 'hire_year', 'promotion_date_dt', # Use datetime version\n",
        "                     'hire_date_dt'] # Use datetime version\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        print(f\"Warning: Input DataFrame is missing required columns for charts: {', '.join(missing_cols)}. Some charts may fail or be skipped.\")\n",
        "\n",
        "    # Filter data for primary functions, falling back if necessary\n",
        "    comp_df = df[df['job_function'].isin(['Product Development', 'Content and Studio'])].copy()\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: No data found for 'Product Development' or 'Content and Studio'. Using all data for charts.\")\n",
        "        comp_df = df.copy()\n",
        "\n",
        "    if comp_df.empty:\n",
        "        print(\"Filtered or original DataFrame is empty. No charts generated.\")\n",
        "        return charts\n",
        "\n",
        "    # Define standard order for job levels for consistent axis sorting\n",
        "    level_order = ['Individual Contributor', 'Manager', 'Director', 'Vice President', 'Unknown']\n",
        "    manager_level_order = ['Manager', 'Director', 'Vice President'] # Order for manager-specific charts\n",
        "\n",
        "    # --- Inner Helper Function to Encode Charts ---\n",
        "    def encode_chart(fig, chart_title=\"\"):\n",
        "        \"\"\"\n",
        "        Applies standard layout updates and encodes a Plotly figure to dict.\n",
        "\n",
        "        Handles styling for common trace types (bar, pie, scatter, box, etc.),\n",
        "        applies base layout defaults (margins, legend position, background),\n",
        "        and performs conditional layout adjustments based on chart type. Uses\n",
        "        `pio.to_json` followed by `json.loads` for robust serialization.\n",
        "\n",
        "        Args:\n",
        "            fig (go.Figure): The Plotly figure object.\n",
        "            chart_title (str): The title for the chart (used for logging/context).\n",
        "\n",
        "        Returns:\n",
        "            dict or None: The figure specification as a dictionary, or None if encoding fails.\n",
        "        \"\"\"\n",
        "        if not isinstance(fig, go.Figure):\n",
        "            print(f\"Warning: Attempted to encode non-figure object for chart '{chart_title}'\")\n",
        "            return None\n",
        "\n",
        "        # --- Base Layout Defaults (Applied to all charts) ---\n",
        "        base_layout = {\n",
        "            'margin': dict(l=60, r=150, t=60, b=100), # Margins to accommodate labels/legends\n",
        "            'legend': dict(\n",
        "                orientation='v', yanchor='middle', y=0.5, # Vertical legend on the right\n",
        "                xanchor='left', x=1.02,\n",
        "                bgcolor='rgba(30,30,30,0.7)', bordercolor='rgba(255,255,255,0.2)', borderwidth=1,\n",
        "                font=dict(size=10, color='#DDDDDD')\n",
        "            ),\n",
        "            'title': {'text': chart_title, 'x': 0.5, 'xanchor': 'center', 'font': {'size': 16}},\n",
        "            'xaxis': {\n",
        "                'automargin': True, 'tickangle': -45, 'showticklabels': True, # Default angle for x-axis labels\n",
        "                'title_standoff': 20, 'title_font_size': 12, 'tickfont_size': 10,\n",
        "                'gridcolor': 'rgba(128,128,128,0.2)', # Subtle grid lines\n",
        "                'linecolor': 'rgba(128,128,128,0.5)',\n",
        "                'zerolinecolor': 'rgba(128,128,128,0.3)',\n",
        "            },\n",
        "            'yaxis': {\n",
        "                'automargin': True, 'title_standoff': 15,\n",
        "                'title_font_size': 12, 'tickfont_size': 10,\n",
        "                'gridcolor': 'rgba(128,128,128,0.2)', # Subtle grid lines\n",
        "                'linecolor': 'rgba(128,128,128,0.5)',\n",
        "                'zerolinecolor': 'rgba(128,128,128,0.3)',\n",
        "            },\n",
        "            'paper_bgcolor': 'rgba(0,0,0,0)', # Transparent background\n",
        "            'plot_bgcolor': 'rgba(0,0,0,0)',  # Transparent plot area\n",
        "            'hovermode': 'closest',\n",
        "            'hoverlabel': dict( # Styling for hover tooltips\n",
        "                bgcolor=\"rgba(15, 15, 15, 0.9)\", font_size=12,\n",
        "                font_family=\"Arial, sans-serif\", font_color=\"#FFFFFF\",\n",
        "                bordercolor=\"rgba(255,255,255,0.4)\"\n",
        "            )\n",
        "            # Font color is inherited from the global template setting\n",
        "        }\n",
        "\n",
        "        # --- Apply Trace Styling (Based on trace type) ---\n",
        "        for trace in fig.data:\n",
        "            try:\n",
        "                trace_type = getattr(trace, 'type', None)\n",
        "                # Common styling: marker lines for clarity\n",
        "                if hasattr(trace, 'marker') and not hasattr(trace.marker, 'line'):\n",
        "                    trace.marker.line = {}\n",
        "                if hasattr(trace, 'marker') and hasattr(trace.marker, 'line'):\n",
        "                     trace.marker.line.width = getattr(trace.marker.line, 'width', 0.5)\n",
        "                     trace.marker.line.color = getattr(trace.marker.line, 'color', 'rgba(255, 255, 255, 0.3)')\n",
        "\n",
        "                # Type-specific styling and hovertemplates\n",
        "                if trace_type == 'bar':\n",
        "                    trace.marker.opacity = getattr(trace.marker, 'opacity', 0.85)\n",
        "                    if not getattr(trace, 'hovertemplate', None):\n",
        "                        trace.hovertemplate = '<b>%{data.name}</b><br>%{x}: %{y}<extra></extra>'\n",
        "                elif trace_type == 'pie':\n",
        "                    # trace.marker.opacity = getattr(trace.marker, 'opacity', 0.9) # Opacity on marker causes error\n",
        "                    trace.opacity = getattr(trace, 'opacity', 0.9) # Apply opacity to the trace itself\n",
        "                    trace.marker.line.width = getattr(trace.marker.line, 'width', 1) # Slightly thicker line for pies\n",
        "                    if not getattr(trace, 'hovertemplate', None):\n",
        "                        trace.hovertemplate = '<b>%{data.name}</b><br>%{label}: %{percent:.1%}<extra></extra>'\n",
        "                elif trace_type == 'scatter':\n",
        "                    if hasattr(trace, 'mode') and ('lines' in trace.mode):\n",
        "                        trace.line = getattr(trace, 'line', {})\n",
        "                        trace.line.width = getattr(trace.line, 'width', 2.5)\n",
        "                        trace.opacity = getattr(trace, 'opacity', 0.8)\n",
        "                    if hasattr(trace, 'mode') and ('markers' in trace.mode):\n",
        "                        trace.marker = getattr(trace, 'marker', {})\n",
        "                        trace.marker.opacity = getattr(trace.marker, 'opacity', 0.7)\n",
        "                        trace.marker.size=getattr(trace.marker, 'size', 6)\n",
        "                    if not getattr(trace, 'hovertemplate', None):\n",
        "                         # Default hover for scatter, customize per chart if needed\n",
        "                         trace.hovertemplate = '<b>%{data.name}</b><br>X: %{x}<br>Y: %{y}<extra></extra>'\n",
        "                elif trace_type == 'box':\n",
        "                    # Apply line style to box plots for consistency\n",
        "                    trace.marker.line.width = 1.5\n",
        "                    trace.marker.line.color = 'rgba(255, 255, 255, 0.4)'\n",
        "                    # Simplified hovertemplate for box plots\n",
        "                    trace.hovertemplate = ('<b>%{x}</b> (%{data.name})<br>Median: %{median:.1f}<br>Q1: %{q1:.1f} | Q3: %{q3:.1f}<extra></extra>')\n",
        "                elif trace_type == 'histogram':\n",
        "                    trace.marker.opacity = getattr(trace.marker, 'opacity', 0.7)\n",
        "                    if not getattr(trace, 'hovertemplate', None):\n",
        "                        trace.hovertemplate = '<b>%{data.name}</b><br>Range: %{x}<br>Count: %{y}<extra></extra>'\n",
        "                elif trace_type == 'indicator':\n",
        "                    if hasattr(trace, 'gauge'): trace.gauge.borderwidth = getattr(trace.gauge, 'borderwidth', 0)\n",
        "                    # Hover info typically not needed/used for indicators\n",
        "                elif trace_type == 'treemap':\n",
        "                     trace.marker.line.width = 1\n",
        "                     trace.marker.line.color = 'rgba(0,0,0,0.4)' # Darker line for contrast on light colors\n",
        "                     trace.textfont = getattr(trace, 'textfont', {}); trace.textfont.size = 11; trace.textfont.color = '#FFFFFF'\n",
        "                     # Default hovertemplate for treemaps\n",
        "                     trace.hovertemplate = '<b>%{label}</b><br>Value: %{value}<br>Parent: %{parent}<extra></extra>'\n",
        "\n",
        "            except AttributeError as ae: print(f\"Warning: Attribute error styling trace for '{chart_title}': {ae}\")\n",
        "            except Exception as e_trace: print(f\"Warning: General error styling trace for '{chart_title}': {e_trace}\")\n",
        "\n",
        "        # --- Apply Layout Updates ---\n",
        "        fig.update_layout(base_layout) # Apply base layout first\n",
        "\n",
        "        # --- Conditional Layout Adjustments ---\n",
        "        # Force category axis for specific time-based charts if needed\n",
        "        if chart_title in ['Promotions Over Time', 'Annual Hiring Volume', 'Approximate Annual Promotion Rate (%)', 'Hiring by Quarter (Trend)']:\n",
        "            if fig.layout.xaxis: fig.update_xaxes(type='category')\n",
        "\n",
        "        # Specific layout adjustments for specific chart types\n",
        "        if fig.data and hasattr(fig.data[0], 'type'):\n",
        "            first_trace_type = fig.data[0].type\n",
        "            if first_trace_type == 'sunburst': # Example: Sunburst often needs minimal margins\n",
        "                fig.update_layout(margin=dict(l=10, r=10, t=30, b=10), showlegend=False)\n",
        "            elif first_trace_type == 'pie': # Example: Donut charts might need specific legend handling\n",
        "                 # Handled per-chart basis if needed (like 'composition' chart)\n",
        "                 pass\n",
        "            elif first_trace_type == 'indicator': # Gauges often need different margins\n",
        "                 fig.update_layout(margin=dict(l=20, r=20, t=50, b=20))\n",
        "\n",
        "        # Adjustments for faceted charts (e.g., promotion quarters)\n",
        "        if chart_title == 'Promotions by Quarter (Faceted by Year)':\n",
        "             if fig.layout.annotations: # Clean facet labels\n",
        "                  fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
        "             # Ensure consistent axis titles across facets if needed\n",
        "             # fig.update_xaxes(title_text=\"Quarter\", matches='x') # Example if needed\n",
        "             # fig.update_yaxes(title_text=\"# Promotions\", matches='y') # Example if needed\n",
        "\n",
        "        # Adjustments for Distplot (from figure_factory)\n",
        "        if chart_title == 'Distribution of Time to Promotion (Distplot)':\n",
        "             fig.update_layout(barmode='overlay') # Overlay histograms\n",
        "             for trace in fig.data: # Style histogram and curve traces\n",
        "                 if trace.type == 'histogram': trace.marker.opacity = 0.6\n",
        "                 elif trace.type == 'scatter' and trace.mode == 'lines': trace.line.width = 2.5\n",
        "\n",
        "        # --- Encode to Dictionary ---\n",
        "        try:\n",
        "            # Use pio.to_json for robust serialization (handles numpy types), then load back to dict\n",
        "            return json.loads(pio.to_json(fig))\n",
        "        except Exception as e:\n",
        "            print(f\"Error encoding chart '{chart_title}' using pio.to_json/json.loads: {e}\")\n",
        "            return None\n",
        "    # --- End of encode_chart ---\n",
        "\n",
        "\n",
        "    # --- Chart Generation Blocks ---\n",
        "    # Each block attempts to create a specific chart, using the processed data\n",
        "    # and the encode_chart helper for styling and serialization.\n",
        "\n",
        "    # Chart 1: Composition by Job Level ('composition' / 'composition_detail') - Donut Charts\n",
        "    try:\n",
        "        fig = None\n",
        "        comp_data = comp_df.groupby(['job_function', 'job_level_title'], observed=False).size().reset_index(name='count')\n",
        "        comp_data['job_level_title'] = pd.Categorical(comp_data['job_level_title'], categories=level_order, ordered=True)\n",
        "        comp_data = comp_data.sort_values(['job_function', 'job_level_title'])\n",
        "\n",
        "        if not comp_data.empty:\n",
        "            fig = go.Figure()\n",
        "            functions = comp_data['job_function'].unique()\n",
        "            level_name_map = {'Individual Contributor': 'IC', 'Manager': 'Manager', 'Director': 'Director', 'Vice President': 'VP'}\n",
        "\n",
        "            # Create Product Development Donut\n",
        "            if 'Product Development' in functions:\n",
        "                prod_data = comp_data[comp_data['job_function'] == 'Product Development']\n",
        "                prod_total = prod_data['count'].sum()\n",
        "                prod_data['percentage'] = prod_data['count'] / prod_total * 100\n",
        "                prod_data['level_short'] = prod_data['job_level_title'].map(level_name_map).fillna(prod_data['job_level_title'])\n",
        "                prod_data['legend_text'] = prod_data.apply(lambda row: f\"{row['level_short']}: {int(row['count'])} ({row['percentage']:.1f}%)\", axis=1)\n",
        "                fig.add_trace(go.Pie(\n",
        "                    values=prod_data['count'], labels=prod_data['legend_text'], name='Product Development',\n",
        "                    domain=dict(x=[0, 0.40], y=[0, 1]), hole=0.6,\n",
        "                    marker_colors=[netflix_red, '#FF4D4D', '#FF8080', '#FFB3B3'], # Shades of primary\n",
        "                    textfont=dict(color='white', size=11), textinfo='none', showlegend=True, legendgroup=\"Prod\"\n",
        "                ))\n",
        "                fig.add_annotation(x=0.20, y=0.5, text=\"Product<br>Development\", showarrow=False, font=dict(size=13))\n",
        "\n",
        "            # Create Content & Studio Donut\n",
        "            if 'Content and Studio' in functions:\n",
        "                content_data = comp_data[comp_data['job_function'] == 'Content and Studio']\n",
        "                content_total = content_data['count'].sum()\n",
        "                content_data['percentage'] = content_data['count'] / content_total * 100\n",
        "                content_data['level_short'] = content_data['job_level_title'].map(level_name_map).fillna(content_data['job_level_title'])\n",
        "                content_data['legend_text'] = content_data.apply(lambda row: f\"{row['level_short']}: {int(row['count'])} ({row['percentage']:.1f}%)\", axis=1)\n",
        "                fig.add_trace(go.Pie(\n",
        "                    values=content_data['count'], labels=content_data['legend_text'], name='Content and Studio',\n",
        "                    domain=dict(x=[0.43, 0.83]), hole=0.6,\n",
        "                    marker_colors=['#8E8E8E', '#AAAAAA', '#CCCCCC', '#DDDDDD'], # Shades of grey\n",
        "                    textfont=dict(color='white', size=11), textinfo='none', showlegend=True, legendgroup=\"Cont\"\n",
        "                ))\n",
        "                fig.add_annotation(x=0.63, y=0.5, text=\"Content<br>& Studio\", showarrow=False, font=dict(size=13))\n",
        "\n",
        "            # Update layout for donut specifics (legend on right, height)\n",
        "            fig.update_layout(\n",
        "                height=380, showlegend=True,\n",
        "                legend=dict(orientation=\"v\", yanchor=\"middle\", y=0.5, xanchor=\"left\", x=0.85, itemsizing=\"constant\")\n",
        "                # Base layout handles margins, bg color etc.\n",
        "            )\n",
        "\n",
        "            # Encode the chart\n",
        "            encoded_chart = encode_chart(fig, 'Composition by Job Level')\n",
        "            if encoded_chart:\n",
        "                charts['composition'] = encoded_chart\n",
        "                charts['composition_detail'] = encoded_chart # Use same chart for both keys\n",
        "            else:\n",
        "                print(\"Skipping 'composition': Encoding failed.\")\n",
        "        else:\n",
        "            print(\"Skipping 'composition': No data for donut charts.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'composition' (Donut): {e}\")\n",
        "        traceback.print_exc()\n",
        "        if 'composition' in charts: del charts['composition']\n",
        "        if 'composition_detail' in charts: del charts['composition_detail']\n",
        "\n",
        "    # Chart 2: Roles (Manager vs IC) (Vertical Bar)\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'role' in comp_df.columns:\n",
        "            role_data = comp_df.groupby(['job_function', 'role'], observed=False).size().reset_index(name='count')\n",
        "            fig = px.bar(role_data, x='role', y='count', color='job_function',\n",
        "                         barmode='group', color_discrete_map=color_map,\n",
        "                         labels={'role': 'Role', 'count': '# Employees', 'job_function': 'Function'})\n",
        "            if fig:\n",
        "                 encoded_chart = encode_chart(fig, 'Managers vs. ICs')\n",
        "                 if encoded_chart: charts['roles'] = encoded_chart\n",
        "                 else: print(\"Skipping 'roles': Encoding failed.\")\n",
        "            else:\n",
        "                 print(\"Skipping 'roles': Figure object not created.\")\n",
        "        else:\n",
        "            print(\"Skipping 'roles': Missing 'role' column.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'roles': {e}\")\n",
        "        traceback.print_exc()\n",
        "        if 'roles' in charts: del charts['roles']\n",
        "\n",
        "    # Chart 3: Tenure Distribution (ECDF) ('tenure_distribution_violin') - ECDF Line\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'tenure_years' in comp_df.columns and comp_df['tenure_years'].notna().any():\n",
        "            fig = go.Figure()\n",
        "            for function in sorted(comp_df['job_function'].unique()):\n",
        "                # Ensure tenure is numeric and handle NaNs\n",
        "                func_data = pd.to_numeric(comp_df[comp_df['job_function'] == function]['tenure_years'], errors='coerce').dropna()\n",
        "                if not func_data.empty:\n",
        "                    ecdf = sm.distributions.ECDF(func_data)\n",
        "                    x_min, x_max = func_data.min(), func_data.max()\n",
        "                    # Handle case where all values are the same\n",
        "                    x_vals = np.array([x_min]) if x_min == x_max else np.linspace(x_min, x_max, num=100)\n",
        "                    y_vals = ecdf(x_vals)\n",
        "                    color = color_map.get(function, netflix_other)\n",
        "                    fig.add_trace(go.Scatter(\n",
        "                        x=x_vals, y=y_vals, mode='lines', name=function, line=dict(color=color),\n",
        "                        hovertemplate=(f'<b>{function}</b><br>Tenure: %{{x:.1f}} Yrs<br>Cum. Prob: %{{y:.2f}}<extra></extra>')\n",
        "                    ))\n",
        "            fig.update_layout(xaxis_title='Tenure (Yrs)', yaxis_title='Cumulative Probability')\n",
        "            if fig and fig.data:\n",
        "                encoded_chart = encode_chart(fig, 'Tenure Distribution (ECDF)')\n",
        "                if encoded_chart: charts['tenure_distribution_violin'] = encoded_chart\n",
        "                else: print(\"Skipping 'tenure_distribution_violin': Encoding failed.\")\n",
        "            else: print(\"Skipping 'tenure_distribution_violin': Figure object created but has no data.\")\n",
        "        else: print(\"Skipping 'tenure_distribution_violin': Missing or insufficient 'tenure_years' data.\")\n",
        "    except ImportError: print(\"Error generating Chart 'tenure_distribution_violin': statsmodels not installed or found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'tenure_distribution_violin': {e}\"); traceback.print_exc()\n",
        "        if 'tenure_distribution_violin' in charts: del charts['tenure_distribution_violin']\n",
        "\n",
        "    # Chart 4: Span of Control (Box Plot) ('span_control_box')\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'is_manager' in comp_df.columns and 'span_of_control' in comp_df.columns:\n",
        "            managers_df = comp_df[comp_df['is_manager']].copy()\n",
        "            managers_df['span_of_control'] = pd.to_numeric(managers_df['span_of_control'], errors='coerce')\n",
        "            managers_df_filtered = managers_df[managers_df['span_of_control'] > 0]\n",
        "\n",
        "            if not managers_df_filtered.empty:\n",
        "                fig = px.box(\n",
        "                    managers_df_filtered,\n",
        "                    y='span_of_control',\n",
        "                    x='job_function',\n",
        "                    color='job_function',\n",
        "                    points='outliers',\n",
        "                    color_discrete_map=color_map,\n",
        "                    labels={\n",
        "                        'span_of_control': 'Direct Reports (Span>0)',\n",
        "                        'job_function': 'Function'\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                for trace in fig.data:\n",
        "                    func = trace.name\n",
        "                    trace.update(\n",
        "                        hoverinfo='text',\n",
        "                        hovertemplate=None,\n",
        "                        text=[f\"Function: {func}<br>Direct Reports: {trace.y[i]:.0f}\" for i in range(len(trace.y))],\n",
        "                        hoverlabel=dict(bgcolor='rgba(0,0,0,0.9)', font_size=12, font_family='Arial')\n",
        "                    )\n",
        "\n",
        "                encoded_chart = encode_chart(fig, 'Span of Control (Managers w/ Reports)')\n",
        "                if encoded_chart:\n",
        "                    charts['span_control_box'] = encoded_chart\n",
        "                else:\n",
        "                    print(\"Skipping 'span_control_box': Encoding failed.\")\n",
        "            else:\n",
        "                print(\"Skipping 'span_control_box': No managers found with > 0 reports.\")\n",
        "        else:\n",
        "            print(\"Skipping 'span_control_box': Missing 'span_of_control' or 'is_manager' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'span_control_box': {e}\")\n",
        "        traceback.print_exc()\n",
        "        charts.pop('span_control_box', None)\n",
        "\n",
        "    # Chart 5: Promotions Trend ('promotions_trend') - Line\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'is_promoted' in comp_df.columns and 'promotion_year' in comp_df.columns:\n",
        "            promo_df = comp_df[comp_df['is_promoted']].copy()\n",
        "            # Ensure promotion_year is numeric and handle NaNs\n",
        "            promo_df['promotion_year'] = pd.to_numeric(promo_df['promotion_year'], errors='coerce').astype('Int64')\n",
        "            promo_df.dropna(subset=['promotion_year'], inplace=True)\n",
        "\n",
        "            if not promo_df.empty:\n",
        "                promo_trend_data = promo_df.groupby(['promotion_year', 'job_function'], observed=False).size().reset_index(name='count')\n",
        "                fig = px.line(promo_trend_data, x='promotion_year', y='count', color='job_function',\n",
        "                              markers=True, color_discrete_map=color_map,\n",
        "                              labels={'count': '# Promotions', 'promotion_year': 'Year', 'job_function': 'Function'})\n",
        "                if fig:\n",
        "                    fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Year: %{x}<br>Promotions: %{y}<extra></extra>')\n",
        "                    encoded_chart = encode_chart(fig, 'Promotions Over Time') # encode_chart handles category axis\n",
        "                    if encoded_chart: charts['promotions_trend'] = encoded_chart\n",
        "                    else: print(\"Skipping 'promotions_trend': Encoding failed.\")\n",
        "                else: print(\"Skipping 'promotions_trend': Figure object not created.\")\n",
        "            else: print(\"Skipping 'promotions_trend': No valid numeric promotion years found after cleaning.\")\n",
        "        else: print(\"Skipping 'promotions_trend': Missing 'promotion_year' or 'is_promoted' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promotions_trend': {e}\"); traceback.print_exc()\n",
        "        if 'promotions_trend' in charts: del charts['promotions_trend']\n",
        "\n",
        "    # Chart 6: Hiring by Quarter ('hiring_quarter') - Line\n",
        "    try:\n",
        "        fig = None\n",
        "        # Requires hire_year (numeric) and hire_quarter (numeric/string)\n",
        "        if 'hire_year' in comp_df.columns and 'hire_quarter' in comp_df.columns:\n",
        "             # Ensure hire_year is numeric Int64\n",
        "             comp_df['hire_year_num'] = pd.to_numeric(comp_df['hire_year'], errors='coerce').astype('Int64')\n",
        "             # Ensure hire_quarter is usable (e.g., string 'YYYYQ#')\n",
        "             comp_df['hire_year_quarter_str'] = np.where(\n",
        "                  comp_df['hire_year_num'].notna() & comp_df['hire_quarter'].notna(),\n",
        "                  comp_df['hire_year_num'].astype(str) + 'Q' + comp_df['hire_quarter'].astype(str).str.replace(r'\\.0$', '', regex=True), # Handle potential float conversion\n",
        "                  pd.NA\n",
        "             )\n",
        "             hire_q_data = comp_df.dropna(subset=['hire_year_quarter_str']).groupby(\n",
        "                 ['hire_year_quarter_str', 'job_function'], observed=False\n",
        "             ).size().reset_index(name='count')\n",
        "             # Sort by the constructed year-quarter string for chronological order\n",
        "             hire_q_data = hire_q_data.sort_values('hire_year_quarter_str')\n",
        "\n",
        "             if not hire_q_data.empty:\n",
        "                 fig = px.line(hire_q_data, x='hire_year_quarter_str', y='count', color='job_function',\n",
        "                              markers=True, color_discrete_map=color_map,\n",
        "                              labels={'count': '# Hires', 'hire_year_quarter_str': 'Year-Quarter', 'job_function': 'Function'})\n",
        "                 if fig:\n",
        "                     fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Quarter: %{x}<br>Hires: %{y}<extra></extra>')\n",
        "                     encoded_chart = encode_chart(fig, 'Hiring by Quarter (Trend)') # encode_chart handles category axis\n",
        "                     if encoded_chart: charts['hiring_quarter'] = encoded_chart\n",
        "                     else: print(\"Skipping 'hiring_quarter': Encoding failed.\")\n",
        "                 else: print(\"Skipping 'hiring_quarter': Figure object not created.\")\n",
        "             else: print(\"Skipping 'hiring_quarter': No data after creating YYYYQ# labels.\")\n",
        "        else: print(\"Skipping 'hiring_quarter': Missing 'hire_quarter' or 'hire_year' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'hiring_quarter' (Line): {e}\"); traceback.print_exc()\n",
        "        if 'hiring_quarter' in charts: del charts['hiring_quarter']\n",
        "\n",
        "    # Chart 7: Time to Promotion by Level ('promo_timing_level' / 'promo_timing_level_main') - Box\n",
        "    try:\n",
        "        fig = None\n",
        "        promo_df_ttp = pd.DataFrame()\n",
        "        if 'time_to_promotion' in comp_df.columns:\n",
        "            comp_df['time_to_promotion_num'] = pd.to_numeric(comp_df['time_to_promotion'], errors='coerce')\n",
        "            promo_df_ttp = comp_df[comp_df['time_to_promotion_num'] >= 0].copy()\n",
        "\n",
        "        if not promo_df_ttp.empty and 'job_level_title' in promo_df_ttp.columns:\n",
        "            promo_df_ttp['job_level_title'] = pd.Categorical(promo_df_ttp['job_level_title'], categories=level_order, ordered=True)\n",
        "            promo_df_ttp = promo_df_ttp.sort_values('job_level_title')\n",
        "\n",
        "            fig = px.box(\n",
        "                promo_df_ttp,\n",
        "                x='job_level_title',\n",
        "                y='time_to_promotion_num',\n",
        "                color='job_function',\n",
        "                points=False,\n",
        "                color_discrete_map=color_map,\n",
        "                labels={\n",
        "                    'job_level_title': 'Level Promoted Into',\n",
        "                    'time_to_promotion_num': 'Time to Promotion (Yrs)',\n",
        "                    'job_function': 'Function'\n",
        "                }\n",
        "            )\n",
        "\n",
        "            for trace in fig.data:\n",
        "                job_func = trace.name\n",
        "                trace.update(\n",
        "                    hoverinfo='text',\n",
        "                    hovertemplate=None,\n",
        "                    text=[f\"Level: {trace.x[i]}<br>Function: {job_func}\" for i in range(len(trace.x))],\n",
        "                    hoverlabel=dict(bgcolor='rgba(0,0,0,0.9)', font_size=12, font_family='Arial')\n",
        "                )\n",
        "\n",
        "            encoded_chart = encode_chart(fig, 'Time to Promotion by Level')\n",
        "            if encoded_chart:\n",
        "                charts['promo_timing_level'] = encoded_chart\n",
        "                charts['promo_timing_level_main'] = encoded_chart\n",
        "            else:\n",
        "                print(\"Skipping 'promo_timing_level': Encoding failed.\")\n",
        "        else:\n",
        "            print(\"Skipping 'promo_timing_level': Missing/invalid 'time_to_promotion' or 'job_level_title' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promo_timing_level': {e}\")\n",
        "        traceback.print_exc()\n",
        "        charts.pop('promo_timing_level', None)\n",
        "        charts.pop('promo_timing_level_main', None)\n",
        "\n",
        "    # Chart 8: Manager vs IC Ratio ('mgmt_ratio') - Donut (Specific layout)\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'role' in comp_df.columns:\n",
        "            role_data = comp_df.groupby(['job_function', 'role'], observed=False).size().unstack(fill_value=0)\n",
        "            required_roles = ['Individual Contributor', 'People Manager']\n",
        "            if ('Product Development' in role_data.index and 'Content and Studio' in role_data.index and\n",
        "                all(role in role_data.columns for role in required_roles)):\n",
        "\n",
        "                fig = go.Figure()\n",
        "                prod_vals = role_data.loc['Product Development']; cont_vals = role_data.loc['Content and Studio']\n",
        "                prod_ic = prod_vals.get('Individual Contributor', 0); prod_mgr = prod_vals.get('People Manager', 0)\n",
        "                cont_ic = cont_vals.get('Individual Contributor', 0); cont_mgr = cont_vals.get('People Manager', 0)\n",
        "\n",
        "                # Add Pie Traces with specific domains and colors\n",
        "                fig.add_trace(go.Pie(\n",
        "                    values=[prod_ic, prod_mgr], labels=['IC', 'Manager'], name='Product Dev',\n",
        "                    domain=dict(x=[0.25, 0.75], y=[0.55, 1.0]), hole=0.4, # Top donut\n",
        "                    marker_colors=[netflix_grey, netflix_red], # IC=grey, Mgr=red\n",
        "                    hovertemplate='<b>%{data.name}</b><br>%{label}: %{percent:.1%}<extra></extra>',\n",
        "                    showlegend=True, textinfo='none'\n",
        "                ))\n",
        "                fig.add_trace(go.Pie(\n",
        "                    values=[cont_ic, cont_mgr], labels=['IC', 'Manager'], name='Content & Studio',\n",
        "                    domain=dict(x=[0.25, 0.75], y=[0.05, 0.50]), hole=0.4, # Bottom donut\n",
        "                    marker_colors=[netflix_grey, netflix_red], # IC=grey, Mgr=red\n",
        "                    hovertemplate='<b>%{data.name}</b><br>%{label}: %{percent:.1%}<extra></extra>',\n",
        "                    showlegend=True, textinfo='none'\n",
        "                ))\n",
        "                # Add annotations for function labels\n",
        "                annotations = [\n",
        "                    dict(text=\"<b>Product <br>Development</b>\", x=0.00, y=0.77, showarrow=False, font=dict(size=14), align=\"center\", xref='paper', yref='paper'),\n",
        "                    dict(text=\"<b>Content <br>& Studio</b>\", x=0.95, y=0.27, showarrow=False, font=dict(size=14), align=\"center\", xref='paper', yref='paper')\n",
        "                ]\n",
        "                # Apply specific layout for this chart\n",
        "                fig.update_layout(\n",
        "                    annotations=annotations, margin=dict(l=10, r=10, t=30, b=20), height=450, # Adjusted height\n",
        "                    showlegend=True,\n",
        "                    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.1, xanchor=\"center\", x=0.5), # Legend below\n",
        "                    title='Manager vs IC Ratio' # Title set here\n",
        "                    # Background colors handled by encode_chart\n",
        "                )\n",
        "                # Encode this specific layout\n",
        "                encoded_chart = encode_chart(fig, 'Manager vs IC Ratio') # Pass title again for logging\n",
        "                if encoded_chart: charts['mgmt_ratio'] = encoded_chart\n",
        "                else: print(\"Skipping 'mgmt_ratio': Encoding failed.\")\n",
        "            else: print(\"Skipping 'mgmt_ratio': Missing required data, functions, or roles.\")\n",
        "        else: print(\"Skipping 'mgmt_ratio': Missing 'role' column.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'mgmt_ratio': {e}\"); traceback.print_exc()\n",
        "        if 'mgmt_ratio' in charts: del charts['mgmt_ratio']\n",
        "\n",
        "    # Chart 9: Span Distribution ('span_distribution') - Horizontal Bar\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'is_manager' in comp_df.columns and 'span_of_control' in comp_df.columns:\n",
        "            managers_df = comp_df[comp_df['is_manager']].copy()\n",
        "            managers_df['span_of_control'] = pd.to_numeric(managers_df['span_of_control'], errors='coerce')\n",
        "            managers_df.dropna(subset=['span_of_control'], inplace=True)\n",
        "\n",
        "            if not managers_df.empty:\n",
        "                bins = [-1, 0, 3, 6, 9, np.inf]; labels = ['0', '1-3', '4-6', '7-9', '10+']\n",
        "                managers_df['span_bin'] = pd.cut(managers_df['span_of_control'], bins=bins, labels=labels, right=True)\n",
        "                span_dist_data = managers_df.groupby(['job_function', 'span_bin'], observed=False).size().unstack(fill_value=0)\n",
        "                # Calculate percentage within each function\n",
        "                span_dist_pct = span_dist_data.apply(lambda x: x / x.sum() * 100 if x.sum() > 0 else x, axis=1).fillna(0)\n",
        "                # Melt for table structure\n",
        "                span_dist_melt = span_dist_pct.reset_index().melt(id_vars='job_function', var_name='span_bin', value_name='percentage')\n",
        "\n",
        "                fig = px.bar(span_dist_melt, y='span_bin', x='percentage', color='job_function',\n",
        "                             barmode='group', orientation='h', color_discrete_map=color_map,\n",
        "                             category_orders={'span_bin': labels[::-1]}, # Reverse order for horizontal\n",
        "                             labels={'span_bin': 'Span of Control', 'percentage': '% of Managers', 'job_function': 'Function'})\n",
        "                if fig:\n",
        "                    fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Span: %{y}<br>% Managers: %{x:.1f}%<extra></extra>')\n",
        "                    # Override legend position for horizontal bar chart\n",
        "                    fig.update_layout(legend=dict(orientation='h', yanchor='top', y=-0.30, x=0.5, xanchor='center'))\n",
        "                    encoded_chart = encode_chart(fig, 'Manager Span Distribution (%)')\n",
        "                    if encoded_chart: charts['span_distribution'] = encoded_chart\n",
        "                    else: print(\"Skipping 'span_distribution': Encoding failed.\")\n",
        "                else: print(\"Skipping 'span_distribution': Figure object not created.\")\n",
        "            else: print(\"Skipping 'span_distribution': No managers with valid span data found.\")\n",
        "        else: print(\"Skipping 'span_distribution': Missing 'span_of_control' or 'is_manager' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'span_distribution': {e}\"); traceback.print_exc()\n",
        "        if 'span_distribution' in charts: del charts['span_distribution']\n",
        "\n",
        "    # Chart 10: Leadership Distribution ('leadership_distribution') - Bar\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'job_level_title' in comp_df.columns and 'job_function' in comp_df.columns:\n",
        "            leadership_levels = ['Director', 'Vice President']\n",
        "            leadership_df = comp_df[comp_df['job_level_title'].isin(leadership_levels)].copy()\n",
        "\n",
        "            if not leadership_df.empty:\n",
        "                total_by_func = comp_df.groupby('job_function', observed=False).size()\n",
        "                leadership_counts = leadership_df.groupby(['job_function', 'job_level_title'], observed=False).size()\n",
        "                # Calculate percentage of *total* function employees at these levels\n",
        "                leadership_pcts = (leadership_counts.div(total_by_func, level='job_function') * 100).reset_index(name='percentage')\n",
        "                leadership_pcts['percentage'] = leadership_pcts['percentage'].fillna(0)\n",
        "\n",
        "                fig = px.bar(leadership_pcts, x='job_level_title', y='percentage', color='job_function',\n",
        "                             barmode='group', color_discrete_map=color_map,\n",
        "                             category_orders={'job_level_title': leadership_levels},\n",
        "                             labels={'percentage': '% of Function Employees', 'job_level_title': 'Leadership Level', 'job_function': 'Function'})\n",
        "                if fig:\n",
        "                    fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Level: %{x}<br>% of Function: %{y:.1f}%<extra></extra>')\n",
        "                    encoded_chart = encode_chart(fig, 'Leadership Representation (% of Function)')\n",
        "                    if encoded_chart: charts['leadership_distribution'] = encoded_chart\n",
        "                    else: print(\"Skipping 'leadership_distribution': Encoding failed.\")\n",
        "                else: print(\"Skipping 'leadership_distribution': Figure object not created.\")\n",
        "            else: print(\"Skipping 'leadership_distribution': No employees found at Director or VP levels.\")\n",
        "        else: print(\"Skipping 'leadership_distribution': Missing 'job_level_title' or 'job_function' columns.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'leadership_distribution': {e}\"); traceback.print_exc()\n",
        "        if 'leadership_distribution' in charts: del charts['leadership_distribution']\n",
        "\n",
        "    # Chart 11: Average Tenure by Level ('tenure_level') - Line\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'tenure_years' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "             # Ensure tenure is numeric\n",
        "             comp_df['tenure_years_num'] = pd.to_numeric(comp_df['tenure_years'], errors='coerce')\n",
        "             tenure_level_data = comp_df.dropna(subset=['tenure_years_num']).groupby(\n",
        "                 ['job_function', 'job_level_title'], observed=False\n",
        "             )['tenure_years_num'].mean().reset_index()\n",
        "             # Order the levels\n",
        "             tenure_level_data['job_level_title'] = pd.Categorical(tenure_level_data['job_level_title'], categories=level_order, ordered=True)\n",
        "             tenure_level_data = tenure_level_data.sort_values('job_level_title')\n",
        "\n",
        "             if not tenure_level_data.empty:\n",
        "                  fig = px.line(tenure_level_data, x='job_level_title', y='tenure_years_num', color='job_function',\n",
        "                                markers=True, color_discrete_map=color_map,\n",
        "                                labels={'tenure_years_num': 'Avg Tenure (Yrs)', 'job_level_title': 'Job Level', 'job_function': 'Function'})\n",
        "                  if fig:\n",
        "                      fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Level: %{x}<br>Avg Tenure: %{y:.1f} Yrs<extra></extra>')\n",
        "                      # Apply category order to axis\n",
        "                      fig.update_layout(xaxis_categoryorder='array', xaxis_categoryarray=level_order)\n",
        "                      encoded_chart = encode_chart(fig, 'Average Tenure by Level (Trend)')\n",
        "                      if encoded_chart: charts['tenure_level'] = encoded_chart\n",
        "                      else: print(\"Skipping 'tenure_level': Encoding failed.\")\n",
        "                  else: print(\"Skipping 'tenure_level': Figure object not created.\")\n",
        "             else: print(\"Skipping 'tenure_level': No data after grouping for line chart.\")\n",
        "        else: print(\"Skipping 'tenure_level': Missing or insufficient 'tenure_years' or 'job_level_title' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'tenure_level' (Line): {e}\"); traceback.print_exc()\n",
        "        if 'tenure_level' in charts: del charts['tenure_level']\n",
        "\n",
        "    # Chart 12: Hiring by Year ('hiring_year') - Bar\n",
        "    try:\n",
        "        fig = None\n",
        "        # Use hire_year_int created earlier if available\n",
        "        hire_year_col = 'hire_year_int' if 'hire_year_int' in comp_df.columns else 'hire_year'\n",
        "        if hire_year_col in comp_df.columns and comp_df[hire_year_col].notna().any():\n",
        "            # Ensure the column is Int64 before grouping\n",
        "            comp_df[hire_year_col] = pd.to_numeric(comp_df[hire_year_col], errors='coerce').astype('Int64')\n",
        "            hire_year_data = comp_df.dropna(subset=[hire_year_col]).groupby(\n",
        "                 [hire_year_col, 'job_function'], observed=False\n",
        "            ).size().reset_index(name='count')\n",
        "\n",
        "            if not hire_year_data.empty:\n",
        "                fig = px.bar(hire_year_data, x=hire_year_col, y='count', color='job_function',\n",
        "                             barmode='group', color_discrete_map=color_map,\n",
        "                             labels={'count': '# Hires', hire_year_col: 'Year', 'job_function': 'Function'})\n",
        "                if fig:\n",
        "                    fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Year: %{x}<br>Hires: %{y}<extra></extra>')\n",
        "                    encoded_chart = encode_chart(fig, 'Annual Hiring Volume') # encode_chart handles category axis\n",
        "                    if encoded_chart: charts['hiring_year'] = encoded_chart\n",
        "                    else: print(\"Skipping 'hiring_year': Encoding failed.\")\n",
        "                else: print(\"Skipping 'hiring_year': Figure object not created.\")\n",
        "            else: print(\"Skipping 'hiring_year': No valid numeric hire years found after cleaning.\")\n",
        "        else: print(f\"Skipping 'hiring_year': Missing '{hire_year_col}' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'hiring_year': {e}\"); traceback.print_exc()\n",
        "        if 'hiring_year' in charts: del charts['hiring_year']\n",
        "\n",
        "    # Chart 13: Hiring by Level ('hiring_level') - Bar (% of Hires)\n",
        "    # *** CORRECTED MELT LOGIC ***\n",
        "    try:\n",
        "        fig = None\n",
        "        hire_year_col = 'hire_year_int' if 'hire_year_int' in comp_df.columns else 'hire_year'\n",
        "        if hire_year_col in comp_df.columns and comp_df[hire_year_col].notna().any():\n",
        "            # Define hires based on having a valid hire year\n",
        "            hires_df = comp_df.dropna(subset=[hire_year_col])\n",
        "            if not hires_df.empty and 'job_level_title' in hires_df.columns:\n",
        "                 # Calculate counts per function/level among hires\n",
        "                 hire_levels = hires_df.groupby(['job_function', 'job_level_title'], observed=False).size().unstack(fill_value=0)\n",
        "                 # Calculate percentage *within each function's hires*\n",
        "                 # axis=1 calculates percentages across columns (levels) for each function (row)\n",
        "                 hire_levels_pct = hire_levels.apply(lambda x: x / x.sum() * 100 if x.sum() > 0 else x, axis=1).reset_index()\n",
        "                 # Melt: Keep 'job_function' fixed, unpivot the level columns\n",
        "                 hire_level_melt = hire_levels_pct.melt(id_vars='job_function', var_name='job_level_title', value_name='percentage') # Corrected id_vars\n",
        "                 # Order levels\n",
        "                 hire_level_melt['job_level_title'] = pd.Categorical(hire_level_melt['job_level_title'], categories=level_order, ordered=True)\n",
        "                 hire_level_melt = hire_level_melt.sort_values('job_level_title')\n",
        "\n",
        "                 fig = px.bar(hire_level_melt, x='job_level_title', y='percentage', color='job_function',\n",
        "                              barmode='group', color_discrete_map=color_map,\n",
        "                              labels={'percentage': '% of Function Hires', 'job_level_title': 'Level Hired Into', 'job_function': 'Function'})\n",
        "                 if fig:\n",
        "                     fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Level: %{x}<br>% Hires: %{y:.1f}%<extra></extra>')\n",
        "                     encoded_chart = encode_chart(fig, 'New Hire Distribution by Level (%)')\n",
        "                     if encoded_chart: charts['hiring_level'] = encoded_chart\n",
        "                     else: print(\"Skipping 'hiring_level': Encoding failed.\")\n",
        "                 else: print(\"Skipping 'hiring_level': Figure object not created.\")\n",
        "            else:\n",
        "                print(\"Skipping 'hiring_level': Missing 'job_level_title' data or no valid hires found.\")\n",
        "        else:\n",
        "            print(f\"Skipping 'hiring_level': Missing or invalid '{hire_year_col}' data required to identify hires.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'hiring_level': {e}\"); traceback.print_exc()\n",
        "        if 'hiring_level' in charts: del charts['hiring_level']\n",
        "\n",
        "\n",
        "    # Chart 14: Promotion Timeline Distribution ('promotion_timeline_hist') - Distplot\n",
        "    try:\n",
        "        fig = None\n",
        "        promo_df_hist = pd.DataFrame() # Initialize\n",
        "        if 'time_to_promotion_num' in comp_df.columns: # Use numeric version created earlier\n",
        "             promo_df_hist = comp_df[comp_df['time_to_promotion_num'] >= 0].copy()\n",
        "\n",
        "        if not promo_df_hist.empty:\n",
        "            hist_data = []\n",
        "            group_labels = []\n",
        "            dist_colors = []\n",
        "            # Ensure functions are sorted for consistent legend order\n",
        "            sorted_functions = sorted(promo_df_hist['job_function'].unique())\n",
        "            for function in sorted_functions:\n",
        "                # Extract TTP data for the function\n",
        "                func_data = promo_df_hist[promo_df_hist['job_function'] == function]['time_to_promotion_num'].tolist()\n",
        "                if func_data: # Only add if data exists\n",
        "                    hist_data.append(func_data)\n",
        "                    group_labels.append(function)\n",
        "                    dist_colors.append(color_map.get(function, netflix_other))\n",
        "\n",
        "            if hist_data: # Check if we collected any data to plot\n",
        "                fig = ff.create_distplot(\n",
        "                    hist_data, group_labels, colors=dist_colors,\n",
        "                    bin_size=0.5, # Adjust bin size as needed\n",
        "                    show_hist=True, show_curve=True, show_rug=False\n",
        "                )\n",
        "                fig.update_layout(\n",
        "                    xaxis_title='Time to Promotion (Yrs)', yaxis_title='Density',\n",
        "                    legend_title='Function'\n",
        "                    # Title set by encode_chart\n",
        "                )\n",
        "                encoded_chart = encode_chart(fig, 'Distribution of Time to Promotion (Distplot)')\n",
        "                if encoded_chart: charts['promotion_timeline_hist'] = encoded_chart\n",
        "                else: print(\"Skipping 'promotion_timeline_hist': Encoding failed.\")\n",
        "            else: print(\"Skipping 'promotion_timeline_hist': No valid data groups found for distplot.\")\n",
        "        else: print(\"Skipping 'promotion_timeline_hist': Missing or invalid 'time_to_promotion' data.\")\n",
        "    except ImportError: print(\"Error generating Chart 'promotion_timeline_hist': Plotly Figure Factory (ff) not available or import failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promotion_timeline_hist' (Distplot): {e}\"); traceback.print_exc()\n",
        "        if 'promotion_timeline_hist' in charts: del charts['promotion_timeline_hist']\n",
        "\n",
        "\n",
        "    # Chart 15: Tenure vs. Time to Promotion ('tenure_vs_ttp') - Scatter\n",
        "    try:\n",
        "        fig = None\n",
        "        # Use numeric versions created earlier if available\n",
        "        ttp_col = 'time_to_promotion_num' if 'time_to_promotion_num' in comp_df.columns else 'time_to_promotion'\n",
        "        tenure_col = 'tenure_years' # Assuming tenure_years is already numeric from load_data\n",
        "\n",
        "        if ttp_col in comp_df.columns and tenure_col in comp_df.columns:\n",
        "             # Ensure both columns are numeric and filter for valid TTP >= 0 and non-null tenure\n",
        "             comp_df[ttp_col] = pd.to_numeric(comp_df[ttp_col], errors='coerce')\n",
        "             comp_df[tenure_col] = pd.to_numeric(comp_df[tenure_col], errors='coerce')\n",
        "             promo_df_scatter = comp_df[(comp_df[ttp_col] >= 0) & comp_df[tenure_col].notna()].copy()\n",
        "        else: promo_df_scatter = pd.DataFrame()\n",
        "\n",
        "        if not promo_df_scatter.empty:\n",
        "            # Add trendline only if sufficient data points exist\n",
        "            trendline_arg = 'ols' if len(promo_df_scatter) > 10 else None\n",
        "            fig = px.scatter(promo_df_scatter, x=tenure_col, y=ttp_col, color='job_function',\n",
        "                             trendline=trendline_arg, trendline_scope=\"overall\", opacity=0.6, color_discrete_map=color_map,\n",
        "                             labels={tenure_col: 'Tenure at Promo (Yrs)', ttp_col: 'Time Since Last Promo (Yrs)', 'job_function': 'Function'})\n",
        "            if fig:\n",
        "                fig.update_traces(hovertemplate=('<b>%{data.name}</b><br>Tenure: %{x:.1f} Yrs<br>TTP: %{y:.1f} Yrs<extra></extra>'))\n",
        "                encoded_chart = encode_chart(fig, 'Tenure vs. Time to Promotion')\n",
        "                if encoded_chart: charts['tenure_vs_ttp'] = encoded_chart\n",
        "                else: print(\"Skipping 'tenure_vs_ttp': Encoding failed.\")\n",
        "            else: print(\"Skipping 'tenure_vs_ttp': Figure object not created.\")\n",
        "        else: print(\"Skipping 'tenure_vs_ttp': Missing or invalid 'time_to_promotion' or 'tenure_years' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'tenure_vs_ttp': {e}\"); traceback.print_exc()\n",
        "        if 'tenure_vs_ttp' in charts: del charts['tenure_vs_ttp']\n",
        "\n",
        "    # Chart 16: Average Time to Promotion (Gauge) ('promotion_timing_gauge') - Gauge (Specific layout)\n",
        "    try:\n",
        "        fig = None\n",
        "        ttp_col = 'time_to_promotion_num' if 'time_to_promotion_num' in comp_df.columns else 'time_to_promotion'\n",
        "        if ttp_col in comp_df.columns:\n",
        "             comp_df[ttp_col] = pd.to_numeric(comp_df[ttp_col], errors='coerce')\n",
        "             promo_df_gauge = comp_df[comp_df[ttp_col] >= 0].copy()\n",
        "        else: promo_df_gauge = pd.DataFrame()\n",
        "\n",
        "        if not promo_df_gauge.empty:\n",
        "            prod_avg_ttp = promo_df_gauge.loc[promo_df_gauge['job_function'] == 'Product Development', ttp_col].mean()\n",
        "            cont_avg_ttp = promo_df_gauge.loc[promo_df_gauge['job_function'] == 'Content and Studio', ttp_col].mean()\n",
        "\n",
        "            if pd.notna(prod_avg_ttp) and pd.notna(cont_avg_ttp):\n",
        "                # Determine gauge range dynamically\n",
        "                max_val = max(prod_avg_ttp, cont_avg_ttp, 0); min_range = 5 # Ensure gauge shows at least 5 years\n",
        "                max_gauge = max(min_range, np.ceil(max_val * 1.2)) # Add 20% buffer, minimum 5\n",
        "\n",
        "                fig = go.Figure()\n",
        "                fig.add_trace(go.Indicator(\n",
        "                    mode = \"gauge+number\", value = safe_round(prod_avg_ttp, 1), domain = {'x': [0, 0.48], 'y': [0, 1]},\n",
        "                    title = {'text': \"Product Dev Avg TTP\", 'font': {'size': 14}},\n",
        "                    gauge = {'axis': {'range': [0, max_gauge]}, 'bar': {'color': netflix_red}},\n",
        "                    number = {'suffix': \" yrs\", 'font': {'size': 18}}))\n",
        "                fig.add_trace(go.Indicator(\n",
        "                    mode = \"gauge+number\", value = safe_round(cont_avg_ttp, 1), domain = {'x': [0.52, 1.0], 'y': [0, 1]},\n",
        "                    title = {'text': \"Content Avg TTP\", 'font': {'size': 14}},\n",
        "                    gauge = {'axis': {'range': [0, max_gauge]}, 'bar': {'color': netflix_grey}},\n",
        "                    number = {'suffix': \" yrs\", 'font': {'size': 18}}))\n",
        "                # Apply specific layout for gauges\n",
        "                fig.update_layout(\n",
        "                    height=250, # Adjust height for gauges\n",
        "                    # Title handled by encode_chart, margins adjusted by encode_chart for indicators\n",
        "                )\n",
        "                encoded_chart = encode_chart(fig, 'Average Time to Promotion')\n",
        "                if encoded_chart: charts['promotion_timing_gauge'] = encoded_chart\n",
        "                else: print(\"Skipping 'promotion_timing_gauge': Encoding failed.\")\n",
        "            else: print(\"Skipping 'promotion_timing_gauge': Could not calculate valid average TTP for one or both functions.\")\n",
        "        else: print(\"Skipping 'promotion_timing_gauge': Missing or invalid 'time_to_promotion' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promotion_timing_gauge': {e}\"); traceback.print_exc()\n",
        "        if 'promotion_timing_gauge' in charts: del charts['promotion_timing_gauge']\n",
        "\n",
        "    # Chart 17: Tenure Density ('tenure_density_alt') - Density Line (using histogram approximation)\n",
        "    try:\n",
        "        fig = None\n",
        "        tenure_col = 'tenure_years' # Assuming tenure_years is already numeric from load_data\n",
        "        if tenure_col in comp_df.columns:\n",
        "             comp_df[tenure_col] = pd.to_numeric(comp_df[tenure_col], errors='coerce')\n",
        "             tenure_df_density = comp_df.dropna(subset=[tenure_col])\n",
        "        else: tenure_df_density = pd.DataFrame()\n",
        "\n",
        "        if not tenure_df_density.empty:\n",
        "            fig = go.Figure()\n",
        "            for function in sorted(tenure_df_density['job_function'].unique()):\n",
        "                func_data = tenure_df_density[tenure_df_density['job_function'] == function][tenure_col]\n",
        "                if not func_data.empty and len(func_data) > 1: # Need >1 point for density\n",
        "                    # Use numpy histogram to approximate density\n",
        "                    density, bin_edges = np.histogram(func_data, bins=30, density=True) # Adjust bins as needed\n",
        "                    x_vals = 0.5 * (bin_edges[1:] + bin_edges[:-1]) # Bin midpoints\n",
        "                    color = color_map.get(function, netflix_other)\n",
        "                    fig.add_trace(go.Scatter(\n",
        "                        x=x_vals, y=density, mode='lines', name=function, line=dict(color=color, shape='spline'), # Smoothed line\n",
        "                        hovertemplate=(f'<b>{function}</b><br>Tenure (approx): %{{x:.1f}} Yrs<br>Density: %{{y:.3f}}<extra></extra>')\n",
        "                    ))\n",
        "                elif not func_data.empty: print(f\"Warning: Only one data point for {function} in tenure density, skipping.\")\n",
        "\n",
        "            fig.update_layout(xaxis_title='Tenure (Yrs)', yaxis_title='Density', legend_title='Function')\n",
        "            if fig and fig.data:\n",
        "                encoded_chart = encode_chart(fig, 'Tenure Density by Function')\n",
        "                if encoded_chart: charts['tenure_density_alt'] = encoded_chart\n",
        "                else: print(\"Skipping 'tenure_density_alt': Encoding failed.\")\n",
        "            else: print(\"Skipping 'tenure_density_alt': Figure object created but has no data or insufficient data.\")\n",
        "        else: print(\"Skipping 'tenure_density_alt': Missing or insufficient 'tenure_years' data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'tenure_density_alt': {e}\"); traceback.print_exc()\n",
        "        if 'tenure_density_alt' in charts: del charts['tenure_density_alt']\n",
        "\n",
        "    # Chart 18: Average Span by Manager Level ('span_level_chart') - Line\n",
        "    try:\n",
        "        fig = None\n",
        "        if 'is_manager' in comp_df.columns and 'span_of_control' in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Ensure span is numeric, filter for managers with span > 0\n",
        "            managers_df = comp_df[comp_df['is_manager']].copy()\n",
        "            managers_df['span_of_control_num'] = pd.to_numeric(managers_df['span_of_control'], errors='coerce')\n",
        "            managers_df = managers_df[managers_df['span_of_control_num'] > 0]\n",
        "\n",
        "            if not managers_df.empty:\n",
        "                span_level_data = managers_df.groupby(['job_function', 'job_level_title'], observed=False)['span_of_control_num'].mean().reset_index()\n",
        "                # Order by specific manager levels\n",
        "                span_level_data['job_level_title'] = pd.Categorical(span_level_data['job_level_title'], categories=manager_level_order, ordered=True)\n",
        "                span_level_data = span_level_data.dropna(subset=['job_level_title']).sort_values('job_level_title')\n",
        "\n",
        "                if not span_level_data.empty:\n",
        "                     fig = px.line(span_level_data, x='job_level_title', y='span_of_control_num', color='job_function',\n",
        "                                   markers=True, color_discrete_map=color_map,\n",
        "                                   labels={'span_of_control_num': 'Avg Span (Mgrs w/ Span>0)', 'job_level_title': 'Manager Level', 'job_function': 'Function'})\n",
        "                     if fig:\n",
        "                         fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Level: %{x}<br>Avg Span: %{y:.1f}<extra></extra>')\n",
        "                         fig.update_layout(xaxis_categoryorder='array', xaxis_categoryarray=manager_level_order) # Ensure correct order on axis\n",
        "                         encoded_chart = encode_chart(fig, 'Average Span by Manager Level (Trend)')\n",
        "                         if encoded_chart: charts['span_level_chart'] = encoded_chart\n",
        "                         else: print(\"Skipping 'span_level_chart': Encoding failed.\")\n",
        "                     else: print(\"Skipping 'span_level_chart': Figure object not created.\")\n",
        "                else: print(\"Skipping 'span_level_chart': No valid data after filtering for manager levels.\")\n",
        "            else: print(\"Skipping 'span_level_chart': No managers with span > 0 found.\")\n",
        "        else: print(\"Skipping 'span_level_chart': Missing required columns.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'span_level_chart' (Line): {e}\"); traceback.print_exc()\n",
        "        if 'span_level_chart' in charts: del charts['span_level_chart']\n",
        "\n",
        "    # Chart 19: Approximate Promotion Rate Trend ('promotion_rate_chart') - Line\n",
        "    try:\n",
        "        fig = None\n",
        "        # Requires promotion status, promotion year, and hire year\n",
        "        promo_year_col = 'promotion_year_int' if 'promotion_year_int' in comp_df.columns else 'promotion_year'\n",
        "        hire_year_col = 'hire_year_int' if 'hire_year_int' in comp_df.columns else 'hire_year'\n",
        "\n",
        "        if ('is_promoted' in comp_df.columns and promo_year_col in comp_df.columns and\n",
        "            hire_year_col in comp_df.columns and comp_df[promo_year_col].notna().any() and\n",
        "            comp_df[hire_year_col].notna().any()):\n",
        "\n",
        "            # --- Calculate Promotions per Year/Function ---\n",
        "            promo_df = comp_df[comp_df['is_promoted']].copy()\n",
        "            # Ensure year is Int64 before grouping\n",
        "            promo_df[promo_year_col] = pd.to_numeric(promo_df[promo_year_col], errors='coerce').astype('Int64')\n",
        "            promo_counts = promo_df.dropna(subset=[promo_year_col]).groupby(\n",
        "                [promo_year_col, 'job_function'], observed=False\n",
        "            ).size()\n",
        "\n",
        "            # --- Calculate Cumulative Headcount per Year/Function ---\n",
        "            # Ensure hire_year is Int64 before grouping\n",
        "            temp_comp_df = comp_df.copy()\n",
        "            temp_comp_df[hire_year_col] = pd.to_numeric(temp_comp_df[hire_year_col], errors='coerce').astype('Int64')\n",
        "            # Group by hire year/function, sum, then calculate cumulative sum over years\n",
        "            total_counts = temp_comp_df.dropna(subset=[hire_year_col]).groupby(\n",
        "                 [hire_year_col, 'job_function'], observed=False\n",
        "            ).size().unstack(fill_value=0).cumsum().stack()\n",
        "\n",
        "            # --- Align and Calculate Rate ---\n",
        "            if not promo_counts.empty and not total_counts.empty:\n",
        "                # Determine common index (all years/functions present in either series)\n",
        "                all_years = sorted(list(set(promo_counts.index.get_level_values(0).dropna()) | set(total_counts.index.get_level_values(0).dropna())))\n",
        "                all_funcs = sorted(list(set(promo_counts.index.get_level_values(1)) | set(total_counts.index.get_level_values(1))))\n",
        "                multi_index = pd.MultiIndex.from_product([all_years, all_funcs], names=['year', 'job_function'])\n",
        "\n",
        "                # Reindex both series to the common index, filling missing values with 0\n",
        "                promo_counts_aligned = promo_counts.reindex(multi_index, fill_value=0)\n",
        "                total_counts_aligned = total_counts.reindex(multi_index, fill_value=0)\n",
        "\n",
        "                # Calculate rate, handle division by zero (replace Inf with 0 or NaN)\n",
        "                rate_data = (promo_counts_aligned / total_counts_aligned * 100).replace([np.inf, -np.inf], 0).fillna(0).reset_index(name='rate')\n",
        "\n",
        "                # Filter out years where total count was zero (leading to 0 rate) if desired, or keep them\n",
        "                # rate_data = rate_data[total_counts_aligned.reindex(multi_index, fill_value=0).reset_index(name='total')['total'] > 0]\n",
        "\n",
        "                if not rate_data.empty:\n",
        "                    fig = px.line(rate_data, x='year', y='rate', color='job_function',\n",
        "                                  markers=True, color_discrete_map=color_map,\n",
        "                                  labels={'rate': 'Approx. Promotion Rate (%)', 'year': 'Year', 'job_function': 'Function'})\n",
        "                    if fig:\n",
        "                        fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Year: %{x}<br>Rate: %{y:.1f}%<extra></extra>')\n",
        "                        fig.update_layout(yaxis_ticksuffix='%')\n",
        "                        encoded_chart = encode_chart(fig, 'Approximate Annual Promotion Rate (%)') # encode_chart handles category axis\n",
        "                        if encoded_chart: charts['promotion_rate_chart'] = encoded_chart\n",
        "                        else: print(\"Skipping 'promotion_rate_chart': Encoding failed.\")\n",
        "                    else: print(\"Skipping 'promotion_rate_chart': Figure object not created.\")\n",
        "                else: print(\"Skipping 'promotion_rate_chart': No valid rate data after calculation/filtering.\")\n",
        "            else: print(\"Skipping 'promotion_rate_chart': Insufficient promotion or total count data.\")\n",
        "        else: print(f\"Skipping 'promotion_rate_chart': Missing required promotion_year, hire_year, or is_promoted data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promotion_rate_chart': {e}\"); traceback.print_exc()\n",
        "        if 'promotion_rate_chart' in charts: del charts['promotion_rate_chart']\n",
        "\n",
        "    # Chart 20: Promotions by Quarter ('promotion_quarter_chart') - Faceted Bar\n",
        "    try:\n",
        "        fig = None\n",
        "        chart_title = \"\"\n",
        "        # Use datetime version of promotion date\n",
        "        promo_date_col = 'promotion_date_dt'\n",
        "        if promo_date_col in comp_df.columns and 'is_promoted' in comp_df.columns:\n",
        "            # Filter for promoted employees with valid datetime objects\n",
        "            promo_q_df = comp_df[comp_df['is_promoted'] & comp_df[promo_date_col].notna()].copy()\n",
        "\n",
        "            if not promo_q_df.empty:\n",
        "                # Extract year and quarter\n",
        "                promo_q_df['promotion_year_str'] = promo_q_df[promo_date_col].dt.year.astype(str)\n",
        "                promo_q_df['promotion_quarter_str'] = 'Q' + promo_q_df[promo_date_col].dt.quarter.astype(str)\n",
        "                # Group by quarter, year, function\n",
        "                promo_q_data = promo_q_df.groupby(\n",
        "                    ['promotion_quarter_str', 'promotion_year_str', 'job_function'], observed=False\n",
        "                ).size().reset_index(name='count')\n",
        "                # Define order for quarters and years\n",
        "                unique_years = sorted(promo_q_data['promotion_year_str'].unique())\n",
        "                quarter_order = ['Q1', 'Q2', 'Q3', 'Q4']\n",
        "                # Apply categorical ordering\n",
        "                promo_q_data['promotion_quarter_str'] = pd.Categorical(promo_q_data['promotion_quarter_str'], categories=quarter_order, ordered=True)\n",
        "                promo_q_data = promo_q_data.sort_values(['promotion_year_str', 'promotion_quarter_str'])\n",
        "\n",
        "                if len(unique_years) == 1: # Single year -> Simple bar chart\n",
        "                    year_label = unique_years[0]\n",
        "                    fig = px.bar(promo_q_data, x='promotion_quarter_str', y='count', color='job_function',\n",
        "                                 barmode='group', color_discrete_map=color_map,\n",
        "                                 labels={'promotion_quarter_str': 'Quarter', 'count': '# Promotions', 'job_function': 'Function'})\n",
        "                    chart_title = f'Promotions by Quarter ({year_label})'\n",
        "                elif len(unique_years) > 1: # Multiple years -> Faceted bar chart\n",
        "                    wrap_cols = 2 if len(unique_years) <= 4 else 3 # Adjust wrap based on number of years\n",
        "                    fig = px.bar(promo_q_data, x='promotion_quarter_str', y='count', color='job_function',\n",
        "                                 barmode='group', facet_col='promotion_year_str', facet_col_wrap=wrap_cols,\n",
        "                                 category_orders={'promotion_year_str': unique_years, 'promotion_quarter_str': quarter_order},\n",
        "                                 color_discrete_map=color_map,\n",
        "                                 labels={'promotion_quarter_str': 'Quarter', 'count': '# Promotions', 'job_function': 'Function'})\n",
        "                    chart_title = 'Promotions by Quarter (Faceted by Year)'\n",
        "                    # Remove individual axis titles for facets for cleaner look\n",
        "                    fig.for_each_xaxis(lambda axis: axis.update(title_text=''))\n",
        "                    fig.for_each_yaxis(lambda axis: axis.update(title_text=''))\n",
        "                else: print(\"Skipping 'promotion_quarter_chart': No unique years found.\")\n",
        "\n",
        "                if fig: # Check if fig was successfully created\n",
        "                    fig.update_traces(hovertemplate='<b>%{data.name}</b><br>Quarter: %{x}<br>Promotions: %{y}<extra></extra>')\n",
        "                    encoded_chart = encode_chart(fig, chart_title) # encode_chart handles facet label cleaning\n",
        "                    if encoded_chart: charts['promotion_quarter_chart'] = encoded_chart\n",
        "                    else: print(f\"Skipping '{chart_title}': Encoding failed.\")\n",
        "            else: print(\"Skipping 'promotion_quarter_chart': No valid promotion dates or no promotions.\")\n",
        "        else: print(f\"Skipping 'promotion_quarter_chart': Missing '{promo_date_col}' or 'is_promoted' column.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating Chart 'promotion_quarter_chart': {e}\"); traceback.print_exc()\n",
        "        if 'promotion_quarter_chart' in charts: del charts['promotion_quarter_chart']\n",
        "\n",
        "    print(f\"Generated {len(charts)} chart specifications.\")\n",
        "    return charts\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# # 7. Summary Statistics Generation\n",
        "# =============================================================================\n",
        "# Description: This section defines the `generate_summary_stats` function.\n",
        "# It calculates key aggregate metrics (total employees, avg tenure, avg span,\n",
        "# avg TTP) overall and by function. It also calculates Year-over-Year (YoY)\n",
        "# changes comparing 2023 vs 2022 for hiring counts, promotion counts, average TTP\n",
        "# for promotions in those years, and the difference in *current* average tenure\n",
        "# between the 2023 and 2022 hire cohorts. These calculated YoY values are\n",
        "# assigned to the specific keys expected by the HTML template's KPI cards.\n",
        "# YoY changes requiring full historical snapshots (like YoY change in total active\n",
        "# headcount or avg span of the *current* workforce) are set to None.\n",
        "\n",
        "\n",
        "def generate_summary_stats(df):\n",
        "    \"\"\"\n",
        "    Calculates summary statistics for the dashboard's key metric displays.\n",
        "\n",
        "    Computes overall and function-specific averages for tenure, time-to-promotion,\n",
        "    and span of control. Calculates YoY changes (2023 vs 2022) for hiring counts,\n",
        "    promotion counts, average TTP (for promotions *in* those years), and the\n",
        "    difference in current average tenure between 2023 and 2022 hire cohorts,\n",
        "    assigning them to the specific keys expected by the template's KPI cards.\n",
        "    Sets YoY changes requiring historical snapshots to None.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The processed DataFrame from `load_data`.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing calculated summary statistics, including\n",
        "              YoY metrics mapped to specific template keys. Returns an empty\n",
        "              dictionary if the input DataFrame is invalid.\n",
        "    \"\"\"\n",
        "    summary = {}\n",
        "    if df is None or df.empty:\n",
        "        print(\"Warning: Input DataFrame is empty for summary stats generation.\")\n",
        "        return summary\n",
        "\n",
        "    # Filter for primary functions, falling back if necessary\n",
        "    comp_df = df[df['job_function'].isin(['Product Development', 'Content and Studio'])].copy()\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: No data for primary functions found for summary stats. Using all data.\")\n",
        "        comp_df = df.copy() # Use original if filter is empty\n",
        "\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: DataFrame is empty even after fallback for summary stats.\")\n",
        "        return summary\n",
        "\n",
        "    # --- Overall Metrics (Based on Current Snapshot/Data) ---\n",
        "    summary['total_employees'] = len(comp_df)\n",
        "    # Calculate overall average tenure of *current* workforce\n",
        "    if 'tenure_years' in comp_df.columns:\n",
        "        summary['avg_tenure'] = comp_df['tenure_years'].mean()\n",
        "\n",
        "    # Calculate overall average time-to-promotion (for promotions that occurred)\n",
        "    comp_df['time_to_promotion_num'] = pd.to_numeric(comp_df['time_to_promotion'], errors='coerce')\n",
        "    promo_df_overall = comp_df[comp_df['time_to_promotion_num'] >= 0].copy()\n",
        "    summary['avg_time_to_promotion'] = promo_df_overall['time_to_promotion_num'].mean() if not promo_df_overall.empty else None\n",
        "\n",
        "    # Calculate overall average span of control (for *current* managers with reports)\n",
        "    managers_df_overall = comp_df[comp_df['is_manager']].copy()\n",
        "    managers_df_overall['span_of_control_num'] = pd.to_numeric(managers_df_overall['span_of_control'], errors='coerce')\n",
        "    summary['avg_span'] = managers_df_overall[managers_df_overall['span_of_control_num'] > 0]['span_of_control_num'].mean() if not managers_df_overall.empty else None\n",
        "\n",
        "    # --- Function-Specific Metrics (Based on Current Snapshot/Data) ---\n",
        "    product_df = comp_df[comp_df['job_function'] == 'Product Development']\n",
        "    content_df = comp_df[comp_df['job_function'] == 'Content and Studio']\n",
        "\n",
        "    # Average Tenure by Function\n",
        "    if 'tenure_years' in product_df.columns: summary['product_avg_tenure'] = product_df['tenure_years'].mean()\n",
        "    if 'tenure_years' in content_df.columns: summary['content_avg_tenure'] = content_df['tenure_years'].mean()\n",
        "\n",
        "    # Average Span by Function (for *current* managers with reports)\n",
        "    prod_managers = product_df[product_df['is_manager']]\n",
        "    cont_managers = content_df[content_df['is_manager']]\n",
        "    if not prod_managers.empty and 'span_of_control_num' in prod_managers.columns:\n",
        "        summary['product_avg_span'] = prod_managers[prod_managers['span_of_control_num'] > 0]['span_of_control_num'].mean()\n",
        "    if not cont_managers.empty and 'span_of_control_num' in cont_managers.columns:\n",
        "        summary['content_avg_span'] = cont_managers[cont_managers['span_of_control_num'] > 0]['span_of_control_num'].mean()\n",
        "\n",
        "    # Average Time-to-Promotion by Function (for promotions that occurred)\n",
        "    prod_promo = product_df[product_df['time_to_promotion_num'] >= 0]\n",
        "    cont_promo = content_df[content_df['time_to_promotion_num'] >= 0]\n",
        "    summary['product_avg_time_to_promotion'] = prod_promo['time_to_promotion_num'].mean() if not prod_promo.empty else None\n",
        "    summary['content_avg_time_to_promotion'] = cont_promo['time_to_promotion_num'].mean() if not cont_promo.empty else None\n",
        "\n",
        "    # --- Calculated Year-over-Year Metrics (2023 vs 2022) ---\n",
        "    last_year = 2023\n",
        "    prior_year = 2022\n",
        "\n",
        "    # Initialize calculated YoY values\n",
        "    yoy_hires_change_pct_calc = None\n",
        "    yoy_promotions_change_pct_calc = None\n",
        "    yoy_avg_ttp_change_calc = None # Absolute change in years for TTP\n",
        "    yoy_tenure_diff_calc = None # Absolute change in years for Tenure comparison\n",
        "\n",
        "    # Ensure necessary columns are numeric Int64 for year comparisons\n",
        "    if 'hire_year' in comp_df.columns:\n",
        "        comp_df['hire_year_int'] = pd.to_numeric(comp_df['hire_year'], errors='coerce').astype('Int64')\n",
        "    if 'promotion_year' in comp_df.columns:\n",
        "        comp_df['promotion_year_int'] = pd.to_numeric(comp_df['promotion_year'], errors='coerce').astype('Int64')\n",
        "\n",
        "    # YoY Hires Calculation\n",
        "    if 'hire_year_int' in comp_df.columns:\n",
        "        hires_last_year = comp_df[comp_df['hire_year_int'] == last_year].shape[0]\n",
        "        hires_prior_year = comp_df[comp_df['hire_year_int'] == prior_year].shape[0]\n",
        "        if hires_prior_year > 0:\n",
        "            yoy_hires_change_pct_calc = ((hires_last_year - hires_prior_year) / hires_prior_year) * 100\n",
        "        elif hires_last_year > 0:\n",
        "            yoy_hires_change_pct_calc = np.inf # Indicate increase from zero\n",
        "        elif hires_prior_year == 0 and hires_last_year == 0:\n",
        "             yoy_hires_change_pct_calc = 0.0 # No change from zero\n",
        "\n",
        "    # YoY Promotions Calculation\n",
        "    promo_df = pd.DataFrame() # Initialize empty df\n",
        "    if 'promotion_year_int' in comp_df.columns and 'is_promoted' in comp_df.columns:\n",
        "        promo_df = comp_df[comp_df['is_promoted'] & comp_df['promotion_year_int'].notna()].copy()\n",
        "        promos_last_year = promo_df[promo_df['promotion_year_int'] == last_year].shape[0]\n",
        "        promos_prior_year = promo_df[promo_df['promotion_year_int'] == prior_year].shape[0]\n",
        "        if promos_prior_year > 0:\n",
        "            yoy_promotions_change_pct_calc = ((promos_last_year - promos_prior_year) / promos_prior_year) * 100\n",
        "        elif promos_last_year > 0:\n",
        "            yoy_promotions_change_pct_calc = np.inf # Indicate increase from zero\n",
        "        elif promos_prior_year == 0 and promos_last_year == 0:\n",
        "             yoy_promotions_change_pct_calc = 0.0 # No change from zero\n",
        "\n",
        "    # YoY Average TTP Calculation (for promotions *in* 2023 vs *in* 2022)\n",
        "    if not promo_df.empty and 'time_to_promotion_num' in promo_df.columns:\n",
        "         ttp_last_year_df = promo_df[(promo_df['promotion_year_int'] == last_year) & (promo_df['time_to_promotion_num'] >= 0)]\n",
        "         ttp_prior_year_df = promo_df[(promo_df['promotion_year_int'] == prior_year) & (promo_df['time_to_promotion_num'] >= 0)]\n",
        "         avg_ttp_last_year = ttp_last_year_df['time_to_promotion_num'].mean() if not ttp_last_year_df.empty else np.nan\n",
        "         avg_ttp_prior_year = ttp_prior_year_df['time_to_promotion_num'].mean() if not ttp_prior_year_df.empty else np.nan\n",
        "         if pd.notna(avg_ttp_last_year) and pd.notna(avg_ttp_prior_year):\n",
        "             yoy_avg_ttp_change_calc = avg_ttp_last_year - avg_ttp_prior_year\n",
        "\n",
        "    # YoY Tenure Comparison (Comparing *current* avg tenure of 2023 hires vs 2022 hires)\n",
        "    if 'hire_year_int' in comp_df.columns and 'tenure_years' in comp_df.columns:\n",
        "        tenure_last_year_hires = comp_df.loc[comp_df['hire_year_int'] == last_year, 'tenure_years'].mean()\n",
        "        tenure_prior_year_hires = comp_df.loc[comp_df['hire_year_int'] == prior_year, 'tenure_years'].mean()\n",
        "        if pd.notna(tenure_last_year_hires) and pd.notna(tenure_prior_year_hires):\n",
        "            # Calculate the difference in current average tenure between the two cohorts\n",
        "            yoy_tenure_diff_calc = tenure_last_year_hires - tenure_prior_year_hires\n",
        "\n",
        "    # --- Assign Calculated or Placeholder Values to Template Keys ---\n",
        "\n",
        "    # KPI Card 1: Total Employees -> Use YoY Hire % Change\n",
        "    summary['yoy_employee_change_pct'] = yoy_hires_change_pct_calc\n",
        "\n",
        "    # KPI Card 2: Avg. Tenure -> Use Difference in Avg Current Tenure (2023 hires vs 2022 hires)\n",
        "    summary['yoy_tenure_change'] = yoy_tenure_diff_calc # Absolute difference in years\n",
        "\n",
        "    # KPI Card 3: Avg. Span -> Use YoY Promotion % Change (Formatted String)\n",
        "    yoy_promo_desc = None\n",
        "    if yoy_promotions_change_pct_calc is not None:\n",
        "        if yoy_promotions_change_pct_calc == np.inf:\n",
        "            yoy_promo_desc = \"Increase from Zero\"\n",
        "        elif yoy_promotions_change_pct_calc == 0.0:\n",
        "            yoy_promo_desc = \"No Change\"\n",
        "        else:\n",
        "            yoy_promo_desc = f\"{'+' if yoy_promotions_change_pct_calc > 0 else ''}{safe_round(yoy_promotions_change_pct_calc, 1)}%\"\n",
        "    summary['yoy_span_change_desc'] = yoy_promo_desc # Assign formatted string or None\n",
        "\n",
        "    # KPI Card 4: Avg. TTP -> Use calculated YoY Avg TTP Change (for promotions *in* those years)\n",
        "    summary['yoy_avg_ttp_change'] = yoy_avg_ttp_change_calc # Absolute change in years\n",
        "\n",
        "    # --- Clean Final Dictionary for JSON ---\n",
        "    summary_cleaned = {}\n",
        "    for k, v in summary.items():\n",
        "        if pd.isna(v):\n",
        "            summary_cleaned[k] = None\n",
        "        elif v == np.inf:\n",
        "            summary_cleaned[k] = \"Increase from Zero\"\n",
        "        elif v == -np.inf:\n",
        "             summary_cleaned[k] = None # Should not happen\n",
        "        else:\n",
        "            summary_cleaned[k] = v\n",
        "\n",
        "    return summary_cleaned\n",
        "\n",
        "# =============================================================================\n",
        "# # 8. Table Data Generation\n",
        "# =============================================================================\n",
        "# Description: This section defines the `generate_table_data` function, which\n",
        "# prepares and formats data specifically for display in the various tables\n",
        "# within the HTML dashboard (e.g., composition breakdown, tenure metrics,\n",
        "# span distribution, promotion counts, hiring counts, TTP by level). It\n",
        "# structures the data as lists of dictionaries, suitable for easy iteration\n",
        "# within the Jinja2 template.\n",
        "\n",
        "def generate_table_data(df):\n",
        "    \"\"\"\n",
        "    Generates data structured for rendering tables in the HTML dashboard.\n",
        "\n",
        "    Prepares data subsets and formats them into lists of dictionaries\n",
        "    for tables related to composition, tenure, span, promotions, hiring,\n",
        "    and time-to-promotion.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The processed DataFrame from `load_data`.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys match the expected table data variables\n",
        "              in the Jinja2 template (e.g., 'compositionTableData') and values\n",
        "              are lists of dictionaries representing table rows. Returns an\n",
        "              empty dictionary if the input DataFrame is invalid.\n",
        "    \"\"\"\n",
        "    table_data = {}\n",
        "    if df is None or df.empty:\n",
        "        print(\"Warning: No data available for table generation.\")\n",
        "        return table_data\n",
        "\n",
        "    # Filter for primary functions, falling back if necessary\n",
        "    comp_df = df[df['job_function'].isin(['Product Development', 'Content and Studio'])].copy()\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: No data for primary functions found for tables. Using all data.\")\n",
        "        comp_df = df.copy() # Use original if filter is empty\n",
        "\n",
        "    if comp_df.empty:\n",
        "        print(\"Warning: DataFrame is empty even after fallback for table data.\")\n",
        "        return table_data\n",
        "\n",
        "    # --- Composition Table Data (Function x Level Counts) ---\n",
        "    try:\n",
        "        # Group by function and level, get counts\n",
        "        comp_counts = comp_df.groupby(['job_function', 'job_level_title'], observed=False).size().reset_index(name='count')\n",
        "        # Rename columns for template consistency\n",
        "        table_data['compositionTableData'] = comp_counts.rename(\n",
        "            columns={'job_function': 'function', 'job_level_title': 'level'}\n",
        "        ).to_dict(orient='records')\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating composition table data: {e}\")\n",
        "        table_data['compositionTableData'] = []\n",
        "\n",
        "    # --- Tenure Table Data (Function x Metrics) ---\n",
        "    try:\n",
        "        if 'tenure_years' in comp_df.columns and comp_df['tenure_years'].notna().any():\n",
        "            # Calculate mean and median tenure by function\n",
        "            tenure_summary = comp_df.groupby('job_function', observed=False)['tenure_years'].agg(['mean', 'median']).reset_index()\n",
        "            tenure_summary.rename(columns={'job_function': 'function', 'mean': 'Average Tenure (Yrs)', 'median': 'Median Tenure (Yrs)'}, inplace=True)\n",
        "\n",
        "            # Calculate % < 2 years tenure by function\n",
        "            short_tenure = comp_df[comp_df['tenure_years'] < 2].groupby('job_function', observed=False).size()\n",
        "            total_tenure = comp_df.groupby('job_function', observed=False).size()\n",
        "            pct_short_tenure = (short_tenure / total_tenure * 100).fillna(0).reset_index(name='% < 2 Yrs Tenure')\n",
        "            pct_short_tenure.rename(columns={'job_function': 'function'}, inplace=True)\n",
        "\n",
        "            # Combine metrics into a single long-format structure for the table\n",
        "            tenure_avg_med = tenure_summary.melt(id_vars='function', var_name='metric', value_name='value')\n",
        "            tenure_pct = pct_short_tenure.melt(id_vars='function', var_name='metric', value_name='value')\n",
        "            tenure_combined = pd.concat([tenure_avg_med, tenure_pct], ignore_index=True)\n",
        "\n",
        "            # Apply safe rounding (1 decimal for years, 0 for percentage)\n",
        "            global safe_round\n",
        "            tenure_combined['value'] = tenure_combined.apply(\n",
        "                lambda row: safe_round(row['value'], decimals=1 if '(Yrs)' in row['metric'] else 0), axis=1\n",
        "            )\n",
        "            table_data['tenureTableData'] = tenure_combined.to_dict(orient='records')\n",
        "        else:\n",
        "             table_data['tenureTableData'] = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating tenure table data: {e}\")\n",
        "        table_data['tenureTableData'] = []\n",
        "\n",
        "    # --- Span Table Data (Function x Span Bin %) ---\n",
        "    try:\n",
        "        if 'is_manager' in comp_df.columns and 'span_of_control' in comp_df.columns:\n",
        "            managers_df = comp_df[comp_df['is_manager']].copy()\n",
        "            managers_df['span_of_control'] = pd.to_numeric(managers_df['span_of_control'], errors='coerce')\n",
        "            managers_df.dropna(subset=['span_of_control'], inplace=True)\n",
        "\n",
        "            if not managers_df.empty:\n",
        "                # Bin managers by span of control\n",
        "                bins = [-1, 0, 3, 6, 9, np.inf]; labels = ['0', '1-3', '4-6', '7-9', '10+']\n",
        "                managers_df['span_bin'] = pd.cut(managers_df['span_of_control'], bins=bins, labels=labels, right=True)\n",
        "                # Calculate counts per function/bin\n",
        "                span_dist_data = managers_df.groupby(['job_function', 'span_bin'], observed=False).size().unstack(fill_value=0)\n",
        "                # Calculate percentage distribution within each function\n",
        "                span_dist_pct = span_dist_data.apply(lambda x: x / x.sum() * 100 if x.sum() > 0 else x, axis=1).fillna(0)\n",
        "                # Melt for table structure\n",
        "                span_dist_melt = span_dist_pct.reset_index().melt(id_vars='job_function', var_name='span_bin', value_name='percentage')\n",
        "                # Round percentage and rename columns\n",
        "                span_dist_melt['percentage'] = span_dist_melt['percentage'].apply(safe_round, decimals=1)\n",
        "                table_data['spanTableData'] = span_dist_melt.rename(columns={'job_function': 'function'}).to_dict(orient='records')\n",
        "            else:\n",
        "                 table_data['spanTableData'] = []\n",
        "        else:\n",
        "             table_data['spanTableData'] = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating span table data: {e}\")\n",
        "        table_data['spanTableData'] = []\n",
        "\n",
        "    # --- Promotions Table Data (Year x Function Counts) ---\n",
        "    try:\n",
        "        if 'is_promoted' in comp_df.columns and 'promotion_year' in comp_df.columns:\n",
        "            promo_df = comp_df[comp_df['is_promoted']].copy()\n",
        "            # Ensure year is numeric Int64\n",
        "            promo_df['promotion_year'] = pd.to_numeric(promo_df['promotion_year'], errors='coerce').astype('Int64')\n",
        "            promo_df.dropna(subset=['promotion_year'], inplace=True)\n",
        "\n",
        "            if not promo_df.empty:\n",
        "                # Group by year and function, count promotions\n",
        "                promo_counts = promo_df.groupby(['promotion_year', 'job_function'], observed=False).size().reset_index(name='count')\n",
        "                # Rename columns for template\n",
        "                table_data['promotionsTableData'] = promo_counts.rename(\n",
        "                    columns={'promotion_year': 'year', 'job_function': 'function'}\n",
        "                ).to_dict(orient='records')\n",
        "            else:\n",
        "                 table_data['promotionsTableData'] = []\n",
        "        else:\n",
        "             table_data['promotionsTableData'] = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating promotions table data: {e}\")\n",
        "        table_data['promotionsTableData'] = []\n",
        "\n",
        "    # --- Hiring Table Data (Quarter x Function Counts) ---\n",
        "    try:\n",
        "        # Use the hire_year_quarter_str column if previously created, otherwise create it\n",
        "        if 'hire_year_quarter_str' not in comp_df.columns:\n",
        "             if 'hire_year' in comp_df.columns and 'hire_quarter' in comp_df.columns:\n",
        "                 comp_df['hire_year_num'] = pd.to_numeric(comp_df['hire_year'], errors='coerce').astype('Int64')\n",
        "                 comp_df['hire_year_quarter_str'] = np.where(\n",
        "                      comp_df['hire_year_num'].notna() & comp_df['hire_quarter'].notna(),\n",
        "                      comp_df['hire_year_num'].astype(str) + 'Q' + comp_df['hire_quarter'].astype(str).str.replace(r'\\.0$', '', regex=True),\n",
        "                      pd.NA\n",
        "                 )\n",
        "             else:\n",
        "                 comp_df['hire_year_quarter_str'] = pd.NA # Ensure column exists even if data is missing\n",
        "\n",
        "        if 'hire_year_quarter_str' in comp_df.columns and comp_df['hire_year_quarter_str'].notna().any():\n",
        "            # Group by year-quarter string and function\n",
        "            hire_counts = comp_df.dropna(subset=['hire_year_quarter_str']).groupby(\n",
        "                ['hire_year_quarter_str', 'job_function'], observed=False\n",
        "            ).size().reset_index(name='count')\n",
        "            # Sort chronologically\n",
        "            hire_counts = hire_counts.sort_values('hire_year_quarter_str')\n",
        "            # Rename columns\n",
        "            table_data['hiringTableData'] = hire_counts.rename(\n",
        "                columns={'hire_year_quarter_str': 'quarter', 'job_function': 'function'}\n",
        "            ).to_dict(orient='records')\n",
        "        else:\n",
        "            table_data['hiringTableData'] = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hiring table data: {e}\")\n",
        "        table_data['hiringTableData'] = []\n",
        "\n",
        "    # --- Time to Promotion (TTP) Table Data (Function x Level Avg TTP) ---\n",
        "    try:\n",
        "        # Use numeric TTP column created earlier if available\n",
        "        ttp_col = 'time_to_promotion_num' if 'time_to_promotion_num' in comp_df.columns else 'time_to_promotion'\n",
        "        if ttp_col in comp_df.columns and 'job_level_title' in comp_df.columns:\n",
        "            # Ensure TTP is numeric and filter for valid TTP >= 0\n",
        "            comp_df[ttp_col] = pd.to_numeric(comp_df[ttp_col], errors='coerce')\n",
        "            promo_df_ttp = comp_df[comp_df[ttp_col] >= 0].copy()\n",
        "\n",
        "            if not promo_df_ttp.empty:\n",
        "                # Calculate average TTP by function and level promoted into\n",
        "                ttp_avg = promo_df_ttp.groupby(['job_function', 'job_level_title'], observed=False)[ttp_col].mean().reset_index(name='avg_ttp')\n",
        "                # Round average TTP\n",
        "                ttp_avg['avg_ttp'] = ttp_avg['avg_ttp'].apply(safe_round, decimals=1)\n",
        "                # Filter for relevant manager/director levels for the table display\n",
        "                ttp_avg_filtered = ttp_avg[ttp_avg['job_level_title'].isin(['Manager', 'Director', 'Vice President'])]\n",
        "                # Rename columns\n",
        "                table_data['ttpTableData'] = ttp_avg_filtered.rename(\n",
        "                    columns={'job_function': 'function', 'job_level_title': 'level'}\n",
        "                ).to_dict(orient='records')\n",
        "            else:\n",
        "                table_data['ttpTableData'] = []\n",
        "        else:\n",
        "            table_data['ttpTableData'] = []\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating TTP table data: {e}\")\n",
        "        table_data['ttpTableData'] = []\n",
        "\n",
        "    print(f\"Generated data for {len(table_data)} tables.\")\n",
        "    return table_data\n",
        "\n",
        "# =============================================================================\n",
        "# # 9. HTML Rendering\n",
        "# =============================================================================\n",
        "# Description: This section defines the `render_html_template` function, which\n",
        "# uses the Jinja2 templating engine to populate an HTML template file with the\n",
        "# generated data (summaries, chart specifications, narratives, table data).\n",
        "# It writes the final, populated HTML content to the specified output file.\n",
        "\n",
        "\n",
        "def render_html_template(context, template_filename, output_filename):\n",
        "    \"\"\"\n",
        "    Renders the Jinja2 HTML template with the provided context data.\n",
        "\n",
        "    Loads the specified template file, injects the context dictionary\n",
        "    (containing JSON strings of summaries, charts, narratives, etc.),\n",
        "    and writes the rendered HTML to the output file.\n",
        "\n",
        "    Args:\n",
        "        context (dict): Dictionary containing data to pass to the template.\n",
        "                        Keys should match variables used in the template.\n",
        "        template_filename (str): The name of the Jinja2 template file.\n",
        "        output_filename (str): The name of the HTML file to generate.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if rendering and writing were successful, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Set up Jinja2 environment to load templates from the current directory\n",
        "        template_loader = jinja2.FileSystemLoader(searchpath=\"./\")\n",
        "        # Enable autoescaping for security\n",
        "        template_env = jinja2.Environment(loader=template_loader, autoescape=jinja2.select_autoescape(['html', 'xml']))\n",
        "\n",
        "        # Load the specified template\n",
        "        template = template_env.get_template(template_filename)\n",
        "\n",
        "        # Render the template with the provided context\n",
        "        html_output = template.render(context)\n",
        "\n",
        "        # Write the rendered HTML to the output file\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_output)\n",
        "\n",
        "        print(f\"Successfully rendered template to {output_filename}\")\n",
        "        return True\n",
        "    except jinja2.TemplateNotFound:\n",
        "        print(f\"Error: Template file '{template_filename}' not found in the current directory.\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error rendering HTML template: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# =============================================================================\n",
        "# # 10. Main Execution Block\n",
        "# =============================================================================\n",
        "# Description: This section defines the `main` function, which serves as the\n",
        "# entry point and orchestrator for the entire script. It calls the functions\n",
        "# for data loading, chart generation, narrative creation, summary statistics,\n",
        "# table data preparation, JSON validation, and finally, HTML rendering.\n",
        "# It includes error handling and ensures the script runs only when executed directly.\n",
        "\n",
        "\n",
        "# Helper function to handle np.inf during JSON serialization if needed,\n",
        "# as fallback for the cleaning step in generate_summary_stats.\n",
        "def handle_inf_default(obj):\n",
        "    if obj == np.inf:\n",
        "        return \"Increase from Zero\" # Consistent string representation\n",
        "    elif obj == -np.inf:\n",
        "         return \"Decrease from Zero\" # Or handle appropriately\n",
        "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to execute the dashboard generation workflow.\n",
        "\n",
        "    Calls functions sequentially to:\n",
        "    1. Load and process data.\n",
        "    2. Generate summary statistics (including calculated YoY metrics).\n",
        "    3. Create chart specifications.\n",
        "    4. Generate detailed narratives.\n",
        "    5. Prepare data for tables.\n",
        "    6. Validate all generated JSON components.\n",
        "    7. Render the final HTML dashboard using a Jinja2 template.\n",
        "    Includes error handling for data loading and rendering steps.\n",
        "    \"\"\"\n",
        "    global report_date, snapshot_file, history_file, template_file, output_html\n",
        "\n",
        "    print(\"--- Starting Netflix Org Dashboard Generation ---\")\n",
        "    # Access global report_date (defined in Part 1)\n",
        "    if 'report_date' not in globals():\n",
        "         report_date = dt.datetime.now() # Define if somehow missing\n",
        "    print(f\"Report date: {report_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    # --- Step 1: Load and Process Data ---\n",
        "    df, bad_dates_json, promo_issue_json = load_data()\n",
        "\n",
        "    # Proceed only if data loading was successful and returned a DataFrame\n",
        "    if df is not None and not df.empty:\n",
        "        try:\n",
        "            print(\"Generating dashboard components...\")\n",
        "\n",
        "            # --- Step 2-5: Generate Dashboard Components ---\n",
        "            summary_stats = generate_summary_stats(df) # Includes calculated YoY\n",
        "            charts = create_charts(df) # Returns dict of chart specs\n",
        "            narratives = generate_detailed_narratives(df, bad_dates_json, promo_issue_json)\n",
        "            table_data = generate_table_data(df)\n",
        "\n",
        "            # --- Step 6: Convert Components to JSON Strings ---\n",
        "            # Use default=str for robust serialization of common types (e.g., datetime if not handled)\n",
        "            # The cleaning in generate_summary_stats handles np.inf, but default=str is good practice.\n",
        "            summary_json_string = json.dumps(summary_stats, default=str)\n",
        "            valid_charts = {k: v for k, v in charts.items() if v is not None}\n",
        "            chart_json_string = json.dumps(valid_charts) # Plotly JSON handled by encode_chart\n",
        "            narratives_cleaned = {k: v for k, v in narratives.items() if v is not None}\n",
        "            narrative_json_string = json.dumps(narratives_cleaned, default=str)\n",
        "            table_data_json_string = json.dumps(table_data, default=str)\n",
        "\n",
        "            # --- Step 7: Validate Generated JSON ---\n",
        "            print(\"\\n--- Validating Generated JSON ---\")\n",
        "            is_summary_valid = validate_json(summary_json_string, \"summary_json\")\n",
        "            is_chart_data_valid = validate_json(chart_json_string, \"initial_charts_json\")\n",
        "            is_narrative_valid = validate_json(narrative_json_string, \"narratives_json\")\n",
        "            is_bad_dates_valid = validate_json(bad_dates_json, \"bad_dates_json\")\n",
        "            is_promo_issue_valid = validate_json(promo_issue_json, \"promo_issue_json\")\n",
        "            is_table_data_valid = validate_json(table_data_json_string, \"table_data_json\")\n",
        "            print(\"--- JSON Validation Complete ---\\n\")\n",
        "\n",
        "            # --- Step 8: Render HTML (Conditional on JSON Validation) ---\n",
        "            all_json_valid = (\n",
        "                is_summary_valid and is_chart_data_valid and is_narrative_valid and\n",
        "                is_bad_dates_valid and is_promo_issue_valid and is_table_data_valid\n",
        "            )\n",
        "\n",
        "            if all_json_valid:\n",
        "                # Prepare context dictionary for Jinja2 template\n",
        "                # Globals already declared at function start\n",
        "                context = {\n",
        "                    \"report_date_str\": report_date.strftime('%Y-%m-%d %H:%M'),\n",
        "                    \"snapshot_file\": snapshot_file,\n",
        "                    \"history_file\": history_file,\n",
        "                    \"summary_json\": summary_json_string,\n",
        "                    \"initial_charts_json\": chart_json_string,\n",
        "                    \"narratives_json\": narrative_json_string,\n",
        "                    \"bad_dates_json\": bad_dates_json,\n",
        "                    \"promo_issue_json\": promo_issue_json,\n",
        "                    \"table_data_json\": table_data_json_string\n",
        "                }\n",
        "\n",
        "                print(f\"Rendering HTML template: {template_file}\")\n",
        "                success = render_html_template(context, template_file, output_html)\n",
        "\n",
        "                if success:\n",
        "                    print(f\"--- Dashboard successfully generated: {output_html} ---\")\n",
        "                else:\n",
        "                    print(\"--- Dashboard generation failed during HTML rendering. ---\")\n",
        "            else:\n",
        "                # Report JSON validation failure\n",
        "                print(\"\\n--- ERROR: One or more JSON components failed validation. HTML rendering aborted. ---\")\n",
        "                print(f\"Validation Results:\\n\"\n",
        "                      f\"  Summary JSON: {is_summary_valid}\\n\"\n",
        "                      f\"  Charts JSON: {is_chart_data_valid}\\n\"\n",
        "                      f\"  Narratives JSON: {is_narrative_valid}\\n\"\n",
        "                      f\"  Bad Dates JSON: {is_bad_dates_valid}\\n\"\n",
        "                      f\"  Promo Issues JSON: {is_promo_issue_valid}\\n\"\n",
        "                      f\"  Table Data JSON: {is_table_data_valid}\")\n",
        "                print(\"--- Dashboard generation failed. ---\")\n",
        "                # Optionally write a basic error HTML\n",
        "                try:\n",
        "                    # output_html is now accessible due to global declaration at function start\n",
        "                    with open(output_html, 'w', encoding='utf-8') as f:\n",
        "                         f.write(\"<html><body><h1>Dashboard Generation Failed</h1><p>Could not generate valid JSON data for all components. Please check script logs/output.</p></body></html>\")\n",
        "                    print(f\"Basic error HTML written to {output_html}\")\n",
        "                except Exception as html_err:\n",
        "                     print(f\"Could not write error HTML file: {html_err}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Catch unexpected errors during component generation or rendering\n",
        "            print(f\"An unexpected error occurred during component generation or rendering: {e}\")\n",
        "            traceback.print_exc()\n",
        "            print(\"--- Dashboard generation failed. ---\")\n",
        "    else:\n",
        "        # Handle case where data loading failed\n",
        "        print(\"No valid data loaded/processed. Dashboard generation aborted.\")\n",
        "        # Optionally write a basic error HTML\n",
        "        try:\n",
        "            # output_html is now accessible due to global declaration at function start\n",
        "            with open(output_html, 'w', encoding='utf-8') as f:\n",
        "                 f.write(\"<html><body><h1>Dashboard Generation Failed</h1><p>Could not load or process input data. Please check CSV files and script configuration.</p></body></html>\")\n",
        "            print(f\"Basic error HTML written to {output_html}\")\n",
        "        except Exception as html_err:\n",
        "             print(f\"Could not write error HTML file: {html_err}\")\n",
        "\n",
        "\n",
        "# Inline Run\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qKJ0vvHh7w7m"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}